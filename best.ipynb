{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "99caf1a5-51c4-4dc9-8c13-c6ad94e09c93",
   "metadata": {},
   "outputs": [],
   "source": [
    "import librosa\n",
    "import librosa.display\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "from sklearn.model_selection import train_test_split\n",
    "import keras\n",
    "from keras.utils import to_categorical\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Flatten, Dropout, Activation, Conv1D, MaxPooling1D\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "1078b27d-89ae-4004-980d-8f6d4010c716",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_list = os.listdir('data/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "a1006c70-4c0c-4e17-b87e-f82cac21a25a",
   "metadata": {},
   "outputs": [],
   "source": [
    "CURDIR = os.getcwd()\n",
    "DATADIR = os.path.join(CURDIR, 'data')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "26347684-ee65-4da6-8bbe-d57865692307",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "list"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(data_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "559420cc-1d2c-4271-b2b3-d8301e229aad",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'03-01-01-01-01-01-11.wav'"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_list[10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "334e8027-4f2a-4743-bfd0-abda6734753f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'01'"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_list[10][6:-16]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "ac19b3de-536e-40af-b297-0480067bd967",
   "metadata": {},
   "outputs": [],
   "source": [
    "data, sampling_rate = librosa.load(os.path.join(DATADIR, data_list[10]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "1d0acd1c-58a1-4bb6-918a-b6c4e5586e85",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1500x500 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(15, 5))\n",
    "librosa.display.waveshow(data, sr=sampling_rate)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "9bd81a7d-d7e3-4bfd-bc27-70e185477f23",
   "metadata": {},
   "outputs": [],
   "source": [
    "# tone_dict={'01':'neutral',\n",
    "#              '02':'calm',\n",
    "#              '03':'happy',\n",
    "#              '04':'sad',\n",
    "#              '05':'angry',\n",
    "#              '06':'fearful',\n",
    "#              '07':'disgust',\n",
    "#              '08':'surprised'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "7c7abaf3-d6fa-4229-8954-5306b12eb11d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_0=pd.DataFrame(columns=['item', 'gender', 'tone'])\n",
    "tone_dict={'02':'calm','03':'happy','04':'sad','05':'angry','06':'fearful'}\n",
    "gender_dict={0:'female',1:'male'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "611af0a0-5f72-415a-b37a-1af3357f8949",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'calm'"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tone_dict.get('02')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "ecb9da2f-b892-4614-827d-d7d00e1bf280",
   "metadata": {},
   "outputs": [],
   "source": [
    "for item in data_list:\n",
    "    gender=gender_dict.get(int(item[18:-4])%2)\n",
    "    try:\n",
    "        tone=tone_dict.get(item[6:-16])\n",
    "        df_0.loc[len(df_0.index)] = [item, gender, tone] \n",
    "    except:\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "9efd6c0d-3deb-4bb8-8cd3-351b924da36e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_0.dropna(inplace=True)\n",
    "df_0.reset_index(drop=True, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "4ede82a1-5c5e-497f-8628-56c6615d3220",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>item</th>\n",
       "      <th>gender</th>\n",
       "      <th>tone</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>03-01-02-01-01-01-01.wav</td>\n",
       "      <td>male</td>\n",
       "      <td>calm</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>03-01-02-01-01-01-02.wav</td>\n",
       "      <td>female</td>\n",
       "      <td>calm</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>03-01-02-01-01-01-03.wav</td>\n",
       "      <td>male</td>\n",
       "      <td>calm</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>03-01-02-01-01-01-04.wav</td>\n",
       "      <td>female</td>\n",
       "      <td>calm</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>03-01-02-01-01-01-05.wav</td>\n",
       "      <td>male</td>\n",
       "      <td>calm</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                       item  gender  tone\n",
       "0  03-01-02-01-01-01-01.wav    male  calm\n",
       "1  03-01-02-01-01-01-02.wav  female  calm\n",
       "2  03-01-02-01-01-01-03.wav    male  calm\n",
       "3  03-01-02-01-01-01-04.wav  female  calm\n",
       "4  03-01-02-01-01-01-05.wav    male  calm"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_0.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "d0ad8ae4-4822-420f-8c0d-1f29863a1387",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = list(df_0['item'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "0a840d39-c6a3-4e5b-95d7-c600eb75bd38",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "list"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d515fac-56e6-4ea4-947a-1271f5cf7c6a",
   "metadata": {},
   "source": [
    "## Getting the features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "daae5efe",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import librosa\n",
    "\n",
    "df_1 = pd.DataFrame()\n",
    "\n",
    "# Define the column names for the DataFrame\n",
    "columns = [f'mfcc_{i}' for i in range(13)] + [f'chroma_{i}' for i in range(12)] + [f'spectral_contrast_{i}' for i in range(7)]\n",
    "\n",
    "# Process each audio file and extract features\n",
    "for index, y in enumerate(data):\n",
    "    # Load the audio file\n",
    "    y, sr = librosa.load(os.path.join(DATADIR, y), sr=22050)  # Adjust sr as needed\n",
    "    \n",
    "    # Extract MFCC features\n",
    "    mfccs = librosa.feature.mfcc(y=y, sr=sr, n_mfcc=13)\n",
    "    mfccs_mean = np.mean(mfccs, axis=1)\n",
    "    \n",
    "    # Extract Chroma features\n",
    "    chroma = librosa.feature.chroma_stft(y=y, sr=sr)\n",
    "    chroma_mean = np.mean(chroma, axis=1)\n",
    "    \n",
    "    # Extract Spectral Contrast features\n",
    "    spectral_contrast = librosa.feature.spectral_contrast(y=y, sr=sr)\n",
    "    spectral_contrast_mean = np.mean(spectral_contrast, axis=1)\n",
    "    \n",
    "    # Combine all features into a single feature vector\n",
    "    features = np.concatenate((mfccs_mean, chroma_mean, spectral_contrast_mean))\n",
    "    \n",
    "    \n",
    "    # Create a DataFrame for the current features\n",
    "    features_df = pd.DataFrame([features], columns=columns)\n",
    "    \n",
    "    # Append the features to the main DataFrame\n",
    "    df_1 = pd.concat([df_1, features_df], ignore_index=True)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "581ca9b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "scaler = StandardScaler()\n",
    "df_1[columns] = scaler.fit_transform(df_1[columns])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "42703d76-2d5f-4d94-b82c-3295afbdfe80",
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = []\n",
    "for index in range(df_0.shape[0]):\n",
    "    label = df_0['gender'][index] +'_'+ df_0['tone'][index]\n",
    "    labels.append(label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "9a9cad5a-8ca1-45b5-8f7a-d0fd0ed9c004",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(df_1, labels, test_size=0.2, random_state=10)\n",
    "X_train = np.array(X_train)\n",
    "y_train = np.array(y_train)\n",
    "X_test = np.array(X_test)\n",
    "y_test = np.array(y_test)\n",
    "\n",
    "lb = LabelEncoder()\n",
    "\n",
    "y_train = to_categorical(lb.fit_transform(y_train))\n",
    "y_test = to_categorical(lb.fit_transform(y_test))\n",
    "\n",
    "# Expand dimensions for CNN input\n",
    "x_traincnn = np.expand_dims(X_train, axis=2)\n",
    "x_testcnn = np.expand_dims(X_test, axis=2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "7c2fabb1-bec5-420c-b21d-f3519b8fe2fa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_17\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv1d_47 (Conv1D)          (None, 32, 128)           768       \n",
      "                                                                 \n",
      " batch_normalization_36 (Bat  (None, 32, 128)          512       \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " activation_77 (Activation)  (None, 32, 128)           0         \n",
      "                                                                 \n",
      " dropout_55 (Dropout)        (None, 32, 128)           0         \n",
      "                                                                 \n",
      " conv1d_48 (Conv1D)          (None, 32, 64)            41024     \n",
      "                                                                 \n",
      " batch_normalization_37 (Bat  (None, 32, 64)           256       \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " activation_78 (Activation)  (None, 32, 64)            0         \n",
      "                                                                 \n",
      " max_pooling1d_14 (MaxPoolin  (None, 16, 64)           0         \n",
      " g1D)                                                            \n",
      "                                                                 \n",
      " dropout_56 (Dropout)        (None, 16, 64)            0         \n",
      "                                                                 \n",
      " conv1d_49 (Conv1D)          (None, 16, 64)            20544     \n",
      "                                                                 \n",
      " batch_normalization_38 (Bat  (None, 16, 64)           256       \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " activation_79 (Activation)  (None, 16, 64)            0         \n",
      "                                                                 \n",
      " dropout_57 (Dropout)        (None, 16, 64)            0         \n",
      "                                                                 \n",
      " flatten_14 (Flatten)        (None, 1024)              0         \n",
      "                                                                 \n",
      " dense_28 (Dense)            (None, 64)                65600     \n",
      "                                                                 \n",
      " batch_normalization_39 (Bat  (None, 64)               256       \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " activation_80 (Activation)  (None, 64)                0         \n",
      "                                                                 \n",
      " dropout_58 (Dropout)        (None, 64)                0         \n",
      "                                                                 \n",
      " dense_29 (Dense)            (None, 10)                650       \n",
      "                                                                 \n",
      " activation_81 (Activation)  (None, 10)                0         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 129,866\n",
      "Trainable params: 129,226\n",
      "Non-trainable params: 640\n",
      "_________________________________________________________________\n",
      "Epoch 1/1000\n",
      "48/48 [==============================] - 5s 22ms/step - loss: 3.1814 - accuracy: 0.1003 - val_loss: 2.4360 - val_accuracy: 0.1302\n",
      "Epoch 2/1000\n",
      "48/48 [==============================] - 1s 11ms/step - loss: 3.0916 - accuracy: 0.1172 - val_loss: 2.4544 - val_accuracy: 0.1302\n",
      "Epoch 3/1000\n",
      "48/48 [==============================] - 1s 13ms/step - loss: 2.9783 - accuracy: 0.1211 - val_loss: 2.4616 - val_accuracy: 0.1406\n",
      "Epoch 4/1000\n",
      "48/48 [==============================] - 1s 12ms/step - loss: 2.9249 - accuracy: 0.1107 - val_loss: 2.4445 - val_accuracy: 0.1354\n",
      "Epoch 5/1000\n",
      "48/48 [==============================] - 1s 11ms/step - loss: 2.8604 - accuracy: 0.1445 - val_loss: 2.4141 - val_accuracy: 0.1667\n",
      "Epoch 6/1000\n",
      "48/48 [==============================] - 1s 12ms/step - loss: 2.7904 - accuracy: 0.1576 - val_loss: 2.3661 - val_accuracy: 0.1875\n",
      "Epoch 7/1000\n",
      "48/48 [==============================] - 1s 11ms/step - loss: 2.7212 - accuracy: 0.1706 - val_loss: 2.3164 - val_accuracy: 0.2083\n",
      "Epoch 8/1000\n",
      "48/48 [==============================] - 1s 11ms/step - loss: 2.7024 - accuracy: 0.1510 - val_loss: 2.2635 - val_accuracy: 0.2396\n",
      "Epoch 9/1000\n",
      "48/48 [==============================] - 1s 11ms/step - loss: 2.7027 - accuracy: 0.1602 - val_loss: 2.2093 - val_accuracy: 0.2604\n",
      "Epoch 10/1000\n",
      "48/48 [==============================] - 1s 12ms/step - loss: 2.6552 - accuracy: 0.1589 - val_loss: 2.1645 - val_accuracy: 0.2656\n",
      "Epoch 11/1000\n",
      "48/48 [==============================] - 1s 12ms/step - loss: 2.6440 - accuracy: 0.1797 - val_loss: 2.1260 - val_accuracy: 0.2812\n",
      "Epoch 12/1000\n",
      "48/48 [==============================] - 1s 11ms/step - loss: 2.5059 - accuracy: 0.1888 - val_loss: 2.0920 - val_accuracy: 0.2656\n",
      "Epoch 13/1000\n",
      "48/48 [==============================] - 1s 12ms/step - loss: 2.5360 - accuracy: 0.1849 - val_loss: 2.0658 - val_accuracy: 0.2656\n",
      "Epoch 14/1000\n",
      "48/48 [==============================] - 1s 11ms/step - loss: 2.4682 - accuracy: 0.1940 - val_loss: 2.0406 - val_accuracy: 0.2656\n",
      "Epoch 15/1000\n",
      "48/48 [==============================] - 1s 13ms/step - loss: 2.4730 - accuracy: 0.1940 - val_loss: 2.0201 - val_accuracy: 0.2656\n",
      "Epoch 16/1000\n",
      "48/48 [==============================] - 1s 11ms/step - loss: 2.4013 - accuracy: 0.2253 - val_loss: 1.9993 - val_accuracy: 0.2865\n",
      "Epoch 17/1000\n",
      "48/48 [==============================] - 1s 12ms/step - loss: 2.3892 - accuracy: 0.2122 - val_loss: 1.9756 - val_accuracy: 0.2969\n",
      "Epoch 18/1000\n",
      "48/48 [==============================] - 1s 11ms/step - loss: 2.3361 - accuracy: 0.2174 - val_loss: 1.9556 - val_accuracy: 0.3177\n",
      "Epoch 19/1000\n",
      "48/48 [==============================] - 1s 12ms/step - loss: 2.3909 - accuracy: 0.2227 - val_loss: 1.9439 - val_accuracy: 0.3542\n",
      "Epoch 20/1000\n",
      "48/48 [==============================] - 1s 11ms/step - loss: 2.2716 - accuracy: 0.2409 - val_loss: 1.9276 - val_accuracy: 0.3698\n",
      "Epoch 21/1000\n",
      "48/48 [==============================] - 1s 12ms/step - loss: 2.3783 - accuracy: 0.2383 - val_loss: 1.9138 - val_accuracy: 0.3854\n",
      "Epoch 22/1000\n",
      "48/48 [==============================] - 1s 12ms/step - loss: 2.2052 - accuracy: 0.2604 - val_loss: 1.8973 - val_accuracy: 0.3958\n",
      "Epoch 23/1000\n",
      "48/48 [==============================] - 1s 12ms/step - loss: 2.3132 - accuracy: 0.2292 - val_loss: 1.8841 - val_accuracy: 0.3750\n",
      "Epoch 24/1000\n",
      "48/48 [==============================] - 1s 12ms/step - loss: 2.2228 - accuracy: 0.2500 - val_loss: 1.8758 - val_accuracy: 0.3958\n",
      "Epoch 25/1000\n",
      "48/48 [==============================] - 1s 12ms/step - loss: 2.2823 - accuracy: 0.2344 - val_loss: 1.8654 - val_accuracy: 0.4167\n",
      "Epoch 26/1000\n",
      "48/48 [==============================] - 1s 12ms/step - loss: 2.1776 - accuracy: 0.2630 - val_loss: 1.8583 - val_accuracy: 0.4219\n",
      "Epoch 27/1000\n",
      "48/48 [==============================] - 1s 11ms/step - loss: 2.2118 - accuracy: 0.2526 - val_loss: 1.8455 - val_accuracy: 0.4271\n",
      "Epoch 28/1000\n",
      "48/48 [==============================] - 1s 12ms/step - loss: 2.1640 - accuracy: 0.2708 - val_loss: 1.8362 - val_accuracy: 0.4271\n",
      "Epoch 29/1000\n",
      "48/48 [==============================] - 1s 11ms/step - loss: 2.2355 - accuracy: 0.2448 - val_loss: 1.8264 - val_accuracy: 0.4375\n",
      "Epoch 30/1000\n",
      "48/48 [==============================] - 1s 12ms/step - loss: 2.1966 - accuracy: 0.2617 - val_loss: 1.8148 - val_accuracy: 0.4479\n",
      "Epoch 31/1000\n",
      "48/48 [==============================] - 1s 11ms/step - loss: 2.2168 - accuracy: 0.2734 - val_loss: 1.8094 - val_accuracy: 0.4531\n",
      "Epoch 32/1000\n",
      "48/48 [==============================] - 1s 12ms/step - loss: 2.1482 - accuracy: 0.2721 - val_loss: 1.7988 - val_accuracy: 0.4583\n",
      "Epoch 33/1000\n",
      "48/48 [==============================] - 1s 11ms/step - loss: 2.1327 - accuracy: 0.2734 - val_loss: 1.7888 - val_accuracy: 0.4688\n",
      "Epoch 34/1000\n",
      "48/48 [==============================] - 1s 12ms/step - loss: 2.1835 - accuracy: 0.2578 - val_loss: 1.7768 - val_accuracy: 0.4635\n",
      "Epoch 35/1000\n",
      "48/48 [==============================] - 1s 11ms/step - loss: 2.0975 - accuracy: 0.3034 - val_loss: 1.7675 - val_accuracy: 0.4531\n",
      "Epoch 36/1000\n",
      "48/48 [==============================] - 1s 12ms/step - loss: 2.0344 - accuracy: 0.2917 - val_loss: 1.7597 - val_accuracy: 0.4688\n",
      "Epoch 37/1000\n",
      "48/48 [==============================] - 1s 11ms/step - loss: 2.0980 - accuracy: 0.2878 - val_loss: 1.7478 - val_accuracy: 0.4583\n",
      "Epoch 38/1000\n",
      "48/48 [==============================] - 1s 12ms/step - loss: 2.0753 - accuracy: 0.2969 - val_loss: 1.7428 - val_accuracy: 0.4583\n",
      "Epoch 39/1000\n",
      "48/48 [==============================] - 1s 11ms/step - loss: 2.0395 - accuracy: 0.3112 - val_loss: 1.7329 - val_accuracy: 0.4531\n",
      "Epoch 40/1000\n",
      "48/48 [==============================] - 1s 12ms/step - loss: 2.0689 - accuracy: 0.3138 - val_loss: 1.7265 - val_accuracy: 0.4531\n",
      "Epoch 41/1000\n",
      "48/48 [==============================] - 1s 11ms/step - loss: 2.0408 - accuracy: 0.3190 - val_loss: 1.7169 - val_accuracy: 0.4635\n",
      "Epoch 42/1000\n",
      "48/48 [==============================] - 1s 12ms/step - loss: 2.0514 - accuracy: 0.3021 - val_loss: 1.7075 - val_accuracy: 0.4375\n",
      "Epoch 43/1000\n",
      "48/48 [==============================] - 1s 11ms/step - loss: 2.0526 - accuracy: 0.2956 - val_loss: 1.7033 - val_accuracy: 0.4635\n",
      "Epoch 44/1000\n",
      "48/48 [==============================] - 1s 12ms/step - loss: 2.0290 - accuracy: 0.3138 - val_loss: 1.6939 - val_accuracy: 0.4531\n",
      "Epoch 45/1000\n",
      "48/48 [==============================] - 1s 12ms/step - loss: 1.9581 - accuracy: 0.3320 - val_loss: 1.6887 - val_accuracy: 0.4635\n",
      "Epoch 46/1000\n",
      "48/48 [==============================] - 1s 11ms/step - loss: 1.9899 - accuracy: 0.3151 - val_loss: 1.6803 - val_accuracy: 0.4635\n",
      "Epoch 47/1000\n",
      "48/48 [==============================] - 1s 12ms/step - loss: 2.0179 - accuracy: 0.2995 - val_loss: 1.6680 - val_accuracy: 0.4583\n",
      "Epoch 48/1000\n",
      "48/48 [==============================] - 1s 11ms/step - loss: 1.9691 - accuracy: 0.2982 - val_loss: 1.6569 - val_accuracy: 0.4531\n",
      "Epoch 49/1000\n",
      "48/48 [==============================] - 1s 12ms/step - loss: 1.9893 - accuracy: 0.3047 - val_loss: 1.6531 - val_accuracy: 0.4635\n",
      "Epoch 50/1000\n",
      "48/48 [==============================] - 1s 11ms/step - loss: 1.9541 - accuracy: 0.3555 - val_loss: 1.6477 - val_accuracy: 0.4635\n",
      "Epoch 51/1000\n",
      "48/48 [==============================] - 1s 12ms/step - loss: 1.9768 - accuracy: 0.3333 - val_loss: 1.6406 - val_accuracy: 0.4583\n",
      "Epoch 52/1000\n",
      "48/48 [==============================] - 1s 11ms/step - loss: 1.9168 - accuracy: 0.3594 - val_loss: 1.6368 - val_accuracy: 0.4583\n",
      "Epoch 53/1000\n",
      "48/48 [==============================] - 1s 12ms/step - loss: 1.9211 - accuracy: 0.3490 - val_loss: 1.6271 - val_accuracy: 0.4583\n",
      "Epoch 54/1000\n",
      "48/48 [==============================] - 1s 11ms/step - loss: 1.9100 - accuracy: 0.3464 - val_loss: 1.6175 - val_accuracy: 0.4583\n",
      "Epoch 55/1000\n",
      "48/48 [==============================] - 1s 12ms/step - loss: 1.9056 - accuracy: 0.3594 - val_loss: 1.6071 - val_accuracy: 0.4583\n",
      "Epoch 56/1000\n",
      "48/48 [==============================] - 1s 11ms/step - loss: 1.8958 - accuracy: 0.3464 - val_loss: 1.6026 - val_accuracy: 0.4583\n",
      "Epoch 57/1000\n",
      "48/48 [==============================] - 1s 13ms/step - loss: 1.9415 - accuracy: 0.3372 - val_loss: 1.5960 - val_accuracy: 0.4635\n",
      "Epoch 58/1000\n",
      "48/48 [==============================] - 1s 11ms/step - loss: 1.8581 - accuracy: 0.3763 - val_loss: 1.5895 - val_accuracy: 0.4635\n",
      "Epoch 59/1000\n",
      "48/48 [==============================] - 1s 12ms/step - loss: 1.8267 - accuracy: 0.3828 - val_loss: 1.5816 - val_accuracy: 0.4740\n",
      "Epoch 60/1000\n",
      "48/48 [==============================] - 1s 11ms/step - loss: 1.8646 - accuracy: 0.3529 - val_loss: 1.5781 - val_accuracy: 0.4792\n",
      "Epoch 61/1000\n",
      "48/48 [==============================] - 1s 11ms/step - loss: 1.9197 - accuracy: 0.3568 - val_loss: 1.5747 - val_accuracy: 0.4792\n",
      "Epoch 62/1000\n",
      "48/48 [==============================] - 1s 12ms/step - loss: 1.8503 - accuracy: 0.3672 - val_loss: 1.5670 - val_accuracy: 0.4792\n",
      "Epoch 63/1000\n",
      "48/48 [==============================] - 1s 11ms/step - loss: 1.7860 - accuracy: 0.3737 - val_loss: 1.5659 - val_accuracy: 0.4635\n",
      "Epoch 64/1000\n",
      "48/48 [==============================] - 1s 11ms/step - loss: 1.8728 - accuracy: 0.3555 - val_loss: 1.5610 - val_accuracy: 0.4792\n",
      "Epoch 65/1000\n",
      "48/48 [==============================] - 1s 12ms/step - loss: 1.8130 - accuracy: 0.3750 - val_loss: 1.5552 - val_accuracy: 0.4740\n",
      "Epoch 66/1000\n",
      "48/48 [==============================] - 1s 12ms/step - loss: 1.8621 - accuracy: 0.3763 - val_loss: 1.5456 - val_accuracy: 0.4948\n",
      "Epoch 67/1000\n",
      "48/48 [==============================] - 1s 12ms/step - loss: 1.8590 - accuracy: 0.3646 - val_loss: 1.5393 - val_accuracy: 0.4896\n",
      "Epoch 68/1000\n",
      "48/48 [==============================] - 1s 12ms/step - loss: 1.7629 - accuracy: 0.3893 - val_loss: 1.5396 - val_accuracy: 0.4740\n",
      "Epoch 69/1000\n",
      "48/48 [==============================] - 1s 11ms/step - loss: 1.8472 - accuracy: 0.3424 - val_loss: 1.5376 - val_accuracy: 0.4792\n",
      "Epoch 70/1000\n",
      "48/48 [==============================] - 1s 12ms/step - loss: 1.7495 - accuracy: 0.3893 - val_loss: 1.5233 - val_accuracy: 0.4740\n",
      "Epoch 71/1000\n",
      "48/48 [==============================] - 1s 11ms/step - loss: 1.7566 - accuracy: 0.3841 - val_loss: 1.5190 - val_accuracy: 0.4844\n",
      "Epoch 72/1000\n",
      "48/48 [==============================] - 1s 12ms/step - loss: 1.7477 - accuracy: 0.3958 - val_loss: 1.5133 - val_accuracy: 0.4844\n",
      "Epoch 73/1000\n",
      "48/48 [==============================] - 1s 11ms/step - loss: 1.7751 - accuracy: 0.3854 - val_loss: 1.5098 - val_accuracy: 0.4896\n",
      "Epoch 74/1000\n",
      "48/48 [==============================] - 1s 12ms/step - loss: 1.7649 - accuracy: 0.3984 - val_loss: 1.5042 - val_accuracy: 0.5000\n",
      "Epoch 75/1000\n",
      "48/48 [==============================] - 1s 11ms/step - loss: 1.7035 - accuracy: 0.4219 - val_loss: 1.4986 - val_accuracy: 0.5052\n",
      "Epoch 76/1000\n",
      "48/48 [==============================] - 1s 12ms/step - loss: 1.7854 - accuracy: 0.3711 - val_loss: 1.4939 - val_accuracy: 0.5000\n",
      "Epoch 77/1000\n",
      "48/48 [==============================] - 1s 11ms/step - loss: 1.7560 - accuracy: 0.4128 - val_loss: 1.4906 - val_accuracy: 0.4896\n",
      "Epoch 78/1000\n",
      "48/48 [==============================] - 1s 11ms/step - loss: 1.6524 - accuracy: 0.4232 - val_loss: 1.4821 - val_accuracy: 0.4948\n",
      "Epoch 79/1000\n",
      "48/48 [==============================] - 1s 12ms/step - loss: 1.7153 - accuracy: 0.4049 - val_loss: 1.4770 - val_accuracy: 0.4948\n",
      "Epoch 80/1000\n",
      "48/48 [==============================] - 1s 12ms/step - loss: 1.6847 - accuracy: 0.4297 - val_loss: 1.4728 - val_accuracy: 0.4948\n",
      "Epoch 81/1000\n",
      "48/48 [==============================] - 1s 12ms/step - loss: 1.7112 - accuracy: 0.4245 - val_loss: 1.4687 - val_accuracy: 0.4948\n",
      "Epoch 82/1000\n",
      "48/48 [==============================] - 1s 12ms/step - loss: 1.7172 - accuracy: 0.4062 - val_loss: 1.4638 - val_accuracy: 0.4948\n",
      "Epoch 83/1000\n",
      "48/48 [==============================] - 1s 11ms/step - loss: 1.6938 - accuracy: 0.4180 - val_loss: 1.4567 - val_accuracy: 0.4896\n",
      "Epoch 84/1000\n",
      "48/48 [==============================] - 1s 11ms/step - loss: 1.6485 - accuracy: 0.4336 - val_loss: 1.4514 - val_accuracy: 0.5052\n",
      "Epoch 85/1000\n",
      "48/48 [==============================] - 1s 13ms/step - loss: 1.6501 - accuracy: 0.4349 - val_loss: 1.4444 - val_accuracy: 0.5104\n",
      "Epoch 86/1000\n",
      "48/48 [==============================] - 1s 11ms/step - loss: 1.6647 - accuracy: 0.4258 - val_loss: 1.4419 - val_accuracy: 0.5000\n",
      "Epoch 87/1000\n",
      "48/48 [==============================] - 1s 13ms/step - loss: 1.6527 - accuracy: 0.4089 - val_loss: 1.4359 - val_accuracy: 0.5052\n",
      "Epoch 88/1000\n",
      "48/48 [==============================] - 1s 12ms/step - loss: 1.6665 - accuracy: 0.4271 - val_loss: 1.4276 - val_accuracy: 0.5000\n",
      "Epoch 89/1000\n",
      "48/48 [==============================] - 1s 11ms/step - loss: 1.6501 - accuracy: 0.4089 - val_loss: 1.4229 - val_accuracy: 0.5052\n",
      "Epoch 90/1000\n",
      "48/48 [==============================] - 1s 11ms/step - loss: 1.6708 - accuracy: 0.4271 - val_loss: 1.4218 - val_accuracy: 0.4948\n",
      "Epoch 91/1000\n",
      "48/48 [==============================] - 1s 12ms/step - loss: 1.6511 - accuracy: 0.4336 - val_loss: 1.4211 - val_accuracy: 0.4948\n",
      "Epoch 92/1000\n",
      "48/48 [==============================] - 1s 12ms/step - loss: 1.6273 - accuracy: 0.4271 - val_loss: 1.4163 - val_accuracy: 0.4896\n",
      "Epoch 93/1000\n",
      "48/48 [==============================] - 1s 12ms/step - loss: 1.5996 - accuracy: 0.4648 - val_loss: 1.4110 - val_accuracy: 0.4948\n",
      "Epoch 94/1000\n",
      "48/48 [==============================] - 1s 11ms/step - loss: 1.6567 - accuracy: 0.4206 - val_loss: 1.4134 - val_accuracy: 0.5000\n",
      "Epoch 95/1000\n",
      "48/48 [==============================] - 1s 12ms/step - loss: 1.5752 - accuracy: 0.4466 - val_loss: 1.4053 - val_accuracy: 0.4948\n",
      "Epoch 96/1000\n",
      "48/48 [==============================] - 1s 11ms/step - loss: 1.6124 - accuracy: 0.4453 - val_loss: 1.3998 - val_accuracy: 0.4948\n",
      "Epoch 97/1000\n",
      "48/48 [==============================] - 1s 11ms/step - loss: 1.6265 - accuracy: 0.4401 - val_loss: 1.3946 - val_accuracy: 0.4896\n",
      "Epoch 98/1000\n",
      "48/48 [==============================] - 1s 12ms/step - loss: 1.5581 - accuracy: 0.4609 - val_loss: 1.3888 - val_accuracy: 0.5104\n",
      "Epoch 99/1000\n",
      "48/48 [==============================] - 1s 12ms/step - loss: 1.5563 - accuracy: 0.4779 - val_loss: 1.3852 - val_accuracy: 0.5052\n",
      "Epoch 100/1000\n",
      "48/48 [==============================] - 1s 11ms/step - loss: 1.6011 - accuracy: 0.4583 - val_loss: 1.3813 - val_accuracy: 0.5000\n",
      "Epoch 101/1000\n",
      "48/48 [==============================] - 1s 12ms/step - loss: 1.5928 - accuracy: 0.4427 - val_loss: 1.3745 - val_accuracy: 0.5052\n",
      "Epoch 102/1000\n",
      "48/48 [==============================] - 1s 11ms/step - loss: 1.6339 - accuracy: 0.4323 - val_loss: 1.3734 - val_accuracy: 0.5000\n",
      "Epoch 103/1000\n",
      "48/48 [==============================] - 1s 11ms/step - loss: 1.5584 - accuracy: 0.4635 - val_loss: 1.3707 - val_accuracy: 0.5052\n",
      "Epoch 104/1000\n",
      "48/48 [==============================] - 1s 11ms/step - loss: 1.5653 - accuracy: 0.4635 - val_loss: 1.3644 - val_accuracy: 0.5104\n",
      "Epoch 105/1000\n",
      "48/48 [==============================] - 1s 12ms/step - loss: 1.5783 - accuracy: 0.4258 - val_loss: 1.3588 - val_accuracy: 0.5156\n",
      "Epoch 106/1000\n",
      "48/48 [==============================] - 1s 11ms/step - loss: 1.5755 - accuracy: 0.4479 - val_loss: 1.3581 - val_accuracy: 0.5260\n",
      "Epoch 107/1000\n",
      "48/48 [==============================] - 1s 11ms/step - loss: 1.5794 - accuracy: 0.4583 - val_loss: 1.3530 - val_accuracy: 0.5208\n",
      "Epoch 108/1000\n",
      "48/48 [==============================] - 1s 11ms/step - loss: 1.5355 - accuracy: 0.4688 - val_loss: 1.3500 - val_accuracy: 0.5312\n",
      "Epoch 109/1000\n",
      "48/48 [==============================] - 1s 12ms/step - loss: 1.5238 - accuracy: 0.4987 - val_loss: 1.3450 - val_accuracy: 0.5312\n",
      "Epoch 110/1000\n",
      "48/48 [==============================] - 1s 11ms/step - loss: 1.5551 - accuracy: 0.4818 - val_loss: 1.3427 - val_accuracy: 0.5417\n",
      "Epoch 111/1000\n",
      "48/48 [==============================] - 1s 12ms/step - loss: 1.4921 - accuracy: 0.5052 - val_loss: 1.3362 - val_accuracy: 0.5312\n",
      "Epoch 112/1000\n",
      "48/48 [==============================] - 1s 11ms/step - loss: 1.5224 - accuracy: 0.4857 - val_loss: 1.3314 - val_accuracy: 0.5260\n",
      "Epoch 113/1000\n",
      "48/48 [==============================] - 1s 12ms/step - loss: 1.4978 - accuracy: 0.4870 - val_loss: 1.3257 - val_accuracy: 0.5312\n",
      "Epoch 114/1000\n",
      "48/48 [==============================] - 1s 12ms/step - loss: 1.4951 - accuracy: 0.4753 - val_loss: 1.3237 - val_accuracy: 0.5312\n",
      "Epoch 115/1000\n",
      "48/48 [==============================] - 1s 12ms/step - loss: 1.5105 - accuracy: 0.4883 - val_loss: 1.3214 - val_accuracy: 0.5365\n",
      "Epoch 116/1000\n",
      "48/48 [==============================] - 1s 12ms/step - loss: 1.4950 - accuracy: 0.4805 - val_loss: 1.3199 - val_accuracy: 0.5365\n",
      "Epoch 117/1000\n",
      "48/48 [==============================] - 1s 11ms/step - loss: 1.4920 - accuracy: 0.4922 - val_loss: 1.3173 - val_accuracy: 0.5312\n",
      "Epoch 118/1000\n",
      "48/48 [==============================] - 1s 12ms/step - loss: 1.4799 - accuracy: 0.4831 - val_loss: 1.3132 - val_accuracy: 0.5365\n",
      "Epoch 119/1000\n",
      "48/48 [==============================] - 1s 11ms/step - loss: 1.4629 - accuracy: 0.4818 - val_loss: 1.3045 - val_accuracy: 0.5365\n",
      "Epoch 120/1000\n",
      "48/48 [==============================] - 1s 12ms/step - loss: 1.5018 - accuracy: 0.4805 - val_loss: 1.2991 - val_accuracy: 0.5365\n",
      "Epoch 121/1000\n",
      "48/48 [==============================] - 1s 11ms/step - loss: 1.5244 - accuracy: 0.4753 - val_loss: 1.3005 - val_accuracy: 0.5260\n",
      "Epoch 122/1000\n",
      "48/48 [==============================] - 1s 12ms/step - loss: 1.4693 - accuracy: 0.4831 - val_loss: 1.2932 - val_accuracy: 0.5365\n",
      "Epoch 123/1000\n",
      "48/48 [==============================] - 1s 11ms/step - loss: 1.4813 - accuracy: 0.4896 - val_loss: 1.2862 - val_accuracy: 0.5365\n",
      "Epoch 124/1000\n",
      "48/48 [==============================] - 1s 12ms/step - loss: 1.4834 - accuracy: 0.4688 - val_loss: 1.2841 - val_accuracy: 0.5365\n",
      "Epoch 125/1000\n",
      "48/48 [==============================] - 1s 11ms/step - loss: 1.4950 - accuracy: 0.4583 - val_loss: 1.2788 - val_accuracy: 0.5312\n",
      "Epoch 126/1000\n",
      "48/48 [==============================] - 1s 11ms/step - loss: 1.4907 - accuracy: 0.5013 - val_loss: 1.2709 - val_accuracy: 0.5417\n",
      "Epoch 127/1000\n",
      "48/48 [==============================] - 1s 12ms/step - loss: 1.4905 - accuracy: 0.5039 - val_loss: 1.2715 - val_accuracy: 0.5312\n",
      "Epoch 128/1000\n",
      "48/48 [==============================] - 1s 11ms/step - loss: 1.5022 - accuracy: 0.4753 - val_loss: 1.2718 - val_accuracy: 0.5417\n",
      "Epoch 129/1000\n",
      "48/48 [==============================] - 1s 12ms/step - loss: 1.4517 - accuracy: 0.5104 - val_loss: 1.2720 - val_accuracy: 0.5365\n",
      "Epoch 130/1000\n",
      "48/48 [==============================] - 1s 11ms/step - loss: 1.4190 - accuracy: 0.5247 - val_loss: 1.2710 - val_accuracy: 0.5312\n",
      "Epoch 131/1000\n",
      "48/48 [==============================] - 1s 12ms/step - loss: 1.4430 - accuracy: 0.5091 - val_loss: 1.2665 - val_accuracy: 0.5365\n",
      "Epoch 132/1000\n",
      "48/48 [==============================] - 1s 11ms/step - loss: 1.4334 - accuracy: 0.4948 - val_loss: 1.2625 - val_accuracy: 0.5469\n",
      "Epoch 133/1000\n",
      "48/48 [==============================] - 1s 12ms/step - loss: 1.4567 - accuracy: 0.5026 - val_loss: 1.2553 - val_accuracy: 0.5625\n",
      "Epoch 134/1000\n",
      "48/48 [==============================] - 1s 11ms/step - loss: 1.4183 - accuracy: 0.5091 - val_loss: 1.2498 - val_accuracy: 0.5573\n",
      "Epoch 135/1000\n",
      "48/48 [==============================] - 1s 11ms/step - loss: 1.4293 - accuracy: 0.5052 - val_loss: 1.2501 - val_accuracy: 0.5625\n",
      "Epoch 136/1000\n",
      "48/48 [==============================] - 1s 12ms/step - loss: 1.4290 - accuracy: 0.5182 - val_loss: 1.2438 - val_accuracy: 0.5625\n",
      "Epoch 137/1000\n",
      "48/48 [==============================] - 1s 11ms/step - loss: 1.4064 - accuracy: 0.5065 - val_loss: 1.2450 - val_accuracy: 0.5625\n",
      "Epoch 138/1000\n",
      "48/48 [==============================] - 1s 12ms/step - loss: 1.3682 - accuracy: 0.5326 - val_loss: 1.2460 - val_accuracy: 0.5625\n",
      "Epoch 139/1000\n",
      "48/48 [==============================] - 1s 11ms/step - loss: 1.4062 - accuracy: 0.5339 - val_loss: 1.2416 - val_accuracy: 0.5781\n",
      "Epoch 140/1000\n",
      "48/48 [==============================] - 1s 12ms/step - loss: 1.3923 - accuracy: 0.5339 - val_loss: 1.2412 - val_accuracy: 0.5781\n",
      "Epoch 141/1000\n",
      "48/48 [==============================] - 1s 11ms/step - loss: 1.3726 - accuracy: 0.5208 - val_loss: 1.2340 - val_accuracy: 0.5781\n",
      "Epoch 142/1000\n",
      "48/48 [==============================] - 1s 12ms/step - loss: 1.3747 - accuracy: 0.5286 - val_loss: 1.2330 - val_accuracy: 0.5677\n",
      "Epoch 143/1000\n",
      "48/48 [==============================] - 1s 12ms/step - loss: 1.3608 - accuracy: 0.5312 - val_loss: 1.2324 - val_accuracy: 0.5729\n",
      "Epoch 144/1000\n",
      "48/48 [==============================] - 1s 12ms/step - loss: 1.3763 - accuracy: 0.5352 - val_loss: 1.2256 - val_accuracy: 0.5833\n",
      "Epoch 145/1000\n",
      "48/48 [==============================] - 1s 12ms/step - loss: 1.3819 - accuracy: 0.5156 - val_loss: 1.2258 - val_accuracy: 0.5833\n",
      "Epoch 146/1000\n",
      "48/48 [==============================] - 1s 12ms/step - loss: 1.4012 - accuracy: 0.5234 - val_loss: 1.2236 - val_accuracy: 0.5885\n",
      "Epoch 147/1000\n",
      "48/48 [==============================] - 1s 12ms/step - loss: 1.3835 - accuracy: 0.5378 - val_loss: 1.2213 - val_accuracy: 0.5833\n",
      "Epoch 148/1000\n",
      "48/48 [==============================] - 1s 11ms/step - loss: 1.3574 - accuracy: 0.5339 - val_loss: 1.2161 - val_accuracy: 0.5833\n",
      "Epoch 149/1000\n",
      "48/48 [==============================] - 1s 12ms/step - loss: 1.3905 - accuracy: 0.5326 - val_loss: 1.2115 - val_accuracy: 0.5885\n",
      "Epoch 150/1000\n",
      "48/48 [==============================] - 1s 11ms/step - loss: 1.3731 - accuracy: 0.5247 - val_loss: 1.2061 - val_accuracy: 0.5833\n",
      "Epoch 151/1000\n",
      "48/48 [==============================] - 1s 12ms/step - loss: 1.3600 - accuracy: 0.5312 - val_loss: 1.2078 - val_accuracy: 0.5833\n",
      "Epoch 152/1000\n",
      "48/48 [==============================] - 1s 12ms/step - loss: 1.3490 - accuracy: 0.5456 - val_loss: 1.2003 - val_accuracy: 0.5885\n",
      "Epoch 153/1000\n",
      "48/48 [==============================] - 1s 11ms/step - loss: 1.3745 - accuracy: 0.5404 - val_loss: 1.1973 - val_accuracy: 0.5833\n",
      "Epoch 154/1000\n",
      "48/48 [==============================] - 1s 12ms/step - loss: 1.3962 - accuracy: 0.5365 - val_loss: 1.1942 - val_accuracy: 0.5833\n",
      "Epoch 155/1000\n",
      "48/48 [==============================] - 1s 12ms/step - loss: 1.3630 - accuracy: 0.5339 - val_loss: 1.1926 - val_accuracy: 0.5885\n",
      "Epoch 156/1000\n",
      "48/48 [==============================] - 1s 11ms/step - loss: 1.3168 - accuracy: 0.5521 - val_loss: 1.1909 - val_accuracy: 0.5833\n",
      "Epoch 157/1000\n",
      "48/48 [==============================] - 1s 11ms/step - loss: 1.3000 - accuracy: 0.5703 - val_loss: 1.1923 - val_accuracy: 0.5885\n",
      "Epoch 158/1000\n",
      "48/48 [==============================] - 1s 12ms/step - loss: 1.3268 - accuracy: 0.5547 - val_loss: 1.1889 - val_accuracy: 0.5833\n",
      "Epoch 159/1000\n",
      "48/48 [==============================] - 1s 13ms/step - loss: 1.3434 - accuracy: 0.5430 - val_loss: 1.1870 - val_accuracy: 0.5781\n",
      "Epoch 160/1000\n",
      "48/48 [==============================] - 1s 12ms/step - loss: 1.3291 - accuracy: 0.5521 - val_loss: 1.1858 - val_accuracy: 0.5677\n",
      "Epoch 161/1000\n",
      "48/48 [==============================] - 1s 12ms/step - loss: 1.3198 - accuracy: 0.5404 - val_loss: 1.1800 - val_accuracy: 0.5833\n",
      "Epoch 162/1000\n",
      "48/48 [==============================] - 1s 11ms/step - loss: 1.3586 - accuracy: 0.5456 - val_loss: 1.1775 - val_accuracy: 0.5781\n",
      "Epoch 163/1000\n",
      "48/48 [==============================] - 1s 12ms/step - loss: 1.2958 - accuracy: 0.5690 - val_loss: 1.1719 - val_accuracy: 0.5729\n",
      "Epoch 164/1000\n",
      "48/48 [==============================] - 1s 11ms/step - loss: 1.2870 - accuracy: 0.5599 - val_loss: 1.1711 - val_accuracy: 0.5833\n",
      "Epoch 165/1000\n",
      "48/48 [==============================] - 1s 12ms/step - loss: 1.3056 - accuracy: 0.5638 - val_loss: 1.1706 - val_accuracy: 0.5833\n",
      "Epoch 166/1000\n",
      "48/48 [==============================] - 1s 12ms/step - loss: 1.3177 - accuracy: 0.5508 - val_loss: 1.1696 - val_accuracy: 0.5781\n",
      "Epoch 167/1000\n",
      "48/48 [==============================] - 1s 12ms/step - loss: 1.3288 - accuracy: 0.5456 - val_loss: 1.1678 - val_accuracy: 0.5729\n",
      "Epoch 168/1000\n",
      "48/48 [==============================] - 1s 11ms/step - loss: 1.3195 - accuracy: 0.5299 - val_loss: 1.1603 - val_accuracy: 0.5833\n",
      "Epoch 169/1000\n",
      "48/48 [==============================] - 1s 12ms/step - loss: 1.2918 - accuracy: 0.5820 - val_loss: 1.1571 - val_accuracy: 0.5781\n",
      "Epoch 170/1000\n",
      "48/48 [==============================] - 1s 11ms/step - loss: 1.2574 - accuracy: 0.5794 - val_loss: 1.1502 - val_accuracy: 0.5885\n",
      "Epoch 171/1000\n",
      "48/48 [==============================] - 1s 11ms/step - loss: 1.3144 - accuracy: 0.5482 - val_loss: 1.1446 - val_accuracy: 0.5990\n",
      "Epoch 172/1000\n",
      "48/48 [==============================] - 1s 12ms/step - loss: 1.2848 - accuracy: 0.5482 - val_loss: 1.1419 - val_accuracy: 0.6042\n",
      "Epoch 173/1000\n",
      "48/48 [==============================] - 1s 11ms/step - loss: 1.3306 - accuracy: 0.5716 - val_loss: 1.1439 - val_accuracy: 0.5885\n",
      "Epoch 174/1000\n",
      "48/48 [==============================] - 1s 11ms/step - loss: 1.2736 - accuracy: 0.5729 - val_loss: 1.1421 - val_accuracy: 0.5885\n",
      "Epoch 175/1000\n",
      "48/48 [==============================] - 1s 13ms/step - loss: 1.3007 - accuracy: 0.5521 - val_loss: 1.1395 - val_accuracy: 0.5885\n",
      "Epoch 176/1000\n",
      "48/48 [==============================] - 1s 12ms/step - loss: 1.2627 - accuracy: 0.5807 - val_loss: 1.1356 - val_accuracy: 0.5938\n",
      "Epoch 177/1000\n",
      "48/48 [==============================] - 1s 11ms/step - loss: 1.3204 - accuracy: 0.5573 - val_loss: 1.1359 - val_accuracy: 0.5885\n",
      "Epoch 178/1000\n",
      "48/48 [==============================] - 1s 12ms/step - loss: 1.2885 - accuracy: 0.5651 - val_loss: 1.1337 - val_accuracy: 0.5833\n",
      "Epoch 179/1000\n",
      "48/48 [==============================] - 1s 11ms/step - loss: 1.2370 - accuracy: 0.5768 - val_loss: 1.1282 - val_accuracy: 0.6042\n",
      "Epoch 180/1000\n",
      "48/48 [==============================] - 1s 11ms/step - loss: 1.3089 - accuracy: 0.5508 - val_loss: 1.1302 - val_accuracy: 0.5990\n",
      "Epoch 181/1000\n",
      "48/48 [==============================] - 1s 12ms/step - loss: 1.2572 - accuracy: 0.5846 - val_loss: 1.1298 - val_accuracy: 0.5885\n",
      "Epoch 182/1000\n",
      "48/48 [==============================] - 1s 12ms/step - loss: 1.2535 - accuracy: 0.5859 - val_loss: 1.1252 - val_accuracy: 0.5990\n",
      "Epoch 183/1000\n",
      "48/48 [==============================] - 1s 11ms/step - loss: 1.2834 - accuracy: 0.5729 - val_loss: 1.1247 - val_accuracy: 0.6042\n",
      "Epoch 184/1000\n",
      "48/48 [==============================] - 1s 12ms/step - loss: 1.2456 - accuracy: 0.5716 - val_loss: 1.1207 - val_accuracy: 0.6042\n",
      "Epoch 185/1000\n",
      "48/48 [==============================] - 1s 12ms/step - loss: 1.2751 - accuracy: 0.5729 - val_loss: 1.1127 - val_accuracy: 0.5833\n",
      "Epoch 186/1000\n",
      "48/48 [==============================] - 1s 12ms/step - loss: 1.2746 - accuracy: 0.5729 - val_loss: 1.1140 - val_accuracy: 0.5885\n",
      "Epoch 187/1000\n",
      "48/48 [==============================] - 1s 11ms/step - loss: 1.2421 - accuracy: 0.5807 - val_loss: 1.1107 - val_accuracy: 0.5938\n",
      "Epoch 188/1000\n",
      "48/48 [==============================] - 1s 12ms/step - loss: 1.2412 - accuracy: 0.5859 - val_loss: 1.1109 - val_accuracy: 0.5990\n",
      "Epoch 189/1000\n",
      "48/48 [==============================] - 1s 13ms/step - loss: 1.2140 - accuracy: 0.6068 - val_loss: 1.1080 - val_accuracy: 0.5833\n",
      "Epoch 190/1000\n",
      "48/48 [==============================] - 1s 11ms/step - loss: 1.2609 - accuracy: 0.5612 - val_loss: 1.1040 - val_accuracy: 0.5938\n",
      "Epoch 191/1000\n",
      "48/48 [==============================] - 1s 13ms/step - loss: 1.2090 - accuracy: 0.6042 - val_loss: 1.0988 - val_accuracy: 0.6042\n",
      "Epoch 192/1000\n",
      "48/48 [==============================] - 1s 11ms/step - loss: 1.2328 - accuracy: 0.5885 - val_loss: 1.0961 - val_accuracy: 0.5990\n",
      "Epoch 193/1000\n",
      "48/48 [==============================] - 1s 11ms/step - loss: 1.1672 - accuracy: 0.6042 - val_loss: 1.0964 - val_accuracy: 0.5990\n",
      "Epoch 194/1000\n",
      "48/48 [==============================] - 1s 12ms/step - loss: 1.2811 - accuracy: 0.5508 - val_loss: 1.0917 - val_accuracy: 0.5990\n",
      "Epoch 195/1000\n",
      "48/48 [==============================] - 1s 12ms/step - loss: 1.1873 - accuracy: 0.6289 - val_loss: 1.0905 - val_accuracy: 0.6042\n",
      "Epoch 196/1000\n",
      "48/48 [==============================] - 1s 12ms/step - loss: 1.2047 - accuracy: 0.5885 - val_loss: 1.0895 - val_accuracy: 0.6094\n",
      "Epoch 197/1000\n",
      "48/48 [==============================] - 1s 11ms/step - loss: 1.2304 - accuracy: 0.5807 - val_loss: 1.0868 - val_accuracy: 0.5938\n",
      "Epoch 198/1000\n",
      "48/48 [==============================] - 1s 13ms/step - loss: 1.2104 - accuracy: 0.5977 - val_loss: 1.0862 - val_accuracy: 0.5990\n",
      "Epoch 199/1000\n",
      "48/48 [==============================] - 1s 12ms/step - loss: 1.1994 - accuracy: 0.6042 - val_loss: 1.0846 - val_accuracy: 0.6094\n",
      "Epoch 200/1000\n",
      "48/48 [==============================] - 1s 11ms/step - loss: 1.2476 - accuracy: 0.5742 - val_loss: 1.0822 - val_accuracy: 0.6042\n",
      "Epoch 201/1000\n",
      "48/48 [==============================] - 1s 12ms/step - loss: 1.2452 - accuracy: 0.5534 - val_loss: 1.0839 - val_accuracy: 0.6094\n",
      "Epoch 202/1000\n",
      "48/48 [==============================] - 1s 11ms/step - loss: 1.2098 - accuracy: 0.5846 - val_loss: 1.0809 - val_accuracy: 0.6094\n",
      "Epoch 203/1000\n",
      "48/48 [==============================] - 1s 11ms/step - loss: 1.2158 - accuracy: 0.6055 - val_loss: 1.0790 - val_accuracy: 0.6042\n",
      "Epoch 204/1000\n",
      "48/48 [==============================] - 1s 12ms/step - loss: 1.1670 - accuracy: 0.6172 - val_loss: 1.0771 - val_accuracy: 0.6042\n",
      "Epoch 205/1000\n",
      "48/48 [==============================] - 1s 11ms/step - loss: 1.2391 - accuracy: 0.5833 - val_loss: 1.0749 - val_accuracy: 0.6042\n",
      "Epoch 206/1000\n",
      "48/48 [==============================] - 1s 11ms/step - loss: 1.2048 - accuracy: 0.6068 - val_loss: 1.0723 - val_accuracy: 0.5990\n",
      "Epoch 207/1000\n",
      "48/48 [==============================] - 1s 11ms/step - loss: 1.2037 - accuracy: 0.5846 - val_loss: 1.0723 - val_accuracy: 0.6146\n",
      "Epoch 208/1000\n",
      "48/48 [==============================] - 1s 11ms/step - loss: 1.1708 - accuracy: 0.6055 - val_loss: 1.0718 - val_accuracy: 0.6198\n",
      "Epoch 209/1000\n",
      "48/48 [==============================] - 1s 12ms/step - loss: 1.1902 - accuracy: 0.5768 - val_loss: 1.0698 - val_accuracy: 0.6198\n",
      "Epoch 210/1000\n",
      "48/48 [==============================] - 1s 11ms/step - loss: 1.1612 - accuracy: 0.6159 - val_loss: 1.0716 - val_accuracy: 0.6146\n",
      "Epoch 211/1000\n",
      "48/48 [==============================] - 1s 12ms/step - loss: 1.2074 - accuracy: 0.5807 - val_loss: 1.0660 - val_accuracy: 0.6198\n",
      "Epoch 212/1000\n",
      "48/48 [==============================] - 1s 12ms/step - loss: 1.1668 - accuracy: 0.6016 - val_loss: 1.0620 - val_accuracy: 0.6094\n",
      "Epoch 213/1000\n",
      "48/48 [==============================] - 1s 11ms/step - loss: 1.1957 - accuracy: 0.6211 - val_loss: 1.0620 - val_accuracy: 0.6094\n",
      "Epoch 214/1000\n",
      "48/48 [==============================] - 1s 12ms/step - loss: 1.1766 - accuracy: 0.6146 - val_loss: 1.0629 - val_accuracy: 0.6146\n",
      "Epoch 215/1000\n",
      "48/48 [==============================] - 1s 11ms/step - loss: 1.1679 - accuracy: 0.5951 - val_loss: 1.0620 - val_accuracy: 0.6042\n",
      "Epoch 216/1000\n",
      "48/48 [==============================] - 1s 12ms/step - loss: 1.1373 - accuracy: 0.6289 - val_loss: 1.0574 - val_accuracy: 0.6042\n",
      "Epoch 217/1000\n",
      "48/48 [==============================] - 1s 11ms/step - loss: 1.1805 - accuracy: 0.6133 - val_loss: 1.0566 - val_accuracy: 0.6094\n",
      "Epoch 218/1000\n",
      "48/48 [==============================] - 1s 12ms/step - loss: 1.1449 - accuracy: 0.6081 - val_loss: 1.0574 - val_accuracy: 0.6094\n",
      "Epoch 219/1000\n",
      "48/48 [==============================] - 1s 11ms/step - loss: 1.1772 - accuracy: 0.6081 - val_loss: 1.0570 - val_accuracy: 0.6094\n",
      "Epoch 220/1000\n",
      "48/48 [==============================] - 1s 12ms/step - loss: 1.1610 - accuracy: 0.6081 - val_loss: 1.0553 - val_accuracy: 0.6094\n",
      "Epoch 221/1000\n",
      "48/48 [==============================] - 1s 11ms/step - loss: 1.1421 - accuracy: 0.6159 - val_loss: 1.0543 - val_accuracy: 0.6198\n",
      "Epoch 222/1000\n",
      "48/48 [==============================] - 1s 12ms/step - loss: 1.1199 - accuracy: 0.6393 - val_loss: 1.0512 - val_accuracy: 0.6198\n",
      "Epoch 223/1000\n",
      "48/48 [==============================] - 1s 11ms/step - loss: 1.1391 - accuracy: 0.6107 - val_loss: 1.0499 - val_accuracy: 0.6198\n",
      "Epoch 224/1000\n",
      "48/48 [==============================] - 1s 12ms/step - loss: 1.1094 - accuracy: 0.6328 - val_loss: 1.0461 - val_accuracy: 0.6198\n",
      "Epoch 225/1000\n",
      "48/48 [==============================] - 1s 12ms/step - loss: 1.1296 - accuracy: 0.6198 - val_loss: 1.0446 - val_accuracy: 0.6146\n",
      "Epoch 226/1000\n",
      "48/48 [==============================] - 1s 11ms/step - loss: 1.1111 - accuracy: 0.6263 - val_loss: 1.0403 - val_accuracy: 0.6094\n",
      "Epoch 227/1000\n",
      "48/48 [==============================] - 1s 12ms/step - loss: 1.1126 - accuracy: 0.6406 - val_loss: 1.0382 - val_accuracy: 0.6094\n",
      "Epoch 228/1000\n",
      "48/48 [==============================] - 1s 11ms/step - loss: 1.1347 - accuracy: 0.6172 - val_loss: 1.0380 - val_accuracy: 0.6042\n",
      "Epoch 229/1000\n",
      "48/48 [==============================] - 1s 11ms/step - loss: 1.1622 - accuracy: 0.6120 - val_loss: 1.0355 - val_accuracy: 0.6094\n",
      "Epoch 230/1000\n",
      "48/48 [==============================] - 1s 12ms/step - loss: 1.1024 - accuracy: 0.6445 - val_loss: 1.0368 - val_accuracy: 0.6094\n",
      "Epoch 231/1000\n",
      "48/48 [==============================] - 1s 11ms/step - loss: 1.0866 - accuracy: 0.6589 - val_loss: 1.0389 - val_accuracy: 0.6146\n",
      "Epoch 232/1000\n",
      "48/48 [==============================] - 1s 11ms/step - loss: 1.0862 - accuracy: 0.6276 - val_loss: 1.0420 - val_accuracy: 0.6146\n",
      "Epoch 233/1000\n",
      "48/48 [==============================] - 1s 12ms/step - loss: 1.1343 - accuracy: 0.6354 - val_loss: 1.0382 - val_accuracy: 0.6146\n",
      "Epoch 234/1000\n",
      "48/48 [==============================] - 1s 11ms/step - loss: 1.1273 - accuracy: 0.6094 - val_loss: 1.0388 - val_accuracy: 0.6146\n",
      "Epoch 235/1000\n",
      "48/48 [==============================] - 1s 12ms/step - loss: 1.1326 - accuracy: 0.6263 - val_loss: 1.0337 - val_accuracy: 0.6094\n",
      "Epoch 236/1000\n",
      "48/48 [==============================] - 1s 11ms/step - loss: 1.1407 - accuracy: 0.6055 - val_loss: 1.0320 - val_accuracy: 0.6146\n",
      "Epoch 237/1000\n",
      "48/48 [==============================] - 1s 11ms/step - loss: 1.1107 - accuracy: 0.6328 - val_loss: 1.0305 - val_accuracy: 0.6146\n",
      "Epoch 238/1000\n",
      "48/48 [==============================] - 1s 12ms/step - loss: 1.0894 - accuracy: 0.6237 - val_loss: 1.0308 - val_accuracy: 0.6146\n",
      "Epoch 239/1000\n",
      "48/48 [==============================] - 1s 12ms/step - loss: 1.0793 - accuracy: 0.6602 - val_loss: 1.0304 - val_accuracy: 0.6198\n",
      "Epoch 240/1000\n",
      "48/48 [==============================] - 1s 11ms/step - loss: 1.1315 - accuracy: 0.6055 - val_loss: 1.0263 - val_accuracy: 0.6146\n",
      "Epoch 241/1000\n",
      "48/48 [==============================] - 1s 11ms/step - loss: 1.0792 - accuracy: 0.6393 - val_loss: 1.0245 - val_accuracy: 0.6146\n",
      "Epoch 242/1000\n",
      "48/48 [==============================] - 1s 12ms/step - loss: 1.0918 - accuracy: 0.6458 - val_loss: 1.0232 - val_accuracy: 0.6250\n",
      "Epoch 243/1000\n",
      "48/48 [==============================] - 1s 11ms/step - loss: 1.1396 - accuracy: 0.6146 - val_loss: 1.0201 - val_accuracy: 0.6302\n",
      "Epoch 244/1000\n",
      "48/48 [==============================] - 1s 12ms/step - loss: 1.0694 - accuracy: 0.6380 - val_loss: 1.0162 - val_accuracy: 0.6302\n",
      "Epoch 245/1000\n",
      "48/48 [==============================] - 1s 12ms/step - loss: 1.0825 - accuracy: 0.6341 - val_loss: 1.0154 - val_accuracy: 0.6198\n",
      "Epoch 246/1000\n",
      "48/48 [==============================] - 1s 12ms/step - loss: 1.1249 - accuracy: 0.6276 - val_loss: 1.0123 - val_accuracy: 0.6146\n",
      "Epoch 247/1000\n",
      "48/48 [==============================] - 1s 11ms/step - loss: 1.1532 - accuracy: 0.5924 - val_loss: 1.0122 - val_accuracy: 0.6198\n",
      "Epoch 248/1000\n",
      "48/48 [==============================] - 1s 12ms/step - loss: 1.1048 - accuracy: 0.6263 - val_loss: 1.0091 - val_accuracy: 0.6250\n",
      "Epoch 249/1000\n",
      "48/48 [==============================] - 1s 12ms/step - loss: 1.0578 - accuracy: 0.6680 - val_loss: 1.0023 - val_accuracy: 0.6302\n",
      "Epoch 250/1000\n",
      "48/48 [==============================] - 1s 12ms/step - loss: 1.0817 - accuracy: 0.6497 - val_loss: 1.0030 - val_accuracy: 0.6250\n",
      "Epoch 251/1000\n",
      "48/48 [==============================] - 1s 11ms/step - loss: 1.0922 - accuracy: 0.6406 - val_loss: 1.0037 - val_accuracy: 0.6302\n",
      "Epoch 252/1000\n",
      "48/48 [==============================] - 1s 12ms/step - loss: 1.1251 - accuracy: 0.6328 - val_loss: 1.0014 - val_accuracy: 0.6302\n",
      "Epoch 253/1000\n",
      "48/48 [==============================] - 1s 12ms/step - loss: 1.0866 - accuracy: 0.6315 - val_loss: 1.0011 - val_accuracy: 0.6302\n",
      "Epoch 254/1000\n",
      "48/48 [==============================] - 1s 12ms/step - loss: 1.0838 - accuracy: 0.6380 - val_loss: 1.0004 - val_accuracy: 0.6302\n",
      "Epoch 255/1000\n",
      "48/48 [==============================] - 1s 12ms/step - loss: 1.0949 - accuracy: 0.6432 - val_loss: 0.9983 - val_accuracy: 0.6250\n",
      "Epoch 256/1000\n",
      "48/48 [==============================] - 1s 11ms/step - loss: 1.1028 - accuracy: 0.6107 - val_loss: 0.9989 - val_accuracy: 0.6302\n",
      "Epoch 257/1000\n",
      "48/48 [==============================] - 1s 12ms/step - loss: 1.0477 - accuracy: 0.6602 - val_loss: 0.9973 - val_accuracy: 0.6302\n",
      "Epoch 258/1000\n",
      "48/48 [==============================] - 1s 11ms/step - loss: 1.1404 - accuracy: 0.6172 - val_loss: 0.9938 - val_accuracy: 0.6302\n",
      "Epoch 259/1000\n",
      "48/48 [==============================] - 1s 13ms/step - loss: 1.0411 - accuracy: 0.6771 - val_loss: 0.9914 - val_accuracy: 0.6302\n",
      "Epoch 260/1000\n",
      "48/48 [==============================] - 1s 12ms/step - loss: 1.0683 - accuracy: 0.6562 - val_loss: 0.9924 - val_accuracy: 0.6250\n",
      "Epoch 261/1000\n",
      "48/48 [==============================] - 1s 13ms/step - loss: 1.0531 - accuracy: 0.6458 - val_loss: 0.9916 - val_accuracy: 0.6250\n",
      "Epoch 262/1000\n",
      "48/48 [==============================] - 1s 11ms/step - loss: 1.0867 - accuracy: 0.6263 - val_loss: 0.9939 - val_accuracy: 0.6250\n",
      "Epoch 263/1000\n",
      "48/48 [==============================] - 1s 12ms/step - loss: 1.0820 - accuracy: 0.6393 - val_loss: 0.9896 - val_accuracy: 0.6250\n",
      "Epoch 264/1000\n",
      "48/48 [==============================] - 1s 13ms/step - loss: 1.0813 - accuracy: 0.6458 - val_loss: 0.9873 - val_accuracy: 0.6250\n",
      "Epoch 265/1000\n",
      "48/48 [==============================] - 1s 11ms/step - loss: 1.0892 - accuracy: 0.6406 - val_loss: 0.9858 - val_accuracy: 0.6354\n",
      "Epoch 266/1000\n",
      "48/48 [==============================] - 1s 13ms/step - loss: 1.0389 - accuracy: 0.6562 - val_loss: 0.9824 - val_accuracy: 0.6354\n",
      "Epoch 267/1000\n",
      "48/48 [==============================] - 1s 11ms/step - loss: 1.0562 - accuracy: 0.6406 - val_loss: 0.9811 - val_accuracy: 0.6406\n",
      "Epoch 268/1000\n",
      "48/48 [==============================] - 1s 11ms/step - loss: 1.0842 - accuracy: 0.6328 - val_loss: 0.9780 - val_accuracy: 0.6458\n",
      "Epoch 269/1000\n",
      "48/48 [==============================] - 1s 12ms/step - loss: 1.0903 - accuracy: 0.6328 - val_loss: 0.9766 - val_accuracy: 0.6510\n",
      "Epoch 270/1000\n",
      "48/48 [==============================] - 1s 11ms/step - loss: 1.0541 - accuracy: 0.6536 - val_loss: 0.9748 - val_accuracy: 0.6562\n",
      "Epoch 271/1000\n",
      "48/48 [==============================] - 1s 11ms/step - loss: 1.1116 - accuracy: 0.6250 - val_loss: 0.9720 - val_accuracy: 0.6510\n",
      "Epoch 272/1000\n",
      "48/48 [==============================] - 1s 12ms/step - loss: 1.0467 - accuracy: 0.6758 - val_loss: 0.9718 - val_accuracy: 0.6510\n",
      "Epoch 273/1000\n",
      "48/48 [==============================] - 1s 11ms/step - loss: 1.0381 - accuracy: 0.6719 - val_loss: 0.9754 - val_accuracy: 0.6510\n",
      "Epoch 274/1000\n",
      "48/48 [==============================] - 1s 12ms/step - loss: 1.0377 - accuracy: 0.6719 - val_loss: 0.9717 - val_accuracy: 0.6510\n",
      "Epoch 275/1000\n",
      "48/48 [==============================] - 1s 11ms/step - loss: 0.9993 - accuracy: 0.6589 - val_loss: 0.9706 - val_accuracy: 0.6510\n",
      "Epoch 276/1000\n",
      "48/48 [==============================] - 1s 12ms/step - loss: 1.0314 - accuracy: 0.6523 - val_loss: 0.9681 - val_accuracy: 0.6510\n",
      "Epoch 277/1000\n",
      "48/48 [==============================] - 1s 11ms/step - loss: 1.0162 - accuracy: 0.6549 - val_loss: 0.9697 - val_accuracy: 0.6406\n",
      "Epoch 278/1000\n",
      "48/48 [==============================] - 1s 13ms/step - loss: 1.0127 - accuracy: 0.6263 - val_loss: 0.9694 - val_accuracy: 0.6406\n",
      "Epoch 279/1000\n",
      "48/48 [==============================] - 1s 12ms/step - loss: 1.0441 - accuracy: 0.6380 - val_loss: 0.9680 - val_accuracy: 0.6458\n",
      "Epoch 280/1000\n",
      "48/48 [==============================] - 1s 12ms/step - loss: 1.0130 - accuracy: 0.6693 - val_loss: 0.9697 - val_accuracy: 0.6406\n",
      "Epoch 281/1000\n",
      "48/48 [==============================] - 1s 12ms/step - loss: 1.0328 - accuracy: 0.6510 - val_loss: 0.9664 - val_accuracy: 0.6458\n",
      "Epoch 282/1000\n",
      "48/48 [==============================] - 1s 13ms/step - loss: 1.0177 - accuracy: 0.6719 - val_loss: 0.9635 - val_accuracy: 0.6406\n",
      "Epoch 283/1000\n",
      "48/48 [==============================] - 1s 11ms/step - loss: 1.0139 - accuracy: 0.6680 - val_loss: 0.9616 - val_accuracy: 0.6510\n",
      "Epoch 284/1000\n",
      "48/48 [==============================] - 1s 12ms/step - loss: 0.9912 - accuracy: 0.6758 - val_loss: 0.9594 - val_accuracy: 0.6458\n",
      "Epoch 285/1000\n",
      "48/48 [==============================] - 1s 11ms/step - loss: 1.0146 - accuracy: 0.6719 - val_loss: 0.9593 - val_accuracy: 0.6354\n",
      "Epoch 286/1000\n",
      "48/48 [==============================] - 1s 11ms/step - loss: 1.0244 - accuracy: 0.6862 - val_loss: 0.9622 - val_accuracy: 0.6406\n",
      "Epoch 287/1000\n",
      "48/48 [==============================] - 1s 13ms/step - loss: 1.0277 - accuracy: 0.6641 - val_loss: 0.9574 - val_accuracy: 0.6354\n",
      "Epoch 288/1000\n",
      "48/48 [==============================] - 1s 12ms/step - loss: 1.0295 - accuracy: 0.6510 - val_loss: 0.9562 - val_accuracy: 0.6302\n",
      "Epoch 289/1000\n",
      "48/48 [==============================] - 1s 13ms/step - loss: 1.0268 - accuracy: 0.6628 - val_loss: 0.9558 - val_accuracy: 0.6354\n",
      "Epoch 290/1000\n",
      "48/48 [==============================] - 1s 11ms/step - loss: 1.0326 - accuracy: 0.6602 - val_loss: 0.9544 - val_accuracy: 0.6354\n",
      "Epoch 291/1000\n",
      "48/48 [==============================] - 1s 11ms/step - loss: 1.0080 - accuracy: 0.6771 - val_loss: 0.9506 - val_accuracy: 0.6406\n",
      "Epoch 292/1000\n",
      "48/48 [==============================] - 1s 11ms/step - loss: 1.0215 - accuracy: 0.6745 - val_loss: 0.9510 - val_accuracy: 0.6406\n",
      "Epoch 293/1000\n",
      "48/48 [==============================] - 1s 12ms/step - loss: 1.0192 - accuracy: 0.6732 - val_loss: 0.9518 - val_accuracy: 0.6302\n",
      "Epoch 294/1000\n",
      "48/48 [==============================] - 1s 11ms/step - loss: 0.9867 - accuracy: 0.6641 - val_loss: 0.9518 - val_accuracy: 0.6406\n",
      "Epoch 295/1000\n",
      "48/48 [==============================] - 1s 11ms/step - loss: 1.0429 - accuracy: 0.6484 - val_loss: 0.9498 - val_accuracy: 0.6406\n",
      "Epoch 296/1000\n",
      "48/48 [==============================] - 1s 13ms/step - loss: 1.0536 - accuracy: 0.6484 - val_loss: 0.9459 - val_accuracy: 0.6510\n",
      "Epoch 297/1000\n",
      "48/48 [==============================] - 1s 13ms/step - loss: 1.0267 - accuracy: 0.6667 - val_loss: 0.9438 - val_accuracy: 0.6615\n",
      "Epoch 298/1000\n",
      "48/48 [==============================] - 1s 11ms/step - loss: 0.9900 - accuracy: 0.6862 - val_loss: 0.9418 - val_accuracy: 0.6510\n",
      "Epoch 299/1000\n",
      "48/48 [==============================] - 1s 11ms/step - loss: 0.9803 - accuracy: 0.6784 - val_loss: 0.9406 - val_accuracy: 0.6510\n",
      "Epoch 300/1000\n",
      "48/48 [==============================] - 1s 11ms/step - loss: 0.9420 - accuracy: 0.7031 - val_loss: 0.9404 - val_accuracy: 0.6510\n",
      "Epoch 301/1000\n",
      "48/48 [==============================] - 1s 13ms/step - loss: 0.9912 - accuracy: 0.6667 - val_loss: 0.9404 - val_accuracy: 0.6562\n",
      "Epoch 302/1000\n",
      "48/48 [==============================] - 1s 11ms/step - loss: 0.9810 - accuracy: 0.6706 - val_loss: 0.9427 - val_accuracy: 0.6615\n",
      "Epoch 303/1000\n",
      "48/48 [==============================] - 1s 11ms/step - loss: 0.9710 - accuracy: 0.6732 - val_loss: 0.9449 - val_accuracy: 0.6667\n",
      "Epoch 304/1000\n",
      "48/48 [==============================] - 1s 13ms/step - loss: 0.9986 - accuracy: 0.6471 - val_loss: 0.9381 - val_accuracy: 0.6667\n",
      "Epoch 305/1000\n",
      "48/48 [==============================] - 1s 11ms/step - loss: 0.9860 - accuracy: 0.6927 - val_loss: 0.9390 - val_accuracy: 0.6562\n",
      "Epoch 306/1000\n",
      "48/48 [==============================] - 1s 12ms/step - loss: 0.9571 - accuracy: 0.6849 - val_loss: 0.9378 - val_accuracy: 0.6510\n",
      "Epoch 307/1000\n",
      "48/48 [==============================] - 1s 12ms/step - loss: 0.9756 - accuracy: 0.6914 - val_loss: 0.9365 - val_accuracy: 0.6510\n",
      "Epoch 308/1000\n",
      "48/48 [==============================] - 1s 11ms/step - loss: 0.9657 - accuracy: 0.6914 - val_loss: 0.9388 - val_accuracy: 0.6667\n",
      "Epoch 309/1000\n",
      "48/48 [==============================] - 1s 12ms/step - loss: 0.9333 - accuracy: 0.6758 - val_loss: 0.9347 - val_accuracy: 0.6667\n",
      "Epoch 310/1000\n",
      "48/48 [==============================] - 1s 11ms/step - loss: 0.9538 - accuracy: 0.7018 - val_loss: 0.9367 - val_accuracy: 0.6823\n",
      "Epoch 311/1000\n",
      "48/48 [==============================] - 1s 12ms/step - loss: 1.0024 - accuracy: 0.6719 - val_loss: 0.9341 - val_accuracy: 0.6719\n",
      "Epoch 312/1000\n",
      "48/48 [==============================] - 1s 11ms/step - loss: 0.9875 - accuracy: 0.6953 - val_loss: 0.9308 - val_accuracy: 0.6667\n",
      "Epoch 313/1000\n",
      "48/48 [==============================] - 1s 13ms/step - loss: 1.0021 - accuracy: 0.6654 - val_loss: 0.9313 - val_accuracy: 0.6771\n",
      "Epoch 314/1000\n",
      "48/48 [==============================] - 1s 11ms/step - loss: 0.9771 - accuracy: 0.6914 - val_loss: 0.9289 - val_accuracy: 0.6719\n",
      "Epoch 315/1000\n",
      "48/48 [==============================] - 1s 12ms/step - loss: 0.9705 - accuracy: 0.6836 - val_loss: 0.9284 - val_accuracy: 0.6771\n",
      "Epoch 316/1000\n",
      "48/48 [==============================] - 1s 11ms/step - loss: 0.9904 - accuracy: 0.6849 - val_loss: 0.9264 - val_accuracy: 0.6719\n",
      "Epoch 317/1000\n",
      "48/48 [==============================] - 1s 13ms/step - loss: 0.9628 - accuracy: 0.6953 - val_loss: 0.9233 - val_accuracy: 0.6667\n",
      "Epoch 318/1000\n",
      "48/48 [==============================] - 1s 12ms/step - loss: 0.9644 - accuracy: 0.6888 - val_loss: 0.9218 - val_accuracy: 0.6875\n",
      "Epoch 319/1000\n",
      "48/48 [==============================] - 1s 12ms/step - loss: 0.9421 - accuracy: 0.6966 - val_loss: 0.9179 - val_accuracy: 0.6719\n",
      "Epoch 320/1000\n",
      "48/48 [==============================] - 1s 11ms/step - loss: 0.9099 - accuracy: 0.6940 - val_loss: 0.9172 - val_accuracy: 0.6875\n",
      "Epoch 321/1000\n",
      "48/48 [==============================] - 1s 12ms/step - loss: 0.9782 - accuracy: 0.6745 - val_loss: 0.9157 - val_accuracy: 0.6823\n",
      "Epoch 322/1000\n",
      "48/48 [==============================] - 1s 12ms/step - loss: 0.9298 - accuracy: 0.7214 - val_loss: 0.9200 - val_accuracy: 0.6823\n",
      "Epoch 323/1000\n",
      "48/48 [==============================] - 1s 11ms/step - loss: 0.9838 - accuracy: 0.6654 - val_loss: 0.9185 - val_accuracy: 0.6875\n",
      "Epoch 324/1000\n",
      "48/48 [==============================] - 1s 12ms/step - loss: 0.9472 - accuracy: 0.6953 - val_loss: 0.9185 - val_accuracy: 0.6823\n",
      "Epoch 325/1000\n",
      "48/48 [==============================] - 1s 11ms/step - loss: 0.9339 - accuracy: 0.7005 - val_loss: 0.9139 - val_accuracy: 0.6875\n",
      "Epoch 326/1000\n",
      "48/48 [==============================] - 1s 11ms/step - loss: 0.9184 - accuracy: 0.7161 - val_loss: 0.9141 - val_accuracy: 0.6927\n",
      "Epoch 327/1000\n",
      "48/48 [==============================] - 1s 12ms/step - loss: 0.9398 - accuracy: 0.6810 - val_loss: 0.9098 - val_accuracy: 0.6771\n",
      "Epoch 328/1000\n",
      "48/48 [==============================] - 1s 11ms/step - loss: 0.8992 - accuracy: 0.7161 - val_loss: 0.9067 - val_accuracy: 0.6823\n",
      "Epoch 329/1000\n",
      "48/48 [==============================] - 1s 12ms/step - loss: 0.9569 - accuracy: 0.6771 - val_loss: 0.9052 - val_accuracy: 0.6823\n",
      "Epoch 330/1000\n",
      "48/48 [==============================] - 1s 11ms/step - loss: 0.9697 - accuracy: 0.6979 - val_loss: 0.9006 - val_accuracy: 0.6771\n",
      "Epoch 331/1000\n",
      "48/48 [==============================] - 1s 12ms/step - loss: 0.9402 - accuracy: 0.6914 - val_loss: 0.9013 - val_accuracy: 0.6771\n",
      "Epoch 332/1000\n",
      "48/48 [==============================] - 1s 11ms/step - loss: 0.9539 - accuracy: 0.6927 - val_loss: 0.9027 - val_accuracy: 0.6719\n",
      "Epoch 333/1000\n",
      "48/48 [==============================] - 1s 12ms/step - loss: 0.8960 - accuracy: 0.7070 - val_loss: 0.9048 - val_accuracy: 0.6719\n",
      "Epoch 334/1000\n",
      "48/48 [==============================] - 1s 11ms/step - loss: 0.9445 - accuracy: 0.6641 - val_loss: 0.9070 - val_accuracy: 0.6823\n",
      "Epoch 335/1000\n",
      "48/48 [==============================] - 1s 12ms/step - loss: 0.9393 - accuracy: 0.7005 - val_loss: 0.9067 - val_accuracy: 0.6719\n",
      "Epoch 336/1000\n",
      "48/48 [==============================] - 1s 11ms/step - loss: 0.9699 - accuracy: 0.6797 - val_loss: 0.9086 - val_accuracy: 0.6875\n",
      "Epoch 337/1000\n",
      "48/48 [==============================] - 1s 11ms/step - loss: 0.9225 - accuracy: 0.6836 - val_loss: 0.9050 - val_accuracy: 0.6823\n",
      "Epoch 338/1000\n",
      "48/48 [==============================] - 1s 12ms/step - loss: 0.8968 - accuracy: 0.7148 - val_loss: 0.9055 - val_accuracy: 0.6823\n",
      "Epoch 339/1000\n",
      "48/48 [==============================] - 1s 11ms/step - loss: 0.9295 - accuracy: 0.6992 - val_loss: 0.9043 - val_accuracy: 0.6771\n",
      "Epoch 340/1000\n",
      "48/48 [==============================] - 1s 12ms/step - loss: 0.9035 - accuracy: 0.7174 - val_loss: 0.9055 - val_accuracy: 0.6771\n",
      "Epoch 341/1000\n",
      "48/48 [==============================] - 1s 12ms/step - loss: 0.9113 - accuracy: 0.7214 - val_loss: 0.9004 - val_accuracy: 0.6875\n",
      "Epoch 342/1000\n",
      "48/48 [==============================] - 1s 11ms/step - loss: 0.9139 - accuracy: 0.6745 - val_loss: 0.8980 - val_accuracy: 0.6823\n",
      "Epoch 343/1000\n",
      "48/48 [==============================] - 1s 12ms/step - loss: 0.9133 - accuracy: 0.6940 - val_loss: 0.9030 - val_accuracy: 0.6875\n",
      "Epoch 344/1000\n",
      "48/48 [==============================] - 1s 11ms/step - loss: 0.9130 - accuracy: 0.6979 - val_loss: 0.8983 - val_accuracy: 0.6927\n",
      "Epoch 345/1000\n",
      "48/48 [==============================] - 1s 11ms/step - loss: 0.9464 - accuracy: 0.7018 - val_loss: 0.8974 - val_accuracy: 0.6875\n",
      "Epoch 346/1000\n",
      "48/48 [==============================] - 1s 12ms/step - loss: 0.8970 - accuracy: 0.7096 - val_loss: 0.8980 - val_accuracy: 0.6927\n",
      "Epoch 347/1000\n",
      "48/48 [==============================] - 1s 11ms/step - loss: 0.9146 - accuracy: 0.7044 - val_loss: 0.9021 - val_accuracy: 0.6823\n",
      "Epoch 348/1000\n",
      "48/48 [==============================] - 1s 11ms/step - loss: 0.8800 - accuracy: 0.7227 - val_loss: 0.8991 - val_accuracy: 0.6875\n",
      "Epoch 349/1000\n",
      "48/48 [==============================] - 1s 12ms/step - loss: 0.9251 - accuracy: 0.6940 - val_loss: 0.8964 - val_accuracy: 0.6875\n",
      "Epoch 350/1000\n",
      "48/48 [==============================] - 1s 11ms/step - loss: 0.9061 - accuracy: 0.7031 - val_loss: 0.8984 - val_accuracy: 0.6875\n",
      "Epoch 351/1000\n",
      "48/48 [==============================] - 1s 11ms/step - loss: 0.8789 - accuracy: 0.7253 - val_loss: 0.8996 - val_accuracy: 0.6875\n",
      "Epoch 352/1000\n",
      "48/48 [==============================] - 1s 12ms/step - loss: 0.9199 - accuracy: 0.7148 - val_loss: 0.8952 - val_accuracy: 0.6875\n",
      "Epoch 353/1000\n",
      "48/48 [==============================] - 1s 12ms/step - loss: 0.8721 - accuracy: 0.7148 - val_loss: 0.8910 - val_accuracy: 0.6927\n",
      "Epoch 354/1000\n",
      "48/48 [==============================] - 1s 11ms/step - loss: 0.9399 - accuracy: 0.7044 - val_loss: 0.8898 - val_accuracy: 0.6927\n",
      "Epoch 355/1000\n",
      "48/48 [==============================] - 1s 12ms/step - loss: 0.8772 - accuracy: 0.7370 - val_loss: 0.8898 - val_accuracy: 0.6979\n",
      "Epoch 356/1000\n",
      "48/48 [==============================] - 1s 11ms/step - loss: 0.8844 - accuracy: 0.7174 - val_loss: 0.8881 - val_accuracy: 0.6979\n",
      "Epoch 357/1000\n",
      "48/48 [==============================] - 1s 11ms/step - loss: 0.9269 - accuracy: 0.6849 - val_loss: 0.8875 - val_accuracy: 0.6979\n",
      "Epoch 358/1000\n",
      "48/48 [==============================] - 1s 12ms/step - loss: 0.9355 - accuracy: 0.6940 - val_loss: 0.8856 - val_accuracy: 0.6979\n",
      "Epoch 359/1000\n",
      "48/48 [==============================] - 1s 11ms/step - loss: 0.9422 - accuracy: 0.6914 - val_loss: 0.8845 - val_accuracy: 0.6927\n",
      "Epoch 360/1000\n",
      "48/48 [==============================] - 1s 11ms/step - loss: 0.8912 - accuracy: 0.7122 - val_loss: 0.8837 - val_accuracy: 0.6927\n",
      "Epoch 361/1000\n",
      "48/48 [==============================] - 1s 12ms/step - loss: 0.9062 - accuracy: 0.6979 - val_loss: 0.8844 - val_accuracy: 0.6927\n",
      "Epoch 362/1000\n",
      "48/48 [==============================] - 1s 11ms/step - loss: 0.8937 - accuracy: 0.7083 - val_loss: 0.8875 - val_accuracy: 0.6875\n",
      "Epoch 363/1000\n",
      "48/48 [==============================] - 1s 12ms/step - loss: 0.8793 - accuracy: 0.7096 - val_loss: 0.8880 - val_accuracy: 0.6875\n",
      "Epoch 364/1000\n",
      "48/48 [==============================] - 1s 11ms/step - loss: 0.8658 - accuracy: 0.7214 - val_loss: 0.8851 - val_accuracy: 0.6979\n",
      "Epoch 365/1000\n",
      "48/48 [==============================] - 1s 11ms/step - loss: 0.9480 - accuracy: 0.6680 - val_loss: 0.8816 - val_accuracy: 0.7031\n",
      "Epoch 366/1000\n",
      "48/48 [==============================] - 1s 12ms/step - loss: 0.8731 - accuracy: 0.7214 - val_loss: 0.8799 - val_accuracy: 0.7031\n",
      "Epoch 367/1000\n",
      "48/48 [==============================] - 1s 12ms/step - loss: 0.9123 - accuracy: 0.7057 - val_loss: 0.8770 - val_accuracy: 0.7135\n",
      "Epoch 368/1000\n",
      "48/48 [==============================] - 1s 11ms/step - loss: 0.8617 - accuracy: 0.7409 - val_loss: 0.8763 - val_accuracy: 0.7135\n",
      "Epoch 369/1000\n",
      "48/48 [==============================] - 1s 11ms/step - loss: 0.8654 - accuracy: 0.7292 - val_loss: 0.8789 - val_accuracy: 0.7083\n",
      "Epoch 370/1000\n",
      "48/48 [==============================] - 1s 11ms/step - loss: 0.9106 - accuracy: 0.6966 - val_loss: 0.8777 - val_accuracy: 0.7031\n",
      "Epoch 371/1000\n",
      "48/48 [==============================] - 1s 11ms/step - loss: 0.8819 - accuracy: 0.7109 - val_loss: 0.8798 - val_accuracy: 0.6979\n",
      "Epoch 372/1000\n",
      "48/48 [==============================] - 1s 11ms/step - loss: 0.8884 - accuracy: 0.7018 - val_loss: 0.8826 - val_accuracy: 0.6979\n",
      "Epoch 373/1000\n",
      "48/48 [==============================] - 1s 12ms/step - loss: 0.9053 - accuracy: 0.7148 - val_loss: 0.8810 - val_accuracy: 0.6927\n",
      "Epoch 374/1000\n",
      "48/48 [==============================] - 1s 11ms/step - loss: 0.8863 - accuracy: 0.7174 - val_loss: 0.8762 - val_accuracy: 0.7031\n",
      "Epoch 375/1000\n",
      "48/48 [==============================] - 1s 12ms/step - loss: 0.8766 - accuracy: 0.7396 - val_loss: 0.8736 - val_accuracy: 0.7083\n",
      "Epoch 376/1000\n",
      "48/48 [==============================] - 1s 11ms/step - loss: 0.8427 - accuracy: 0.7292 - val_loss: 0.8726 - val_accuracy: 0.7135\n",
      "Epoch 377/1000\n",
      "48/48 [==============================] - 1s 12ms/step - loss: 0.9035 - accuracy: 0.6771 - val_loss: 0.8747 - val_accuracy: 0.7135\n",
      "Epoch 378/1000\n",
      "48/48 [==============================] - 1s 11ms/step - loss: 0.8524 - accuracy: 0.7109 - val_loss: 0.8761 - val_accuracy: 0.7135\n",
      "Epoch 379/1000\n",
      "48/48 [==============================] - 1s 12ms/step - loss: 0.8796 - accuracy: 0.7227 - val_loss: 0.8772 - val_accuracy: 0.7031\n",
      "Epoch 380/1000\n",
      "48/48 [==============================] - 1s 11ms/step - loss: 0.8777 - accuracy: 0.7109 - val_loss: 0.8742 - val_accuracy: 0.6979\n",
      "Epoch 381/1000\n",
      "48/48 [==============================] - 1s 12ms/step - loss: 0.8773 - accuracy: 0.7188 - val_loss: 0.8718 - val_accuracy: 0.7083\n",
      "Epoch 382/1000\n",
      "48/48 [==============================] - 1s 11ms/step - loss: 0.8372 - accuracy: 0.7435 - val_loss: 0.8717 - val_accuracy: 0.7031\n",
      "Epoch 383/1000\n",
      "48/48 [==============================] - 1s 12ms/step - loss: 0.8801 - accuracy: 0.6992 - val_loss: 0.8649 - val_accuracy: 0.7031\n",
      "Epoch 384/1000\n",
      "48/48 [==============================] - 1s 11ms/step - loss: 0.9039 - accuracy: 0.6992 - val_loss: 0.8659 - val_accuracy: 0.7083\n",
      "Epoch 385/1000\n",
      "48/48 [==============================] - 1s 12ms/step - loss: 0.8837 - accuracy: 0.7005 - val_loss: 0.8662 - val_accuracy: 0.7031\n",
      "Epoch 386/1000\n",
      "48/48 [==============================] - 1s 11ms/step - loss: 0.8731 - accuracy: 0.7109 - val_loss: 0.8628 - val_accuracy: 0.7031\n",
      "Epoch 387/1000\n",
      "48/48 [==============================] - 1s 12ms/step - loss: 0.8704 - accuracy: 0.7057 - val_loss: 0.8642 - val_accuracy: 0.7083\n",
      "Epoch 388/1000\n",
      "48/48 [==============================] - 1s 11ms/step - loss: 0.8752 - accuracy: 0.7096 - val_loss: 0.8654 - val_accuracy: 0.7031\n",
      "Epoch 389/1000\n",
      "48/48 [==============================] - 1s 11ms/step - loss: 0.8818 - accuracy: 0.7174 - val_loss: 0.8659 - val_accuracy: 0.7031\n",
      "Epoch 390/1000\n",
      "48/48 [==============================] - 1s 12ms/step - loss: 0.8429 - accuracy: 0.7122 - val_loss: 0.8681 - val_accuracy: 0.7083\n",
      "Epoch 391/1000\n",
      "48/48 [==============================] - 1s 11ms/step - loss: 0.8623 - accuracy: 0.7083 - val_loss: 0.8665 - val_accuracy: 0.6979\n",
      "Epoch 392/1000\n",
      "48/48 [==============================] - 1s 11ms/step - loss: 0.8654 - accuracy: 0.7383 - val_loss: 0.8640 - val_accuracy: 0.6979\n",
      "Epoch 393/1000\n",
      "48/48 [==============================] - 1s 13ms/step - loss: 0.8759 - accuracy: 0.7122 - val_loss: 0.8622 - val_accuracy: 0.7031\n",
      "Epoch 394/1000\n",
      "48/48 [==============================] - 1s 13ms/step - loss: 0.8914 - accuracy: 0.6914 - val_loss: 0.8614 - val_accuracy: 0.7083\n",
      "Epoch 395/1000\n",
      "48/48 [==============================] - 1s 12ms/step - loss: 0.8754 - accuracy: 0.7096 - val_loss: 0.8607 - val_accuracy: 0.7083\n",
      "Epoch 396/1000\n",
      "48/48 [==============================] - 1s 12ms/step - loss: 0.8117 - accuracy: 0.7578 - val_loss: 0.8618 - val_accuracy: 0.7083\n",
      "Epoch 397/1000\n",
      "48/48 [==============================] - 1s 12ms/step - loss: 0.8298 - accuracy: 0.7292 - val_loss: 0.8599 - val_accuracy: 0.7083\n",
      "Epoch 398/1000\n",
      "48/48 [==============================] - 1s 11ms/step - loss: 0.8531 - accuracy: 0.7318 - val_loss: 0.8598 - val_accuracy: 0.7083\n",
      "Epoch 399/1000\n",
      "48/48 [==============================] - 1s 11ms/step - loss: 0.8064 - accuracy: 0.7513 - val_loss: 0.8616 - val_accuracy: 0.7083\n",
      "Epoch 400/1000\n",
      "48/48 [==============================] - 1s 12ms/step - loss: 0.8536 - accuracy: 0.7096 - val_loss: 0.8623 - val_accuracy: 0.7083\n",
      "Epoch 401/1000\n",
      "48/48 [==============================] - 1s 11ms/step - loss: 0.8210 - accuracy: 0.7500 - val_loss: 0.8559 - val_accuracy: 0.7031\n",
      "Epoch 402/1000\n",
      "48/48 [==============================] - 1s 12ms/step - loss: 0.8448 - accuracy: 0.7188 - val_loss: 0.8540 - val_accuracy: 0.7031\n",
      "Epoch 403/1000\n",
      "48/48 [==============================] - 1s 12ms/step - loss: 0.8261 - accuracy: 0.7448 - val_loss: 0.8559 - val_accuracy: 0.6979\n",
      "Epoch 404/1000\n",
      "48/48 [==============================] - 1s 12ms/step - loss: 0.8615 - accuracy: 0.7305 - val_loss: 0.8573 - val_accuracy: 0.6979\n",
      "Epoch 405/1000\n",
      "48/48 [==============================] - 1s 12ms/step - loss: 0.8069 - accuracy: 0.7591 - val_loss: 0.8538 - val_accuracy: 0.7031\n",
      "Epoch 406/1000\n",
      "48/48 [==============================] - 1s 11ms/step - loss: 0.8095 - accuracy: 0.7643 - val_loss: 0.8522 - val_accuracy: 0.6979\n",
      "Epoch 407/1000\n",
      "48/48 [==============================] - 1s 11ms/step - loss: 0.8682 - accuracy: 0.7083 - val_loss: 0.8527 - val_accuracy: 0.6979\n",
      "Epoch 408/1000\n",
      "48/48 [==============================] - 1s 13ms/step - loss: 0.8045 - accuracy: 0.7435 - val_loss: 0.8523 - val_accuracy: 0.6875\n",
      "Epoch 409/1000\n",
      "48/48 [==============================] - 1s 11ms/step - loss: 0.8273 - accuracy: 0.7409 - val_loss: 0.8536 - val_accuracy: 0.7031\n",
      "Epoch 410/1000\n",
      "48/48 [==============================] - 1s 12ms/step - loss: 0.8232 - accuracy: 0.7331 - val_loss: 0.8528 - val_accuracy: 0.7083\n",
      "Epoch 411/1000\n",
      "48/48 [==============================] - 1s 12ms/step - loss: 0.8202 - accuracy: 0.7565 - val_loss: 0.8522 - val_accuracy: 0.7083\n",
      "Epoch 412/1000\n",
      "48/48 [==============================] - 1s 12ms/step - loss: 0.8367 - accuracy: 0.7214 - val_loss: 0.8489 - val_accuracy: 0.7135\n",
      "Epoch 413/1000\n",
      "48/48 [==============================] - 1s 12ms/step - loss: 0.8228 - accuracy: 0.7474 - val_loss: 0.8470 - val_accuracy: 0.7135\n",
      "Epoch 414/1000\n",
      "48/48 [==============================] - 1s 11ms/step - loss: 0.8491 - accuracy: 0.7253 - val_loss: 0.8485 - val_accuracy: 0.7135\n",
      "Epoch 415/1000\n",
      "48/48 [==============================] - 1s 12ms/step - loss: 0.8590 - accuracy: 0.7227 - val_loss: 0.8473 - val_accuracy: 0.7083\n",
      "Epoch 416/1000\n",
      "48/48 [==============================] - 1s 11ms/step - loss: 0.7935 - accuracy: 0.7370 - val_loss: 0.8453 - val_accuracy: 0.7135\n",
      "Epoch 417/1000\n",
      "48/48 [==============================] - 1s 12ms/step - loss: 0.8810 - accuracy: 0.7135 - val_loss: 0.8413 - val_accuracy: 0.7135\n",
      "Epoch 418/1000\n",
      "48/48 [==============================] - 1s 11ms/step - loss: 0.8428 - accuracy: 0.7357 - val_loss: 0.8395 - val_accuracy: 0.7188\n",
      "Epoch 419/1000\n",
      "48/48 [==============================] - 1s 11ms/step - loss: 0.8077 - accuracy: 0.7435 - val_loss: 0.8377 - val_accuracy: 0.7188\n",
      "Epoch 420/1000\n",
      "48/48 [==============================] - 1s 12ms/step - loss: 0.8304 - accuracy: 0.7409 - val_loss: 0.8347 - val_accuracy: 0.7083\n",
      "Epoch 421/1000\n",
      "48/48 [==============================] - 1s 12ms/step - loss: 0.8067 - accuracy: 0.7643 - val_loss: 0.8326 - val_accuracy: 0.7188\n",
      "Epoch 422/1000\n",
      "48/48 [==============================] - 1s 11ms/step - loss: 0.8033 - accuracy: 0.7448 - val_loss: 0.8355 - val_accuracy: 0.7135\n",
      "Epoch 423/1000\n",
      "48/48 [==============================] - 1s 12ms/step - loss: 0.8519 - accuracy: 0.7448 - val_loss: 0.8374 - val_accuracy: 0.7083\n",
      "Epoch 424/1000\n",
      "48/48 [==============================] - 1s 11ms/step - loss: 0.8567 - accuracy: 0.7214 - val_loss: 0.8345 - val_accuracy: 0.7188\n",
      "Epoch 425/1000\n",
      "48/48 [==============================] - 1s 11ms/step - loss: 0.8095 - accuracy: 0.7500 - val_loss: 0.8308 - val_accuracy: 0.7188\n",
      "Epoch 426/1000\n",
      "48/48 [==============================] - 1s 11ms/step - loss: 0.8240 - accuracy: 0.7370 - val_loss: 0.8327 - val_accuracy: 0.7188\n",
      "Epoch 427/1000\n",
      "48/48 [==============================] - 1s 11ms/step - loss: 0.8075 - accuracy: 0.7539 - val_loss: 0.8333 - val_accuracy: 0.7135\n",
      "Epoch 428/1000\n",
      "48/48 [==============================] - 1s 12ms/step - loss: 0.7957 - accuracy: 0.7474 - val_loss: 0.8319 - val_accuracy: 0.7135\n",
      "Epoch 429/1000\n",
      "48/48 [==============================] - 1s 11ms/step - loss: 0.8345 - accuracy: 0.7279 - val_loss: 0.8346 - val_accuracy: 0.7188\n",
      "Epoch 430/1000\n",
      "48/48 [==============================] - 1s 12ms/step - loss: 0.8301 - accuracy: 0.7174 - val_loss: 0.8360 - val_accuracy: 0.7188\n",
      "Epoch 431/1000\n",
      "48/48 [==============================] - 1s 11ms/step - loss: 0.7955 - accuracy: 0.7305 - val_loss: 0.8385 - val_accuracy: 0.7135\n",
      "Epoch 432/1000\n",
      "48/48 [==============================] - 1s 11ms/step - loss: 0.8099 - accuracy: 0.7448 - val_loss: 0.8412 - val_accuracy: 0.7083\n",
      "Epoch 433/1000\n",
      "48/48 [==============================] - 1s 12ms/step - loss: 0.8235 - accuracy: 0.7344 - val_loss: 0.8423 - val_accuracy: 0.7031\n",
      "Epoch 434/1000\n",
      "48/48 [==============================] - 1s 11ms/step - loss: 0.7872 - accuracy: 0.7409 - val_loss: 0.8408 - val_accuracy: 0.7135\n",
      "Epoch 435/1000\n",
      "48/48 [==============================] - 1s 12ms/step - loss: 0.8125 - accuracy: 0.7422 - val_loss: 0.8415 - val_accuracy: 0.7031\n",
      "Epoch 436/1000\n",
      "48/48 [==============================] - 1s 11ms/step - loss: 0.7989 - accuracy: 0.7539 - val_loss: 0.8431 - val_accuracy: 0.7083\n",
      "Epoch 437/1000\n",
      "48/48 [==============================] - 1s 12ms/step - loss: 0.7318 - accuracy: 0.7812 - val_loss: 0.8428 - val_accuracy: 0.7135\n",
      "Epoch 438/1000\n",
      "48/48 [==============================] - 1s 11ms/step - loss: 0.8192 - accuracy: 0.7422 - val_loss: 0.8404 - val_accuracy: 0.6979\n",
      "Epoch 439/1000\n",
      "48/48 [==============================] - 1s 11ms/step - loss: 0.8446 - accuracy: 0.7227 - val_loss: 0.8337 - val_accuracy: 0.7083\n",
      "Epoch 440/1000\n",
      "48/48 [==============================] - 1s 12ms/step - loss: 0.7633 - accuracy: 0.7578 - val_loss: 0.8351 - val_accuracy: 0.7135\n",
      "Epoch 441/1000\n",
      "48/48 [==============================] - 1s 11ms/step - loss: 0.7528 - accuracy: 0.7682 - val_loss: 0.8341 - val_accuracy: 0.7188\n",
      "Epoch 442/1000\n",
      "48/48 [==============================] - 1s 12ms/step - loss: 0.8140 - accuracy: 0.7513 - val_loss: 0.8342 - val_accuracy: 0.7188\n",
      "Epoch 443/1000\n",
      "48/48 [==============================] - 1s 12ms/step - loss: 0.7885 - accuracy: 0.7409 - val_loss: 0.8346 - val_accuracy: 0.7240\n",
      "Epoch 444/1000\n",
      "48/48 [==============================] - 1s 12ms/step - loss: 0.7986 - accuracy: 0.7474 - val_loss: 0.8332 - val_accuracy: 0.7188\n",
      "Epoch 445/1000\n",
      "48/48 [==============================] - 1s 11ms/step - loss: 0.7725 - accuracy: 0.7448 - val_loss: 0.8331 - val_accuracy: 0.7188\n",
      "Epoch 446/1000\n",
      "48/48 [==============================] - 1s 12ms/step - loss: 0.7763 - accuracy: 0.7500 - val_loss: 0.8309 - val_accuracy: 0.7240\n",
      "Epoch 447/1000\n",
      "48/48 [==============================] - 1s 11ms/step - loss: 0.7851 - accuracy: 0.7474 - val_loss: 0.8324 - val_accuracy: 0.7240\n",
      "Epoch 448/1000\n",
      "48/48 [==============================] - 1s 11ms/step - loss: 0.7470 - accuracy: 0.7773 - val_loss: 0.8351 - val_accuracy: 0.7135\n",
      "Epoch 449/1000\n",
      "48/48 [==============================] - 1s 12ms/step - loss: 0.7877 - accuracy: 0.7578 - val_loss: 0.8329 - val_accuracy: 0.7188\n",
      "Epoch 450/1000\n",
      "48/48 [==============================] - 1s 11ms/step - loss: 0.8289 - accuracy: 0.7266 - val_loss: 0.8295 - val_accuracy: 0.7135\n",
      "Epoch 451/1000\n",
      "48/48 [==============================] - 1s 12ms/step - loss: 0.7868 - accuracy: 0.7500 - val_loss: 0.8306 - val_accuracy: 0.7083\n",
      "Epoch 452/1000\n",
      "48/48 [==============================] - 1s 12ms/step - loss: 0.7675 - accuracy: 0.7656 - val_loss: 0.8291 - val_accuracy: 0.7083\n",
      "Epoch 453/1000\n",
      "48/48 [==============================] - 1s 13ms/step - loss: 0.7917 - accuracy: 0.7370 - val_loss: 0.8296 - val_accuracy: 0.7135\n",
      "Epoch 454/1000\n",
      "48/48 [==============================] - 1s 12ms/step - loss: 0.7861 - accuracy: 0.7539 - val_loss: 0.8286 - val_accuracy: 0.7135\n",
      "Epoch 455/1000\n",
      "48/48 [==============================] - 1s 12ms/step - loss: 0.7314 - accuracy: 0.7617 - val_loss: 0.8256 - val_accuracy: 0.7188\n",
      "Epoch 456/1000\n",
      "48/48 [==============================] - 1s 13ms/step - loss: 0.8101 - accuracy: 0.7422 - val_loss: 0.8222 - val_accuracy: 0.7188\n",
      "Epoch 457/1000\n",
      "48/48 [==============================] - 1s 12ms/step - loss: 0.7674 - accuracy: 0.7617 - val_loss: 0.8210 - val_accuracy: 0.7240\n",
      "Epoch 458/1000\n",
      "48/48 [==============================] - 1s 12ms/step - loss: 0.7516 - accuracy: 0.7617 - val_loss: 0.8179 - val_accuracy: 0.7240\n",
      "Epoch 459/1000\n",
      "48/48 [==============================] - 1s 12ms/step - loss: 0.7751 - accuracy: 0.7734 - val_loss: 0.8194 - val_accuracy: 0.7188\n",
      "Epoch 460/1000\n",
      "48/48 [==============================] - 1s 12ms/step - loss: 0.7634 - accuracy: 0.7591 - val_loss: 0.8140 - val_accuracy: 0.7240\n",
      "Epoch 461/1000\n",
      "48/48 [==============================] - 1s 12ms/step - loss: 0.7524 - accuracy: 0.7630 - val_loss: 0.8158 - val_accuracy: 0.7188\n",
      "Epoch 462/1000\n",
      "48/48 [==============================] - 1s 11ms/step - loss: 0.8273 - accuracy: 0.7526 - val_loss: 0.8151 - val_accuracy: 0.7083\n",
      "Epoch 463/1000\n",
      "48/48 [==============================] - 1s 12ms/step - loss: 0.7591 - accuracy: 0.7487 - val_loss: 0.8166 - val_accuracy: 0.7135\n",
      "Epoch 464/1000\n",
      "48/48 [==============================] - 1s 11ms/step - loss: 0.7869 - accuracy: 0.7409 - val_loss: 0.8146 - val_accuracy: 0.7188\n",
      "Epoch 465/1000\n",
      "48/48 [==============================] - 1s 12ms/step - loss: 0.7414 - accuracy: 0.7617 - val_loss: 0.8159 - val_accuracy: 0.7292\n",
      "Epoch 466/1000\n",
      "48/48 [==============================] - 1s 11ms/step - loss: 0.7479 - accuracy: 0.7539 - val_loss: 0.8140 - val_accuracy: 0.7292\n",
      "Epoch 467/1000\n",
      "48/48 [==============================] - 1s 12ms/step - loss: 0.7457 - accuracy: 0.7604 - val_loss: 0.8133 - val_accuracy: 0.7188\n",
      "Epoch 468/1000\n",
      "48/48 [==============================] - 1s 12ms/step - loss: 0.7926 - accuracy: 0.7383 - val_loss: 0.8133 - val_accuracy: 0.7188\n",
      "Epoch 469/1000\n",
      "48/48 [==============================] - 1s 11ms/step - loss: 0.7429 - accuracy: 0.7904 - val_loss: 0.8105 - val_accuracy: 0.7240\n",
      "Epoch 470/1000\n",
      "48/48 [==============================] - 1s 13ms/step - loss: 0.7591 - accuracy: 0.7526 - val_loss: 0.8081 - val_accuracy: 0.7188\n",
      "Epoch 471/1000\n",
      "48/48 [==============================] - 1s 12ms/step - loss: 0.7908 - accuracy: 0.7474 - val_loss: 0.8067 - val_accuracy: 0.7188\n",
      "Epoch 472/1000\n",
      "48/48 [==============================] - 1s 12ms/step - loss: 0.7990 - accuracy: 0.7266 - val_loss: 0.8117 - val_accuracy: 0.7135\n",
      "Epoch 473/1000\n",
      "48/48 [==============================] - 1s 11ms/step - loss: 0.7371 - accuracy: 0.7799 - val_loss: 0.8128 - val_accuracy: 0.7135\n",
      "Epoch 474/1000\n",
      "48/48 [==============================] - 1s 12ms/step - loss: 0.7691 - accuracy: 0.7669 - val_loss: 0.8124 - val_accuracy: 0.7188\n",
      "Epoch 475/1000\n",
      "48/48 [==============================] - 1s 12ms/step - loss: 0.7603 - accuracy: 0.7578 - val_loss: 0.8112 - val_accuracy: 0.7240\n",
      "Epoch 476/1000\n",
      "48/48 [==============================] - 1s 12ms/step - loss: 0.7919 - accuracy: 0.7500 - val_loss: 0.8055 - val_accuracy: 0.7240\n",
      "Epoch 477/1000\n",
      "48/48 [==============================] - 1s 12ms/step - loss: 0.7271 - accuracy: 0.7643 - val_loss: 0.8058 - val_accuracy: 0.7240\n",
      "Epoch 478/1000\n",
      "48/48 [==============================] - 1s 12ms/step - loss: 0.7116 - accuracy: 0.7891 - val_loss: 0.8048 - val_accuracy: 0.7188\n",
      "Epoch 479/1000\n",
      "48/48 [==============================] - 1s 12ms/step - loss: 0.7711 - accuracy: 0.7734 - val_loss: 0.7996 - val_accuracy: 0.7188\n",
      "Epoch 480/1000\n",
      "48/48 [==============================] - 1s 13ms/step - loss: 0.7221 - accuracy: 0.7747 - val_loss: 0.8033 - val_accuracy: 0.7240\n",
      "Epoch 481/1000\n",
      "48/48 [==============================] - 1s 12ms/step - loss: 0.7701 - accuracy: 0.7578 - val_loss: 0.8020 - val_accuracy: 0.7188\n",
      "Epoch 482/1000\n",
      "48/48 [==============================] - 1s 12ms/step - loss: 0.7588 - accuracy: 0.7669 - val_loss: 0.8035 - val_accuracy: 0.7240\n",
      "Epoch 483/1000\n",
      "48/48 [==============================] - 1s 13ms/step - loss: 0.7745 - accuracy: 0.7435 - val_loss: 0.8057 - val_accuracy: 0.7240\n",
      "Epoch 484/1000\n",
      "48/48 [==============================] - 1s 11ms/step - loss: 0.7282 - accuracy: 0.7695 - val_loss: 0.8054 - val_accuracy: 0.7240\n",
      "Epoch 485/1000\n",
      "48/48 [==============================] - 1s 13ms/step - loss: 0.7615 - accuracy: 0.7526 - val_loss: 0.8076 - val_accuracy: 0.7240\n",
      "Epoch 486/1000\n",
      "48/48 [==============================] - 1s 11ms/step - loss: 0.7597 - accuracy: 0.7604 - val_loss: 0.8080 - val_accuracy: 0.7240\n",
      "Epoch 487/1000\n",
      "48/48 [==============================] - 1s 11ms/step - loss: 0.7548 - accuracy: 0.7630 - val_loss: 0.8066 - val_accuracy: 0.7240\n",
      "Epoch 488/1000\n",
      "48/48 [==============================] - 1s 10ms/step - loss: 0.7017 - accuracy: 0.7786 - val_loss: 0.8016 - val_accuracy: 0.7240\n",
      "Epoch 489/1000\n",
      "48/48 [==============================] - 1s 10ms/step - loss: 0.6992 - accuracy: 0.7734 - val_loss: 0.8016 - val_accuracy: 0.7292\n",
      "Epoch 490/1000\n",
      "48/48 [==============================] - 1s 11ms/step - loss: 0.7579 - accuracy: 0.7721 - val_loss: 0.8048 - val_accuracy: 0.7292\n",
      "Epoch 491/1000\n",
      "48/48 [==============================] - 0s 9ms/step - loss: 0.7511 - accuracy: 0.7604 - val_loss: 0.8000 - val_accuracy: 0.7344\n",
      "Epoch 492/1000\n",
      "48/48 [==============================] - 0s 10ms/step - loss: 0.7227 - accuracy: 0.7812 - val_loss: 0.7995 - val_accuracy: 0.7292\n",
      "Epoch 493/1000\n",
      "48/48 [==============================] - 0s 9ms/step - loss: 0.7070 - accuracy: 0.7799 - val_loss: 0.8000 - val_accuracy: 0.7344\n",
      "Epoch 494/1000\n",
      "48/48 [==============================] - 0s 10ms/step - loss: 0.7570 - accuracy: 0.7617 - val_loss: 0.8000 - val_accuracy: 0.7448\n",
      "Epoch 495/1000\n",
      "48/48 [==============================] - 1s 11ms/step - loss: 0.7498 - accuracy: 0.7591 - val_loss: 0.8034 - val_accuracy: 0.7396\n",
      "Epoch 496/1000\n",
      "48/48 [==============================] - 0s 10ms/step - loss: 0.7304 - accuracy: 0.7604 - val_loss: 0.8037 - val_accuracy: 0.7396\n",
      "Epoch 497/1000\n",
      "48/48 [==============================] - 0s 10ms/step - loss: 0.7127 - accuracy: 0.7695 - val_loss: 0.8009 - val_accuracy: 0.7344\n",
      "Epoch 498/1000\n",
      "48/48 [==============================] - 1s 11ms/step - loss: 0.7880 - accuracy: 0.7656 - val_loss: 0.8038 - val_accuracy: 0.7292\n",
      "Epoch 499/1000\n",
      "48/48 [==============================] - 0s 10ms/step - loss: 0.7507 - accuracy: 0.7826 - val_loss: 0.8016 - val_accuracy: 0.7292\n",
      "Epoch 500/1000\n",
      "48/48 [==============================] - 1s 11ms/step - loss: 0.7249 - accuracy: 0.7904 - val_loss: 0.8042 - val_accuracy: 0.7292\n",
      "Epoch 501/1000\n",
      "48/48 [==============================] - 0s 10ms/step - loss: 0.7386 - accuracy: 0.7643 - val_loss: 0.8055 - val_accuracy: 0.7240\n",
      "Epoch 502/1000\n",
      "48/48 [==============================] - 0s 10ms/step - loss: 0.7070 - accuracy: 0.7786 - val_loss: 0.8092 - val_accuracy: 0.7135\n",
      "Epoch 503/1000\n",
      "48/48 [==============================] - 1s 11ms/step - loss: 0.7319 - accuracy: 0.7786 - val_loss: 0.8118 - val_accuracy: 0.7188\n",
      "Epoch 504/1000\n",
      "48/48 [==============================] - 0s 10ms/step - loss: 0.7380 - accuracy: 0.7721 - val_loss: 0.8091 - val_accuracy: 0.7240\n",
      "Epoch 505/1000\n",
      "48/48 [==============================] - 0s 10ms/step - loss: 0.6881 - accuracy: 0.7812 - val_loss: 0.8070 - val_accuracy: 0.7240\n",
      "Epoch 506/1000\n",
      "48/48 [==============================] - 1s 11ms/step - loss: 0.7442 - accuracy: 0.7734 - val_loss: 0.8086 - val_accuracy: 0.7135\n",
      "Epoch 507/1000\n",
      "48/48 [==============================] - 0s 10ms/step - loss: 0.7040 - accuracy: 0.7839 - val_loss: 0.8052 - val_accuracy: 0.7188\n",
      "Epoch 508/1000\n",
      "48/48 [==============================] - 1s 10ms/step - loss: 0.7507 - accuracy: 0.7552 - val_loss: 0.8056 - val_accuracy: 0.7292\n",
      "Epoch 509/1000\n",
      "48/48 [==============================] - 0s 10ms/step - loss: 0.7350 - accuracy: 0.7799 - val_loss: 0.8022 - val_accuracy: 0.7240\n",
      "Epoch 510/1000\n",
      "48/48 [==============================] - 1s 11ms/step - loss: 0.7056 - accuracy: 0.7734 - val_loss: 0.8022 - val_accuracy: 0.7240\n",
      "Epoch 511/1000\n",
      "48/48 [==============================] - 0s 10ms/step - loss: 0.6943 - accuracy: 0.7852 - val_loss: 0.8003 - val_accuracy: 0.7240\n",
      "Epoch 512/1000\n",
      "48/48 [==============================] - 1s 11ms/step - loss: 0.6735 - accuracy: 0.7956 - val_loss: 0.8006 - val_accuracy: 0.7292\n",
      "Epoch 513/1000\n",
      "48/48 [==============================] - 0s 10ms/step - loss: 0.7248 - accuracy: 0.7656 - val_loss: 0.8004 - val_accuracy: 0.7240\n",
      "Epoch 514/1000\n",
      "48/48 [==============================] - 1s 11ms/step - loss: 0.7528 - accuracy: 0.7617 - val_loss: 0.7980 - val_accuracy: 0.7240\n",
      "Epoch 515/1000\n",
      "48/48 [==============================] - 0s 10ms/step - loss: 0.6940 - accuracy: 0.7839 - val_loss: 0.7984 - val_accuracy: 0.7240\n",
      "Epoch 516/1000\n",
      "48/48 [==============================] - 1s 11ms/step - loss: 0.6864 - accuracy: 0.7930 - val_loss: 0.7996 - val_accuracy: 0.7292\n",
      "Epoch 517/1000\n",
      "48/48 [==============================] - 0s 10ms/step - loss: 0.6725 - accuracy: 0.8086 - val_loss: 0.7999 - val_accuracy: 0.7292\n",
      "Epoch 518/1000\n",
      "48/48 [==============================] - 1s 12ms/step - loss: 0.6803 - accuracy: 0.8021 - val_loss: 0.7974 - val_accuracy: 0.7240\n",
      "Epoch 519/1000\n",
      "48/48 [==============================] - 1s 10ms/step - loss: 0.6953 - accuracy: 0.7799 - val_loss: 0.7972 - val_accuracy: 0.7292\n",
      "Epoch 520/1000\n",
      "48/48 [==============================] - 1s 11ms/step - loss: 0.7451 - accuracy: 0.7526 - val_loss: 0.7969 - val_accuracy: 0.7188\n",
      "Epoch 521/1000\n",
      "48/48 [==============================] - 0s 11ms/step - loss: 0.7079 - accuracy: 0.7826 - val_loss: 0.7976 - val_accuracy: 0.7292\n",
      "Epoch 522/1000\n",
      "48/48 [==============================] - 1s 11ms/step - loss: 0.7378 - accuracy: 0.7708 - val_loss: 0.7962 - val_accuracy: 0.7240\n",
      "Epoch 523/1000\n",
      "48/48 [==============================] - 1s 13ms/step - loss: 0.7429 - accuracy: 0.7812 - val_loss: 0.7947 - val_accuracy: 0.7188\n",
      "Epoch 524/1000\n",
      "48/48 [==============================] - 1s 12ms/step - loss: 0.6913 - accuracy: 0.7982 - val_loss: 0.7943 - val_accuracy: 0.7188\n",
      "Epoch 525/1000\n",
      "48/48 [==============================] - 1s 11ms/step - loss: 0.6962 - accuracy: 0.8099 - val_loss: 0.7923 - val_accuracy: 0.7188\n",
      "Epoch 526/1000\n",
      "48/48 [==============================] - 0s 10ms/step - loss: 0.6965 - accuracy: 0.7917 - val_loss: 0.7925 - val_accuracy: 0.7188\n",
      "Epoch 527/1000\n",
      "48/48 [==============================] - 0s 10ms/step - loss: 0.7334 - accuracy: 0.7695 - val_loss: 0.7952 - val_accuracy: 0.7188\n",
      "Epoch 528/1000\n",
      "48/48 [==============================] - 1s 10ms/step - loss: 0.6573 - accuracy: 0.7943 - val_loss: 0.7950 - val_accuracy: 0.7188\n",
      "Epoch 529/1000\n",
      "48/48 [==============================] - 1s 11ms/step - loss: 0.6949 - accuracy: 0.7760 - val_loss: 0.7941 - val_accuracy: 0.7240\n",
      "Epoch 530/1000\n",
      "48/48 [==============================] - 1s 12ms/step - loss: 0.6865 - accuracy: 0.7982 - val_loss: 0.7942 - val_accuracy: 0.7292\n",
      "Epoch 531/1000\n",
      "48/48 [==============================] - 1s 11ms/step - loss: 0.6622 - accuracy: 0.8294 - val_loss: 0.7932 - val_accuracy: 0.7344\n",
      "Epoch 532/1000\n",
      "48/48 [==============================] - 1s 11ms/step - loss: 0.6871 - accuracy: 0.7891 - val_loss: 0.7918 - val_accuracy: 0.7240\n",
      "Epoch 533/1000\n",
      "48/48 [==============================] - 1s 11ms/step - loss: 0.6446 - accuracy: 0.7982 - val_loss: 0.7929 - val_accuracy: 0.7240\n",
      "Epoch 534/1000\n",
      "48/48 [==============================] - 1s 11ms/step - loss: 0.6667 - accuracy: 0.7878 - val_loss: 0.7903 - val_accuracy: 0.7188\n",
      "Epoch 535/1000\n",
      "48/48 [==============================] - 1s 12ms/step - loss: 0.6512 - accuracy: 0.8008 - val_loss: 0.7896 - val_accuracy: 0.7083\n",
      "Epoch 536/1000\n",
      "48/48 [==============================] - 1s 11ms/step - loss: 0.7021 - accuracy: 0.7904 - val_loss: 0.7886 - val_accuracy: 0.7135\n",
      "Epoch 537/1000\n",
      "48/48 [==============================] - 1s 12ms/step - loss: 0.6693 - accuracy: 0.7826 - val_loss: 0.7855 - val_accuracy: 0.7240\n",
      "Epoch 538/1000\n",
      "48/48 [==============================] - 1s 11ms/step - loss: 0.7009 - accuracy: 0.7852 - val_loss: 0.7907 - val_accuracy: 0.7240\n",
      "Epoch 539/1000\n",
      "48/48 [==============================] - 1s 12ms/step - loss: 0.6407 - accuracy: 0.8112 - val_loss: 0.7925 - val_accuracy: 0.7188\n",
      "Epoch 540/1000\n",
      "48/48 [==============================] - 1s 11ms/step - loss: 0.7191 - accuracy: 0.7747 - val_loss: 0.7892 - val_accuracy: 0.7240\n",
      "Epoch 541/1000\n",
      "48/48 [==============================] - 1s 12ms/step - loss: 0.6711 - accuracy: 0.7865 - val_loss: 0.7873 - val_accuracy: 0.7240\n",
      "Epoch 542/1000\n",
      "48/48 [==============================] - 1s 12ms/step - loss: 0.6540 - accuracy: 0.8073 - val_loss: 0.7860 - val_accuracy: 0.7292\n",
      "Epoch 543/1000\n",
      "48/48 [==============================] - 1s 11ms/step - loss: 0.6991 - accuracy: 0.8034 - val_loss: 0.7853 - val_accuracy: 0.7396\n",
      "Epoch 544/1000\n",
      "48/48 [==============================] - 1s 12ms/step - loss: 0.6763 - accuracy: 0.7839 - val_loss: 0.7869 - val_accuracy: 0.7344\n",
      "Epoch 545/1000\n",
      "48/48 [==============================] - 1s 13ms/step - loss: 0.6766 - accuracy: 0.7982 - val_loss: 0.7859 - val_accuracy: 0.7344\n",
      "Epoch 546/1000\n",
      "48/48 [==============================] - 1s 11ms/step - loss: 0.6651 - accuracy: 0.7930 - val_loss: 0.7845 - val_accuracy: 0.7344\n",
      "Epoch 547/1000\n",
      "48/48 [==============================] - 1s 11ms/step - loss: 0.6882 - accuracy: 0.7904 - val_loss: 0.7860 - val_accuracy: 0.7344\n",
      "Epoch 548/1000\n",
      "48/48 [==============================] - 1s 11ms/step - loss: 0.6728 - accuracy: 0.7917 - val_loss: 0.7857 - val_accuracy: 0.7292\n",
      "Epoch 549/1000\n",
      "48/48 [==============================] - 1s 11ms/step - loss: 0.6795 - accuracy: 0.8047 - val_loss: 0.7890 - val_accuracy: 0.7292\n",
      "Epoch 550/1000\n",
      "48/48 [==============================] - 1s 11ms/step - loss: 0.6660 - accuracy: 0.7760 - val_loss: 0.7915 - val_accuracy: 0.7292\n",
      "Epoch 551/1000\n",
      "48/48 [==============================] - 1s 11ms/step - loss: 0.6951 - accuracy: 0.7891 - val_loss: 0.7863 - val_accuracy: 0.7344\n",
      "Epoch 552/1000\n",
      "48/48 [==============================] - 1s 12ms/step - loss: 0.6862 - accuracy: 0.8021 - val_loss: 0.7849 - val_accuracy: 0.7344\n",
      "Epoch 553/1000\n",
      "48/48 [==============================] - 1s 12ms/step - loss: 0.6551 - accuracy: 0.8034 - val_loss: 0.7811 - val_accuracy: 0.7396\n",
      "Epoch 554/1000\n",
      "48/48 [==============================] - 1s 12ms/step - loss: 0.6953 - accuracy: 0.7812 - val_loss: 0.7852 - val_accuracy: 0.7344\n",
      "Epoch 555/1000\n",
      "48/48 [==============================] - 1s 12ms/step - loss: 0.6614 - accuracy: 0.8047 - val_loss: 0.7862 - val_accuracy: 0.7344\n",
      "Epoch 556/1000\n",
      "48/48 [==============================] - 1s 12ms/step - loss: 0.7024 - accuracy: 0.7799 - val_loss: 0.7835 - val_accuracy: 0.7240\n",
      "Epoch 557/1000\n",
      "48/48 [==============================] - 1s 12ms/step - loss: 0.6423 - accuracy: 0.8151 - val_loss: 0.7829 - val_accuracy: 0.7344\n",
      "Epoch 558/1000\n",
      "48/48 [==============================] - 1s 11ms/step - loss: 0.6962 - accuracy: 0.7878 - val_loss: 0.7869 - val_accuracy: 0.7240\n",
      "Epoch 559/1000\n",
      "48/48 [==============================] - 1s 13ms/step - loss: 0.6498 - accuracy: 0.7982 - val_loss: 0.7800 - val_accuracy: 0.7344\n",
      "Epoch 560/1000\n",
      "48/48 [==============================] - 1s 11ms/step - loss: 0.6876 - accuracy: 0.7943 - val_loss: 0.7834 - val_accuracy: 0.7188\n",
      "Epoch 561/1000\n",
      "48/48 [==============================] - 1s 11ms/step - loss: 0.6724 - accuracy: 0.8073 - val_loss: 0.7811 - val_accuracy: 0.7292\n",
      "Epoch 562/1000\n",
      "48/48 [==============================] - 1s 12ms/step - loss: 0.6683 - accuracy: 0.8060 - val_loss: 0.7818 - val_accuracy: 0.7135\n",
      "Epoch 563/1000\n",
      "48/48 [==============================] - 1s 12ms/step - loss: 0.6914 - accuracy: 0.7708 - val_loss: 0.7811 - val_accuracy: 0.7292\n",
      "Epoch 564/1000\n",
      "48/48 [==============================] - 1s 12ms/step - loss: 0.6590 - accuracy: 0.8073 - val_loss: 0.7791 - val_accuracy: 0.7240\n",
      "Epoch 565/1000\n",
      "48/48 [==============================] - 1s 13ms/step - loss: 0.6528 - accuracy: 0.8086 - val_loss: 0.7776 - val_accuracy: 0.7240\n",
      "Epoch 566/1000\n",
      "48/48 [==============================] - 1s 12ms/step - loss: 0.6809 - accuracy: 0.7734 - val_loss: 0.7793 - val_accuracy: 0.7240\n",
      "Epoch 567/1000\n",
      "48/48 [==============================] - 1s 13ms/step - loss: 0.6353 - accuracy: 0.8060 - val_loss: 0.7763 - val_accuracy: 0.7240\n",
      "Epoch 568/1000\n",
      "48/48 [==============================] - 1s 12ms/step - loss: 0.6439 - accuracy: 0.8034 - val_loss: 0.7740 - val_accuracy: 0.7240\n",
      "Epoch 569/1000\n",
      "48/48 [==============================] - 1s 12ms/step - loss: 0.6779 - accuracy: 0.7812 - val_loss: 0.7784 - val_accuracy: 0.7240\n",
      "Epoch 570/1000\n",
      "48/48 [==============================] - 1s 12ms/step - loss: 0.6350 - accuracy: 0.8112 - val_loss: 0.7834 - val_accuracy: 0.7135\n",
      "Epoch 571/1000\n",
      "48/48 [==============================] - 1s 13ms/step - loss: 0.6251 - accuracy: 0.7969 - val_loss: 0.7834 - val_accuracy: 0.7135\n",
      "Epoch 572/1000\n",
      "48/48 [==============================] - 1s 12ms/step - loss: 0.6936 - accuracy: 0.7878 - val_loss: 0.7817 - val_accuracy: 0.7188\n",
      "Epoch 573/1000\n",
      "48/48 [==============================] - 1s 12ms/step - loss: 0.6873 - accuracy: 0.7708 - val_loss: 0.7796 - val_accuracy: 0.7292\n",
      "Epoch 574/1000\n",
      "48/48 [==============================] - 1s 12ms/step - loss: 0.6470 - accuracy: 0.7956 - val_loss: 0.7798 - val_accuracy: 0.7344\n",
      "Epoch 575/1000\n",
      "48/48 [==============================] - 1s 11ms/step - loss: 0.6920 - accuracy: 0.8034 - val_loss: 0.7770 - val_accuracy: 0.7292\n",
      "Epoch 576/1000\n",
      "48/48 [==============================] - 1s 13ms/step - loss: 0.6646 - accuracy: 0.7865 - val_loss: 0.7775 - val_accuracy: 0.7188\n",
      "Epoch 577/1000\n",
      "48/48 [==============================] - 1s 12ms/step - loss: 0.6910 - accuracy: 0.7786 - val_loss: 0.7743 - val_accuracy: 0.7292\n",
      "Epoch 578/1000\n",
      "48/48 [==============================] - 1s 12ms/step - loss: 0.6835 - accuracy: 0.7812 - val_loss: 0.7753 - val_accuracy: 0.7344\n",
      "Epoch 579/1000\n",
      "48/48 [==============================] - 1s 13ms/step - loss: 0.6760 - accuracy: 0.8021 - val_loss: 0.7782 - val_accuracy: 0.7292\n",
      "Epoch 580/1000\n",
      "48/48 [==============================] - 1s 12ms/step - loss: 0.6723 - accuracy: 0.8047 - val_loss: 0.7768 - val_accuracy: 0.7292\n",
      "Epoch 581/1000\n",
      "48/48 [==============================] - 1s 13ms/step - loss: 0.6322 - accuracy: 0.8203 - val_loss: 0.7737 - val_accuracy: 0.7240\n",
      "Epoch 582/1000\n",
      "48/48 [==============================] - 1s 12ms/step - loss: 0.5909 - accuracy: 0.8190 - val_loss: 0.7734 - val_accuracy: 0.7292\n",
      "Epoch 583/1000\n",
      "48/48 [==============================] - 1s 11ms/step - loss: 0.6402 - accuracy: 0.8151 - val_loss: 0.7763 - val_accuracy: 0.7292\n",
      "Epoch 584/1000\n",
      "48/48 [==============================] - 1s 13ms/step - loss: 0.6476 - accuracy: 0.7943 - val_loss: 0.7765 - val_accuracy: 0.7292\n",
      "Epoch 585/1000\n",
      "48/48 [==============================] - 1s 12ms/step - loss: 0.6451 - accuracy: 0.7982 - val_loss: 0.7773 - val_accuracy: 0.7240\n",
      "Epoch 586/1000\n",
      "48/48 [==============================] - 1s 13ms/step - loss: 0.6943 - accuracy: 0.7852 - val_loss: 0.7773 - val_accuracy: 0.7396\n",
      "Epoch 587/1000\n",
      "48/48 [==============================] - 1s 11ms/step - loss: 0.6770 - accuracy: 0.7682 - val_loss: 0.7751 - val_accuracy: 0.7344\n",
      "Epoch 588/1000\n",
      "48/48 [==============================] - 1s 12ms/step - loss: 0.6257 - accuracy: 0.8008 - val_loss: 0.7738 - val_accuracy: 0.7344\n",
      "Epoch 589/1000\n",
      "48/48 [==============================] - 1s 13ms/step - loss: 0.6526 - accuracy: 0.7917 - val_loss: 0.7757 - val_accuracy: 0.7500\n",
      "Epoch 590/1000\n",
      "48/48 [==============================] - 1s 12ms/step - loss: 0.6551 - accuracy: 0.7982 - val_loss: 0.7717 - val_accuracy: 0.7240\n",
      "Epoch 591/1000\n",
      "48/48 [==============================] - 1s 13ms/step - loss: 0.6329 - accuracy: 0.7956 - val_loss: 0.7747 - val_accuracy: 0.7292\n",
      "Epoch 592/1000\n",
      "48/48 [==============================] - 1s 12ms/step - loss: 0.6386 - accuracy: 0.8099 - val_loss: 0.7746 - val_accuracy: 0.7396\n",
      "Epoch 593/1000\n",
      "48/48 [==============================] - 1s 13ms/step - loss: 0.6518 - accuracy: 0.8125 - val_loss: 0.7745 - val_accuracy: 0.7396\n",
      "Epoch 594/1000\n",
      "48/48 [==============================] - 1s 11ms/step - loss: 0.6819 - accuracy: 0.7904 - val_loss: 0.7753 - val_accuracy: 0.7344\n",
      "Epoch 595/1000\n",
      "48/48 [==============================] - 1s 13ms/step - loss: 0.6079 - accuracy: 0.8138 - val_loss: 0.7733 - val_accuracy: 0.7292\n",
      "Epoch 596/1000\n",
      "48/48 [==============================] - 1s 12ms/step - loss: 0.6738 - accuracy: 0.7943 - val_loss: 0.7653 - val_accuracy: 0.7292\n",
      "Epoch 597/1000\n",
      "48/48 [==============================] - 1s 13ms/step - loss: 0.6836 - accuracy: 0.7891 - val_loss: 0.7692 - val_accuracy: 0.7448\n",
      "Epoch 598/1000\n",
      "48/48 [==============================] - 1s 12ms/step - loss: 0.6215 - accuracy: 0.8125 - val_loss: 0.7708 - val_accuracy: 0.7292\n",
      "Epoch 599/1000\n",
      "48/48 [==============================] - 1s 12ms/step - loss: 0.6176 - accuracy: 0.8112 - val_loss: 0.7664 - val_accuracy: 0.7292\n",
      "Epoch 600/1000\n",
      "48/48 [==============================] - 1s 13ms/step - loss: 0.6370 - accuracy: 0.7904 - val_loss: 0.7705 - val_accuracy: 0.7240\n",
      "Epoch 601/1000\n",
      "48/48 [==============================] - 1s 12ms/step - loss: 0.6290 - accuracy: 0.8138 - val_loss: 0.7689 - val_accuracy: 0.7292\n",
      "Epoch 602/1000\n",
      "48/48 [==============================] - 1s 12ms/step - loss: 0.6327 - accuracy: 0.8190 - val_loss: 0.7710 - val_accuracy: 0.7240\n",
      "Epoch 603/1000\n",
      "48/48 [==============================] - 1s 12ms/step - loss: 0.6510 - accuracy: 0.7852 - val_loss: 0.7700 - val_accuracy: 0.7240\n",
      "Epoch 604/1000\n",
      "48/48 [==============================] - 1s 13ms/step - loss: 0.6451 - accuracy: 0.8073 - val_loss: 0.7696 - val_accuracy: 0.7344\n",
      "Epoch 605/1000\n",
      "48/48 [==============================] - 1s 12ms/step - loss: 0.6120 - accuracy: 0.8060 - val_loss: 0.7669 - val_accuracy: 0.7448\n",
      "Epoch 606/1000\n",
      "48/48 [==============================] - 1s 13ms/step - loss: 0.6784 - accuracy: 0.7943 - val_loss: 0.7709 - val_accuracy: 0.7240\n",
      "Epoch 607/1000\n",
      "48/48 [==============================] - 1s 13ms/step - loss: 0.6444 - accuracy: 0.7995 - val_loss: 0.7682 - val_accuracy: 0.7188\n",
      "Epoch 608/1000\n",
      "48/48 [==============================] - 1s 12ms/step - loss: 0.6443 - accuracy: 0.8034 - val_loss: 0.7684 - val_accuracy: 0.7292\n",
      "Epoch 609/1000\n",
      "48/48 [==============================] - 1s 13ms/step - loss: 0.6081 - accuracy: 0.8177 - val_loss: 0.7671 - val_accuracy: 0.7396\n",
      "Epoch 610/1000\n",
      "48/48 [==============================] - 1s 12ms/step - loss: 0.6608 - accuracy: 0.7982 - val_loss: 0.7666 - val_accuracy: 0.7240\n",
      "Epoch 611/1000\n",
      "48/48 [==============================] - 1s 11ms/step - loss: 0.5878 - accuracy: 0.8320 - val_loss: 0.7745 - val_accuracy: 0.7292\n",
      "Epoch 612/1000\n",
      "48/48 [==============================] - 1s 12ms/step - loss: 0.6135 - accuracy: 0.8021 - val_loss: 0.7712 - val_accuracy: 0.7188\n",
      "Epoch 613/1000\n",
      "48/48 [==============================] - 1s 12ms/step - loss: 0.6046 - accuracy: 0.8333 - val_loss: 0.7704 - val_accuracy: 0.7292\n",
      "Epoch 614/1000\n",
      "48/48 [==============================] - 1s 12ms/step - loss: 0.5940 - accuracy: 0.8294 - val_loss: 0.7676 - val_accuracy: 0.7344\n",
      "Epoch 615/1000\n",
      "48/48 [==============================] - 1s 12ms/step - loss: 0.6121 - accuracy: 0.8112 - val_loss: 0.7680 - val_accuracy: 0.7344\n",
      "Epoch 616/1000\n",
      "48/48 [==============================] - 1s 13ms/step - loss: 0.6331 - accuracy: 0.7930 - val_loss: 0.7713 - val_accuracy: 0.7344\n",
      "Epoch 617/1000\n",
      "48/48 [==============================] - 1s 13ms/step - loss: 0.6286 - accuracy: 0.8021 - val_loss: 0.7733 - val_accuracy: 0.7292\n",
      "Epoch 618/1000\n",
      "48/48 [==============================] - 1s 12ms/step - loss: 0.6056 - accuracy: 0.8229 - val_loss: 0.7684 - val_accuracy: 0.7240\n",
      "Epoch 619/1000\n",
      "48/48 [==============================] - 1s 13ms/step - loss: 0.5803 - accuracy: 0.8203 - val_loss: 0.7654 - val_accuracy: 0.7292\n",
      "Epoch 620/1000\n",
      "48/48 [==============================] - 1s 12ms/step - loss: 0.6447 - accuracy: 0.8151 - val_loss: 0.7630 - val_accuracy: 0.7292\n",
      "Epoch 621/1000\n",
      "48/48 [==============================] - 1s 12ms/step - loss: 0.6236 - accuracy: 0.8138 - val_loss: 0.7633 - val_accuracy: 0.7292\n",
      "Epoch 622/1000\n",
      "48/48 [==============================] - 1s 13ms/step - loss: 0.6314 - accuracy: 0.8177 - val_loss: 0.7601 - val_accuracy: 0.7292\n",
      "Epoch 623/1000\n",
      "48/48 [==============================] - 1s 12ms/step - loss: 0.5919 - accuracy: 0.8151 - val_loss: 0.7619 - val_accuracy: 0.7292\n",
      "Epoch 624/1000\n",
      "48/48 [==============================] - 1s 13ms/step - loss: 0.6273 - accuracy: 0.8099 - val_loss: 0.7573 - val_accuracy: 0.7344\n",
      "Epoch 625/1000\n",
      "48/48 [==============================] - 1s 12ms/step - loss: 0.6190 - accuracy: 0.8112 - val_loss: 0.7510 - val_accuracy: 0.7552\n",
      "Epoch 626/1000\n",
      "48/48 [==============================] - 1s 13ms/step - loss: 0.6049 - accuracy: 0.8060 - val_loss: 0.7533 - val_accuracy: 0.7552\n",
      "Epoch 627/1000\n",
      "48/48 [==============================] - 1s 12ms/step - loss: 0.6212 - accuracy: 0.8138 - val_loss: 0.7504 - val_accuracy: 0.7500\n",
      "Epoch 628/1000\n",
      "48/48 [==============================] - 1s 12ms/step - loss: 0.6746 - accuracy: 0.7891 - val_loss: 0.7513 - val_accuracy: 0.7500\n",
      "Epoch 629/1000\n",
      "48/48 [==============================] - 1s 13ms/step - loss: 0.6075 - accuracy: 0.8021 - val_loss: 0.7556 - val_accuracy: 0.7448\n",
      "Epoch 630/1000\n",
      "48/48 [==============================] - 1s 11ms/step - loss: 0.6600 - accuracy: 0.7917 - val_loss: 0.7543 - val_accuracy: 0.7448\n",
      "Epoch 631/1000\n",
      "48/48 [==============================] - 1s 12ms/step - loss: 0.5744 - accuracy: 0.8164 - val_loss: 0.7552 - val_accuracy: 0.7344\n",
      "Epoch 632/1000\n",
      "48/48 [==============================] - 1s 12ms/step - loss: 0.5723 - accuracy: 0.8242 - val_loss: 0.7543 - val_accuracy: 0.7396\n",
      "Epoch 633/1000\n",
      "48/48 [==============================] - 1s 12ms/step - loss: 0.5981 - accuracy: 0.8242 - val_loss: 0.7530 - val_accuracy: 0.7396\n",
      "Epoch 634/1000\n",
      "48/48 [==============================] - 1s 13ms/step - loss: 0.5856 - accuracy: 0.8164 - val_loss: 0.7522 - val_accuracy: 0.7396\n",
      "Epoch 635/1000\n",
      "48/48 [==============================] - 1s 11ms/step - loss: 0.5611 - accuracy: 0.8307 - val_loss: 0.7544 - val_accuracy: 0.7396\n",
      "Epoch 636/1000\n",
      "48/48 [==============================] - 1s 12ms/step - loss: 0.6244 - accuracy: 0.8008 - val_loss: 0.7589 - val_accuracy: 0.7396\n",
      "Epoch 637/1000\n",
      "48/48 [==============================] - 1s 12ms/step - loss: 0.6354 - accuracy: 0.8060 - val_loss: 0.7563 - val_accuracy: 0.7396\n",
      "Epoch 638/1000\n",
      "48/48 [==============================] - 1s 13ms/step - loss: 0.6059 - accuracy: 0.7982 - val_loss: 0.7508 - val_accuracy: 0.7396\n",
      "Epoch 639/1000\n",
      "48/48 [==============================] - 1s 13ms/step - loss: 0.6096 - accuracy: 0.8112 - val_loss: 0.7509 - val_accuracy: 0.7240\n",
      "Epoch 640/1000\n",
      "48/48 [==============================] - 1s 12ms/step - loss: 0.6376 - accuracy: 0.8112 - val_loss: 0.7483 - val_accuracy: 0.7240\n",
      "Epoch 641/1000\n",
      "48/48 [==============================] - 1s 13ms/step - loss: 0.6019 - accuracy: 0.7930 - val_loss: 0.7456 - val_accuracy: 0.7344\n",
      "Epoch 642/1000\n",
      "48/48 [==============================] - 1s 12ms/step - loss: 0.5661 - accuracy: 0.8333 - val_loss: 0.7490 - val_accuracy: 0.7292\n",
      "Epoch 643/1000\n",
      "48/48 [==============================] - 1s 12ms/step - loss: 0.6256 - accuracy: 0.8021 - val_loss: 0.7531 - val_accuracy: 0.7292\n",
      "Epoch 644/1000\n",
      "48/48 [==============================] - 1s 13ms/step - loss: 0.5982 - accuracy: 0.8177 - val_loss: 0.7548 - val_accuracy: 0.7292\n",
      "Epoch 645/1000\n",
      "48/48 [==============================] - 1s 11ms/step - loss: 0.5990 - accuracy: 0.8216 - val_loss: 0.7563 - val_accuracy: 0.7240\n",
      "Epoch 646/1000\n",
      "48/48 [==============================] - 1s 11ms/step - loss: 0.6312 - accuracy: 0.7982 - val_loss: 0.7544 - val_accuracy: 0.7240\n",
      "Epoch 647/1000\n",
      "48/48 [==============================] - 1s 12ms/step - loss: 0.5911 - accuracy: 0.8359 - val_loss: 0.7505 - val_accuracy: 0.7292\n",
      "Epoch 648/1000\n",
      "48/48 [==============================] - 1s 11ms/step - loss: 0.5711 - accuracy: 0.8099 - val_loss: 0.7509 - val_accuracy: 0.7344\n",
      "Epoch 649/1000\n",
      "48/48 [==============================] - 1s 13ms/step - loss: 0.6008 - accuracy: 0.8255 - val_loss: 0.7520 - val_accuracy: 0.7292\n",
      "Epoch 650/1000\n",
      "48/48 [==============================] - 1s 11ms/step - loss: 0.5856 - accuracy: 0.8229 - val_loss: 0.7502 - val_accuracy: 0.7396\n",
      "Epoch 651/1000\n",
      "48/48 [==============================] - 1s 15ms/step - loss: 0.6026 - accuracy: 0.8177 - val_loss: 0.7521 - val_accuracy: 0.7396\n",
      "Epoch 652/1000\n",
      "48/48 [==============================] - 1s 12ms/step - loss: 0.6461 - accuracy: 0.7930 - val_loss: 0.7540 - val_accuracy: 0.7448\n",
      "Epoch 653/1000\n",
      "48/48 [==============================] - 1s 13ms/step - loss: 0.5789 - accuracy: 0.8294 - val_loss: 0.7511 - val_accuracy: 0.7396\n",
      "Epoch 654/1000\n",
      "48/48 [==============================] - 1s 14ms/step - loss: 0.5913 - accuracy: 0.8190 - val_loss: 0.7544 - val_accuracy: 0.7292\n",
      "Epoch 655/1000\n",
      "48/48 [==============================] - 1s 14ms/step - loss: 0.6264 - accuracy: 0.8034 - val_loss: 0.7528 - val_accuracy: 0.7396\n",
      "Epoch 656/1000\n",
      "48/48 [==============================] - 1s 13ms/step - loss: 0.6047 - accuracy: 0.8229 - val_loss: 0.7501 - val_accuracy: 0.7344\n",
      "Epoch 657/1000\n",
      "48/48 [==============================] - 1s 14ms/step - loss: 0.6427 - accuracy: 0.8151 - val_loss: 0.7520 - val_accuracy: 0.7344\n",
      "Epoch 658/1000\n",
      "48/48 [==============================] - 1s 13ms/step - loss: 0.5802 - accuracy: 0.8216 - val_loss: 0.7542 - val_accuracy: 0.7344\n",
      "Epoch 659/1000\n",
      "48/48 [==============================] - 1s 12ms/step - loss: 0.5860 - accuracy: 0.8125 - val_loss: 0.7546 - val_accuracy: 0.7344\n",
      "Epoch 660/1000\n",
      "48/48 [==============================] - 1s 13ms/step - loss: 0.5715 - accuracy: 0.8385 - val_loss: 0.7555 - val_accuracy: 0.7240\n",
      "Epoch 661/1000\n",
      "48/48 [==============================] - 1s 13ms/step - loss: 0.5763 - accuracy: 0.8112 - val_loss: 0.7540 - val_accuracy: 0.7396\n",
      "Epoch 662/1000\n",
      "48/48 [==============================] - 1s 12ms/step - loss: 0.5703 - accuracy: 0.8138 - val_loss: 0.7532 - val_accuracy: 0.7448\n",
      "Epoch 663/1000\n",
      "48/48 [==============================] - 1s 16ms/step - loss: 0.5324 - accuracy: 0.8568 - val_loss: 0.7548 - val_accuracy: 0.7396\n",
      "Epoch 664/1000\n",
      "48/48 [==============================] - 1s 14ms/step - loss: 0.6113 - accuracy: 0.8203 - val_loss: 0.7523 - val_accuracy: 0.7396\n",
      "Epoch 665/1000\n",
      "48/48 [==============================] - 1s 12ms/step - loss: 0.5736 - accuracy: 0.8372 - val_loss: 0.7523 - val_accuracy: 0.7396\n",
      "Epoch 666/1000\n",
      "48/48 [==============================] - 1s 12ms/step - loss: 0.6427 - accuracy: 0.8125 - val_loss: 0.7532 - val_accuracy: 0.7448\n",
      "Epoch 667/1000\n",
      "48/48 [==============================] - 1s 13ms/step - loss: 0.6262 - accuracy: 0.8151 - val_loss: 0.7530 - val_accuracy: 0.7448\n",
      "Epoch 668/1000\n",
      "48/48 [==============================] - 1s 12ms/step - loss: 0.5396 - accuracy: 0.8307 - val_loss: 0.7518 - val_accuracy: 0.7552\n",
      "Epoch 669/1000\n",
      "48/48 [==============================] - 1s 13ms/step - loss: 0.6068 - accuracy: 0.8138 - val_loss: 0.7533 - val_accuracy: 0.7604\n",
      "Epoch 670/1000\n",
      "48/48 [==============================] - 1s 12ms/step - loss: 0.5364 - accuracy: 0.8385 - val_loss: 0.7529 - val_accuracy: 0.7448\n",
      "Epoch 671/1000\n",
      "48/48 [==============================] - 1s 11ms/step - loss: 0.6380 - accuracy: 0.7891 - val_loss: 0.7509 - val_accuracy: 0.7448\n",
      "Epoch 672/1000\n",
      "48/48 [==============================] - 1s 13ms/step - loss: 0.5659 - accuracy: 0.8164 - val_loss: 0.7499 - val_accuracy: 0.7396\n",
      "Epoch 673/1000\n",
      "48/48 [==============================] - 1s 13ms/step - loss: 0.5843 - accuracy: 0.8281 - val_loss: 0.7494 - val_accuracy: 0.7396\n",
      "Epoch 674/1000\n",
      "48/48 [==============================] - 1s 12ms/step - loss: 0.6052 - accuracy: 0.8073 - val_loss: 0.7513 - val_accuracy: 0.7396\n",
      "Epoch 675/1000\n",
      "48/48 [==============================] - 1s 13ms/step - loss: 0.6023 - accuracy: 0.8047 - val_loss: 0.7503 - val_accuracy: 0.7344\n",
      "Epoch 676/1000\n",
      "48/48 [==============================] - 1s 13ms/step - loss: 0.5861 - accuracy: 0.8229 - val_loss: 0.7468 - val_accuracy: 0.7396\n",
      "Epoch 677/1000\n",
      "48/48 [==============================] - 1s 12ms/step - loss: 0.5639 - accuracy: 0.8177 - val_loss: 0.7484 - val_accuracy: 0.7396\n",
      "Epoch 678/1000\n",
      "48/48 [==============================] - 1s 11ms/step - loss: 0.5743 - accuracy: 0.8242 - val_loss: 0.7483 - val_accuracy: 0.7552\n",
      "Epoch 679/1000\n",
      "48/48 [==============================] - 1s 12ms/step - loss: 0.5221 - accuracy: 0.8581 - val_loss: 0.7514 - val_accuracy: 0.7500\n",
      "Epoch 680/1000\n",
      "48/48 [==============================] - 1s 12ms/step - loss: 0.5745 - accuracy: 0.8268 - val_loss: 0.7538 - val_accuracy: 0.7500\n",
      "Epoch 681/1000\n",
      "48/48 [==============================] - 1s 11ms/step - loss: 0.5411 - accuracy: 0.8555 - val_loss: 0.7529 - val_accuracy: 0.7448\n",
      "Epoch 682/1000\n",
      "48/48 [==============================] - 1s 12ms/step - loss: 0.5985 - accuracy: 0.8242 - val_loss: 0.7502 - val_accuracy: 0.7500\n",
      "Epoch 683/1000\n",
      "48/48 [==============================] - 1s 13ms/step - loss: 0.5716 - accuracy: 0.8320 - val_loss: 0.7442 - val_accuracy: 0.7448\n",
      "Epoch 684/1000\n",
      "48/48 [==============================] - 1s 12ms/step - loss: 0.5945 - accuracy: 0.8281 - val_loss: 0.7427 - val_accuracy: 0.7396\n",
      "Epoch 685/1000\n",
      "48/48 [==============================] - 1s 13ms/step - loss: 0.5622 - accuracy: 0.8424 - val_loss: 0.7438 - val_accuracy: 0.7448\n",
      "Epoch 686/1000\n",
      "48/48 [==============================] - 1s 11ms/step - loss: 0.5724 - accuracy: 0.8464 - val_loss: 0.7449 - val_accuracy: 0.7448\n",
      "Epoch 687/1000\n",
      "48/48 [==============================] - 1s 12ms/step - loss: 0.5684 - accuracy: 0.8268 - val_loss: 0.7463 - val_accuracy: 0.7552\n",
      "Epoch 688/1000\n",
      "48/48 [==============================] - 1s 13ms/step - loss: 0.5952 - accuracy: 0.8164 - val_loss: 0.7492 - val_accuracy: 0.7500\n",
      "Epoch 689/1000\n",
      "48/48 [==============================] - 1s 12ms/step - loss: 0.5548 - accuracy: 0.8385 - val_loss: 0.7489 - val_accuracy: 0.7604\n",
      "Epoch 690/1000\n",
      "48/48 [==============================] - 1s 12ms/step - loss: 0.6016 - accuracy: 0.8112 - val_loss: 0.7443 - val_accuracy: 0.7500\n",
      "Epoch 691/1000\n",
      "48/48 [==============================] - 1s 15ms/step - loss: 0.5868 - accuracy: 0.8281 - val_loss: 0.7413 - val_accuracy: 0.7552\n",
      "Epoch 692/1000\n",
      "48/48 [==============================] - 1s 15ms/step - loss: 0.5749 - accuracy: 0.8294 - val_loss: 0.7449 - val_accuracy: 0.7448\n",
      "Epoch 693/1000\n",
      "48/48 [==============================] - 1s 12ms/step - loss: 0.5575 - accuracy: 0.8372 - val_loss: 0.7434 - val_accuracy: 0.7448\n",
      "Epoch 694/1000\n",
      "48/48 [==============================] - 1s 13ms/step - loss: 0.5574 - accuracy: 0.8542 - val_loss: 0.7432 - val_accuracy: 0.7552\n",
      "Epoch 695/1000\n",
      "48/48 [==============================] - 1s 13ms/step - loss: 0.5501 - accuracy: 0.8281 - val_loss: 0.7483 - val_accuracy: 0.7448\n",
      "Epoch 696/1000\n",
      "48/48 [==============================] - 1s 12ms/step - loss: 0.5873 - accuracy: 0.8346 - val_loss: 0.7480 - val_accuracy: 0.7552\n",
      "Epoch 697/1000\n",
      "48/48 [==============================] - 1s 13ms/step - loss: 0.5805 - accuracy: 0.8346 - val_loss: 0.7429 - val_accuracy: 0.7604\n",
      "Epoch 698/1000\n",
      "48/48 [==============================] - 1s 14ms/step - loss: 0.5423 - accuracy: 0.8424 - val_loss: 0.7432 - val_accuracy: 0.7552\n",
      "Epoch 699/1000\n",
      "48/48 [==============================] - 1s 12ms/step - loss: 0.5965 - accuracy: 0.8203 - val_loss: 0.7486 - val_accuracy: 0.7604\n",
      "Epoch 700/1000\n",
      "48/48 [==============================] - 1s 13ms/step - loss: 0.5511 - accuracy: 0.8359 - val_loss: 0.7477 - val_accuracy: 0.7604\n",
      "Epoch 701/1000\n",
      "48/48 [==============================] - 1s 12ms/step - loss: 0.5768 - accuracy: 0.8177 - val_loss: 0.7475 - val_accuracy: 0.7552\n",
      "Epoch 702/1000\n",
      "48/48 [==============================] - 1s 11ms/step - loss: 0.5494 - accuracy: 0.8138 - val_loss: 0.7425 - val_accuracy: 0.7552\n",
      "Epoch 703/1000\n",
      "48/48 [==============================] - 1s 13ms/step - loss: 0.5603 - accuracy: 0.8359 - val_loss: 0.7434 - val_accuracy: 0.7500\n",
      "Epoch 704/1000\n",
      "48/48 [==============================] - 1s 11ms/step - loss: 0.5878 - accuracy: 0.8359 - val_loss: 0.7460 - val_accuracy: 0.7448\n",
      "Epoch 705/1000\n",
      "48/48 [==============================] - 1s 12ms/step - loss: 0.5433 - accuracy: 0.8411 - val_loss: 0.7430 - val_accuracy: 0.7344\n",
      "Epoch 706/1000\n",
      "48/48 [==============================] - 1s 15ms/step - loss: 0.5776 - accuracy: 0.8359 - val_loss: 0.7439 - val_accuracy: 0.7396\n",
      "Epoch 707/1000\n",
      "48/48 [==============================] - 1s 12ms/step - loss: 0.5553 - accuracy: 0.8242 - val_loss: 0.7464 - val_accuracy: 0.7396\n",
      "Epoch 708/1000\n",
      "48/48 [==============================] - 1s 14ms/step - loss: 0.5295 - accuracy: 0.8477 - val_loss: 0.7426 - val_accuracy: 0.7396\n",
      "Epoch 709/1000\n",
      "48/48 [==============================] - 1s 13ms/step - loss: 0.5799 - accuracy: 0.8346 - val_loss: 0.7434 - val_accuracy: 0.7500\n",
      "Epoch 710/1000\n",
      "48/48 [==============================] - 1s 11ms/step - loss: 0.5380 - accuracy: 0.8346 - val_loss: 0.7443 - val_accuracy: 0.7500\n",
      "Epoch 711/1000\n",
      "48/48 [==============================] - 1s 13ms/step - loss: 0.6057 - accuracy: 0.8047 - val_loss: 0.7477 - val_accuracy: 0.7604\n",
      "Epoch 712/1000\n",
      "48/48 [==============================] - 1s 11ms/step - loss: 0.5098 - accuracy: 0.8581 - val_loss: 0.7451 - val_accuracy: 0.7448\n",
      "Epoch 713/1000\n",
      "48/48 [==============================] - 1s 13ms/step - loss: 0.5545 - accuracy: 0.8333 - val_loss: 0.7495 - val_accuracy: 0.7500\n",
      "Epoch 714/1000\n",
      "48/48 [==============================] - 1s 12ms/step - loss: 0.5327 - accuracy: 0.8333 - val_loss: 0.7477 - val_accuracy: 0.7396\n",
      "Epoch 715/1000\n",
      "48/48 [==============================] - 1s 13ms/step - loss: 0.5369 - accuracy: 0.8333 - val_loss: 0.7476 - val_accuracy: 0.7448\n",
      "Epoch 716/1000\n",
      "48/48 [==============================] - 1s 12ms/step - loss: 0.5135 - accuracy: 0.8503 - val_loss: 0.7456 - val_accuracy: 0.7396\n",
      "Epoch 717/1000\n",
      "48/48 [==============================] - 1s 12ms/step - loss: 0.5597 - accuracy: 0.8216 - val_loss: 0.7502 - val_accuracy: 0.7448\n",
      "Epoch 718/1000\n",
      "48/48 [==============================] - 1s 12ms/step - loss: 0.5612 - accuracy: 0.8333 - val_loss: 0.7507 - val_accuracy: 0.7448\n",
      "Epoch 719/1000\n",
      "48/48 [==============================] - 1s 13ms/step - loss: 0.5452 - accuracy: 0.8385 - val_loss: 0.7470 - val_accuracy: 0.7448\n",
      "Epoch 720/1000\n",
      "48/48 [==============================] - 1s 12ms/step - loss: 0.6111 - accuracy: 0.8190 - val_loss: 0.7479 - val_accuracy: 0.7500\n",
      "Epoch 721/1000\n",
      "48/48 [==============================] - 1s 11ms/step - loss: 0.5464 - accuracy: 0.8268 - val_loss: 0.7450 - val_accuracy: 0.7552\n",
      "Epoch 722/1000\n",
      "48/48 [==============================] - 1s 11ms/step - loss: 0.5279 - accuracy: 0.8464 - val_loss: 0.7469 - val_accuracy: 0.7552\n",
      "Epoch 723/1000\n",
      "48/48 [==============================] - 1s 12ms/step - loss: 0.5521 - accuracy: 0.8229 - val_loss: 0.7440 - val_accuracy: 0.7500\n",
      "Epoch 724/1000\n",
      "48/48 [==============================] - 1s 12ms/step - loss: 0.5382 - accuracy: 0.8255 - val_loss: 0.7460 - val_accuracy: 0.7552\n",
      "Epoch 725/1000\n",
      "48/48 [==============================] - 1s 12ms/step - loss: 0.5298 - accuracy: 0.8424 - val_loss: 0.7455 - val_accuracy: 0.7552\n",
      "Epoch 726/1000\n",
      "48/48 [==============================] - 1s 13ms/step - loss: 0.6116 - accuracy: 0.8177 - val_loss: 0.7393 - val_accuracy: 0.7604\n",
      "Epoch 727/1000\n",
      "48/48 [==============================] - 1s 11ms/step - loss: 0.5251 - accuracy: 0.8385 - val_loss: 0.7405 - val_accuracy: 0.7656\n",
      "Epoch 728/1000\n",
      "48/48 [==============================] - 1s 12ms/step - loss: 0.5637 - accuracy: 0.8307 - val_loss: 0.7412 - val_accuracy: 0.7604\n",
      "Epoch 729/1000\n",
      "48/48 [==============================] - 1s 13ms/step - loss: 0.5618 - accuracy: 0.8477 - val_loss: 0.7437 - val_accuracy: 0.7552\n",
      "Epoch 730/1000\n",
      "48/48 [==============================] - 1s 11ms/step - loss: 0.5185 - accuracy: 0.8542 - val_loss: 0.7465 - val_accuracy: 0.7604\n",
      "Epoch 731/1000\n",
      "48/48 [==============================] - 1s 13ms/step - loss: 0.5377 - accuracy: 0.8424 - val_loss: 0.7423 - val_accuracy: 0.7708\n",
      "Epoch 732/1000\n",
      "48/48 [==============================] - 1s 11ms/step - loss: 0.5137 - accuracy: 0.8516 - val_loss: 0.7398 - val_accuracy: 0.7760\n",
      "Epoch 733/1000\n",
      "48/48 [==============================] - 1s 12ms/step - loss: 0.5261 - accuracy: 0.8451 - val_loss: 0.7429 - val_accuracy: 0.7656\n",
      "Epoch 734/1000\n",
      "48/48 [==============================] - 1s 11ms/step - loss: 0.5581 - accuracy: 0.8438 - val_loss: 0.7418 - val_accuracy: 0.7604\n",
      "Epoch 735/1000\n",
      "48/48 [==============================] - 1s 11ms/step - loss: 0.5497 - accuracy: 0.8255 - val_loss: 0.7437 - val_accuracy: 0.7552\n",
      "Epoch 736/1000\n",
      "48/48 [==============================] - 1s 12ms/step - loss: 0.5569 - accuracy: 0.8281 - val_loss: 0.7444 - val_accuracy: 0.7552\n",
      "Epoch 737/1000\n",
      "48/48 [==============================] - 1s 12ms/step - loss: 0.4937 - accuracy: 0.8438 - val_loss: 0.7424 - val_accuracy: 0.7552\n",
      "Epoch 738/1000\n",
      "48/48 [==============================] - 1s 11ms/step - loss: 0.5272 - accuracy: 0.8477 - val_loss: 0.7395 - val_accuracy: 0.7604\n",
      "Epoch 739/1000\n",
      "48/48 [==============================] - 1s 13ms/step - loss: 0.5436 - accuracy: 0.8464 - val_loss: 0.7329 - val_accuracy: 0.7760\n",
      "Epoch 740/1000\n",
      "48/48 [==============================] - 1s 12ms/step - loss: 0.5735 - accuracy: 0.8203 - val_loss: 0.7292 - val_accuracy: 0.7656\n",
      "Epoch 741/1000\n",
      "48/48 [==============================] - 1s 13ms/step - loss: 0.5048 - accuracy: 0.8372 - val_loss: 0.7287 - val_accuracy: 0.7708\n",
      "Epoch 742/1000\n",
      "48/48 [==============================] - 1s 12ms/step - loss: 0.5312 - accuracy: 0.8411 - val_loss: 0.7281 - val_accuracy: 0.7656\n",
      "Epoch 743/1000\n",
      "48/48 [==============================] - 1s 11ms/step - loss: 0.5313 - accuracy: 0.8359 - val_loss: 0.7308 - val_accuracy: 0.7656\n",
      "Epoch 744/1000\n",
      "48/48 [==============================] - 1s 12ms/step - loss: 0.5139 - accuracy: 0.8438 - val_loss: 0.7258 - val_accuracy: 0.7708\n",
      "Epoch 745/1000\n",
      "48/48 [==============================] - 1s 12ms/step - loss: 0.5104 - accuracy: 0.8542 - val_loss: 0.7301 - val_accuracy: 0.7656\n",
      "Epoch 746/1000\n",
      "48/48 [==============================] - 1s 13ms/step - loss: 0.5365 - accuracy: 0.8438 - val_loss: 0.7308 - val_accuracy: 0.7604\n",
      "Epoch 747/1000\n",
      "48/48 [==============================] - 1s 12ms/step - loss: 0.5241 - accuracy: 0.8477 - val_loss: 0.7316 - val_accuracy: 0.7708\n",
      "Epoch 748/1000\n",
      "48/48 [==============================] - 1s 13ms/step - loss: 0.5180 - accuracy: 0.8464 - val_loss: 0.7319 - val_accuracy: 0.7708\n",
      "Epoch 749/1000\n",
      "48/48 [==============================] - 1s 12ms/step - loss: 0.5244 - accuracy: 0.8490 - val_loss: 0.7337 - val_accuracy: 0.7656\n",
      "Epoch 750/1000\n",
      "48/48 [==============================] - 1s 12ms/step - loss: 0.5171 - accuracy: 0.8424 - val_loss: 0.7298 - val_accuracy: 0.7656\n",
      "Epoch 751/1000\n",
      "48/48 [==============================] - 1s 12ms/step - loss: 0.5082 - accuracy: 0.8568 - val_loss: 0.7279 - val_accuracy: 0.7760\n",
      "Epoch 752/1000\n",
      "48/48 [==============================] - 1s 12ms/step - loss: 0.5281 - accuracy: 0.8438 - val_loss: 0.7315 - val_accuracy: 0.7708\n",
      "Epoch 753/1000\n",
      "48/48 [==============================] - 1s 12ms/step - loss: 0.5120 - accuracy: 0.8581 - val_loss: 0.7314 - val_accuracy: 0.7656\n",
      "Epoch 754/1000\n",
      "48/48 [==============================] - 1s 13ms/step - loss: 0.5143 - accuracy: 0.8464 - val_loss: 0.7287 - val_accuracy: 0.7760\n",
      "Epoch 755/1000\n",
      "48/48 [==============================] - 1s 13ms/step - loss: 0.5320 - accuracy: 0.8385 - val_loss: 0.7284 - val_accuracy: 0.7708\n",
      "Epoch 756/1000\n",
      "48/48 [==============================] - 1s 12ms/step - loss: 0.5330 - accuracy: 0.8307 - val_loss: 0.7223 - val_accuracy: 0.7760\n",
      "Epoch 757/1000\n",
      "48/48 [==============================] - 1s 12ms/step - loss: 0.5114 - accuracy: 0.8464 - val_loss: 0.7233 - val_accuracy: 0.7656\n",
      "Epoch 758/1000\n",
      "48/48 [==============================] - 1s 12ms/step - loss: 0.5760 - accuracy: 0.8216 - val_loss: 0.7211 - val_accuracy: 0.7708\n",
      "Epoch 759/1000\n",
      "48/48 [==============================] - 1s 11ms/step - loss: 0.5054 - accuracy: 0.8568 - val_loss: 0.7227 - val_accuracy: 0.7552\n",
      "Epoch 760/1000\n",
      "48/48 [==============================] - 1s 12ms/step - loss: 0.5625 - accuracy: 0.8411 - val_loss: 0.7268 - val_accuracy: 0.7552\n",
      "Epoch 761/1000\n",
      "48/48 [==============================] - 1s 11ms/step - loss: 0.5658 - accuracy: 0.8151 - val_loss: 0.7323 - val_accuracy: 0.7604\n",
      "Epoch 762/1000\n",
      "48/48 [==============================] - 1s 11ms/step - loss: 0.5470 - accuracy: 0.8281 - val_loss: 0.7288 - val_accuracy: 0.7656\n",
      "Epoch 763/1000\n",
      "48/48 [==============================] - 1s 13ms/step - loss: 0.5471 - accuracy: 0.8346 - val_loss: 0.7307 - val_accuracy: 0.7604\n",
      "Epoch 764/1000\n",
      "48/48 [==============================] - 1s 11ms/step - loss: 0.4909 - accuracy: 0.8555 - val_loss: 0.7328 - val_accuracy: 0.7552\n",
      "Epoch 765/1000\n",
      "48/48 [==============================] - 1s 13ms/step - loss: 0.5447 - accuracy: 0.8229 - val_loss: 0.7373 - val_accuracy: 0.7604\n",
      "Epoch 766/1000\n",
      "48/48 [==============================] - 1s 12ms/step - loss: 0.4917 - accuracy: 0.8542 - val_loss: 0.7330 - val_accuracy: 0.7552\n",
      "Epoch 767/1000\n",
      "48/48 [==============================] - 1s 13ms/step - loss: 0.4705 - accuracy: 0.8672 - val_loss: 0.7332 - val_accuracy: 0.7552\n",
      "Epoch 768/1000\n",
      "48/48 [==============================] - 1s 11ms/step - loss: 0.5007 - accuracy: 0.8633 - val_loss: 0.7292 - val_accuracy: 0.7604\n",
      "Epoch 769/1000\n",
      "48/48 [==============================] - 1s 12ms/step - loss: 0.4863 - accuracy: 0.8542 - val_loss: 0.7341 - val_accuracy: 0.7604\n",
      "Epoch 770/1000\n",
      "48/48 [==============================] - 1s 11ms/step - loss: 0.5228 - accuracy: 0.8424 - val_loss: 0.7342 - val_accuracy: 0.7604\n",
      "Epoch 771/1000\n",
      "48/48 [==============================] - 1s 11ms/step - loss: 0.5124 - accuracy: 0.8307 - val_loss: 0.7332 - val_accuracy: 0.7604\n",
      "Epoch 772/1000\n",
      "48/48 [==============================] - 1s 12ms/step - loss: 0.5132 - accuracy: 0.8555 - val_loss: 0.7291 - val_accuracy: 0.7500\n",
      "Epoch 773/1000\n",
      "48/48 [==============================] - 1s 11ms/step - loss: 0.5070 - accuracy: 0.8555 - val_loss: 0.7259 - val_accuracy: 0.7552\n",
      "Epoch 774/1000\n",
      "48/48 [==============================] - 1s 12ms/step - loss: 0.4966 - accuracy: 0.8568 - val_loss: 0.7244 - val_accuracy: 0.7552\n",
      "Epoch 775/1000\n",
      "48/48 [==============================] - 1s 13ms/step - loss: 0.5018 - accuracy: 0.8633 - val_loss: 0.7212 - val_accuracy: 0.7656\n",
      "Epoch 776/1000\n",
      "48/48 [==============================] - 1s 13ms/step - loss: 0.5171 - accuracy: 0.8477 - val_loss: 0.7181 - val_accuracy: 0.7812\n",
      "Epoch 777/1000\n",
      "48/48 [==============================] - 1s 12ms/step - loss: 0.5048 - accuracy: 0.8398 - val_loss: 0.7185 - val_accuracy: 0.7708\n",
      "Epoch 778/1000\n",
      "48/48 [==============================] - 1s 13ms/step - loss: 0.4823 - accuracy: 0.8477 - val_loss: 0.7197 - val_accuracy: 0.7760\n",
      "Epoch 779/1000\n",
      "48/48 [==============================] - 1s 12ms/step - loss: 0.5313 - accuracy: 0.8372 - val_loss: 0.7146 - val_accuracy: 0.7812\n",
      "Epoch 780/1000\n",
      "48/48 [==============================] - 1s 13ms/step - loss: 0.5330 - accuracy: 0.8359 - val_loss: 0.7156 - val_accuracy: 0.7760\n",
      "Epoch 781/1000\n",
      "48/48 [==============================] - 1s 12ms/step - loss: 0.5158 - accuracy: 0.8398 - val_loss: 0.7137 - val_accuracy: 0.7604\n",
      "Epoch 782/1000\n",
      "48/48 [==============================] - 1s 12ms/step - loss: 0.5400 - accuracy: 0.8372 - val_loss: 0.7114 - val_accuracy: 0.7760\n",
      "Epoch 783/1000\n",
      "48/48 [==============================] - 1s 13ms/step - loss: 0.4793 - accuracy: 0.8724 - val_loss: 0.7103 - val_accuracy: 0.7760\n",
      "Epoch 784/1000\n",
      "48/48 [==============================] - 1s 12ms/step - loss: 0.4852 - accuracy: 0.8620 - val_loss: 0.7114 - val_accuracy: 0.7760\n",
      "Epoch 785/1000\n",
      "48/48 [==============================] - 1s 13ms/step - loss: 0.4906 - accuracy: 0.8516 - val_loss: 0.7085 - val_accuracy: 0.7812\n",
      "Epoch 786/1000\n",
      "48/48 [==============================] - 1s 12ms/step - loss: 0.4883 - accuracy: 0.8542 - val_loss: 0.7107 - val_accuracy: 0.7760\n",
      "Epoch 787/1000\n",
      "48/48 [==============================] - 1s 12ms/step - loss: 0.5211 - accuracy: 0.8346 - val_loss: 0.7094 - val_accuracy: 0.7760\n",
      "Epoch 788/1000\n",
      "48/48 [==============================] - 1s 12ms/step - loss: 0.5103 - accuracy: 0.8581 - val_loss: 0.7106 - val_accuracy: 0.7708\n",
      "Epoch 789/1000\n",
      "48/48 [==============================] - 1s 12ms/step - loss: 0.4893 - accuracy: 0.8477 - val_loss: 0.7104 - val_accuracy: 0.7760\n",
      "Epoch 790/1000\n",
      "48/48 [==============================] - 1s 13ms/step - loss: 0.5147 - accuracy: 0.8451 - val_loss: 0.7176 - val_accuracy: 0.7708\n",
      "Epoch 791/1000\n",
      "48/48 [==============================] - 1s 13ms/step - loss: 0.5095 - accuracy: 0.8372 - val_loss: 0.7209 - val_accuracy: 0.7760\n",
      "Epoch 792/1000\n",
      "48/48 [==============================] - 1s 12ms/step - loss: 0.5025 - accuracy: 0.8620 - val_loss: 0.7171 - val_accuracy: 0.7760\n",
      "Epoch 793/1000\n",
      "48/48 [==============================] - 1s 12ms/step - loss: 0.5130 - accuracy: 0.8438 - val_loss: 0.7167 - val_accuracy: 0.7760\n",
      "Epoch 794/1000\n",
      "48/48 [==============================] - 1s 13ms/step - loss: 0.4868 - accuracy: 0.8516 - val_loss: 0.7182 - val_accuracy: 0.7656\n",
      "Epoch 795/1000\n",
      "48/48 [==============================] - 1s 12ms/step - loss: 0.4855 - accuracy: 0.8607 - val_loss: 0.7180 - val_accuracy: 0.7604\n",
      "Epoch 796/1000\n",
      "48/48 [==============================] - 1s 12ms/step - loss: 0.4933 - accuracy: 0.8438 - val_loss: 0.7176 - val_accuracy: 0.7656\n",
      "Epoch 797/1000\n",
      "48/48 [==============================] - 0s 10ms/step - loss: 0.4894 - accuracy: 0.8438 - val_loss: 0.7228 - val_accuracy: 0.7708\n",
      "Epoch 798/1000\n",
      "48/48 [==============================] - 0s 9ms/step - loss: 0.5274 - accuracy: 0.8464 - val_loss: 0.7241 - val_accuracy: 0.7656\n",
      "Epoch 799/1000\n",
      "48/48 [==============================] - 0s 9ms/step - loss: 0.5042 - accuracy: 0.8411 - val_loss: 0.7239 - val_accuracy: 0.7708\n",
      "Epoch 800/1000\n",
      "48/48 [==============================] - 0s 9ms/step - loss: 0.4934 - accuracy: 0.8411 - val_loss: 0.7279 - val_accuracy: 0.7865\n",
      "Epoch 801/1000\n",
      "48/48 [==============================] - 0s 10ms/step - loss: 0.4861 - accuracy: 0.8685 - val_loss: 0.7282 - val_accuracy: 0.7656\n",
      "Epoch 802/1000\n",
      "48/48 [==============================] - 0s 9ms/step - loss: 0.5242 - accuracy: 0.8372 - val_loss: 0.7268 - val_accuracy: 0.7760\n",
      "Epoch 803/1000\n",
      "48/48 [==============================] - 0s 9ms/step - loss: 0.4893 - accuracy: 0.8659 - val_loss: 0.7305 - val_accuracy: 0.7708\n",
      "Epoch 804/1000\n",
      "48/48 [==============================] - 0s 9ms/step - loss: 0.5074 - accuracy: 0.8438 - val_loss: 0.7255 - val_accuracy: 0.7760\n",
      "Epoch 805/1000\n",
      "48/48 [==============================] - 0s 9ms/step - loss: 0.5460 - accuracy: 0.8398 - val_loss: 0.7189 - val_accuracy: 0.7812\n",
      "Epoch 806/1000\n",
      "48/48 [==============================] - 0s 8ms/step - loss: 0.4951 - accuracy: 0.8503 - val_loss: 0.7170 - val_accuracy: 0.7760\n",
      "Epoch 807/1000\n",
      "48/48 [==============================] - 0s 9ms/step - loss: 0.5282 - accuracy: 0.8333 - val_loss: 0.7244 - val_accuracy: 0.7760\n",
      "Epoch 808/1000\n",
      "48/48 [==============================] - 0s 9ms/step - loss: 0.4455 - accuracy: 0.8828 - val_loss: 0.7234 - val_accuracy: 0.7708\n",
      "Epoch 809/1000\n",
      "48/48 [==============================] - 0s 8ms/step - loss: 0.5299 - accuracy: 0.8424 - val_loss: 0.7171 - val_accuracy: 0.7708\n",
      "Epoch 810/1000\n",
      "48/48 [==============================] - 0s 9ms/step - loss: 0.4735 - accuracy: 0.8685 - val_loss: 0.7179 - val_accuracy: 0.7812\n",
      "Epoch 811/1000\n",
      "48/48 [==============================] - 0s 8ms/step - loss: 0.5027 - accuracy: 0.8516 - val_loss: 0.7186 - val_accuracy: 0.7812\n",
      "Epoch 812/1000\n",
      "48/48 [==============================] - 0s 8ms/step - loss: 0.4960 - accuracy: 0.8516 - val_loss: 0.7145 - val_accuracy: 0.7760\n",
      "Epoch 813/1000\n",
      "48/48 [==============================] - 0s 9ms/step - loss: 0.4994 - accuracy: 0.8464 - val_loss: 0.7104 - val_accuracy: 0.7865\n",
      "Epoch 814/1000\n",
      "48/48 [==============================] - 0s 10ms/step - loss: 0.5438 - accuracy: 0.8229 - val_loss: 0.7061 - val_accuracy: 0.7708\n",
      "Epoch 815/1000\n",
      "48/48 [==============================] - 0s 9ms/step - loss: 0.4941 - accuracy: 0.8411 - val_loss: 0.7056 - val_accuracy: 0.7760\n",
      "Epoch 816/1000\n",
      "48/48 [==============================] - 0s 9ms/step - loss: 0.4547 - accuracy: 0.8672 - val_loss: 0.7063 - val_accuracy: 0.7865\n",
      "Epoch 817/1000\n",
      "48/48 [==============================] - 0s 9ms/step - loss: 0.5017 - accuracy: 0.8385 - val_loss: 0.7050 - val_accuracy: 0.7865\n",
      "Epoch 818/1000\n",
      "48/48 [==============================] - 0s 8ms/step - loss: 0.5253 - accuracy: 0.8503 - val_loss: 0.7021 - val_accuracy: 0.7812\n",
      "Epoch 819/1000\n",
      "48/48 [==============================] - 0s 8ms/step - loss: 0.4676 - accuracy: 0.8594 - val_loss: 0.7033 - val_accuracy: 0.7760\n",
      "Epoch 820/1000\n",
      "48/48 [==============================] - 0s 8ms/step - loss: 0.4164 - accuracy: 0.8698 - val_loss: 0.7052 - val_accuracy: 0.7812\n",
      "Epoch 821/1000\n",
      "48/48 [==============================] - 0s 9ms/step - loss: 0.4618 - accuracy: 0.8672 - val_loss: 0.7046 - val_accuracy: 0.7656\n",
      "Epoch 822/1000\n",
      "48/48 [==============================] - 0s 8ms/step - loss: 0.5132 - accuracy: 0.8529 - val_loss: 0.7027 - val_accuracy: 0.7812\n",
      "Epoch 823/1000\n",
      "48/48 [==============================] - 0s 8ms/step - loss: 0.5223 - accuracy: 0.8516 - val_loss: 0.7060 - val_accuracy: 0.7708\n",
      "Epoch 824/1000\n",
      "48/48 [==============================] - 0s 9ms/step - loss: 0.4500 - accuracy: 0.8789 - val_loss: 0.7053 - val_accuracy: 0.7708\n",
      "Epoch 825/1000\n",
      "48/48 [==============================] - 0s 9ms/step - loss: 0.4656 - accuracy: 0.8659 - val_loss: 0.7058 - val_accuracy: 0.7760\n",
      "Epoch 826/1000\n",
      "48/48 [==============================] - 0s 8ms/step - loss: 0.5230 - accuracy: 0.8359 - val_loss: 0.7058 - val_accuracy: 0.7656\n",
      "Epoch 827/1000\n",
      "48/48 [==============================] - 0s 8ms/step - loss: 0.4958 - accuracy: 0.8503 - val_loss: 0.7058 - val_accuracy: 0.7708\n",
      "Epoch 828/1000\n",
      "48/48 [==============================] - 0s 9ms/step - loss: 0.4981 - accuracy: 0.8464 - val_loss: 0.7055 - val_accuracy: 0.7760\n",
      "Epoch 829/1000\n",
      "48/48 [==============================] - 0s 8ms/step - loss: 0.4776 - accuracy: 0.8490 - val_loss: 0.7041 - val_accuracy: 0.7604\n",
      "Epoch 830/1000\n",
      "48/48 [==============================] - 0s 8ms/step - loss: 0.4609 - accuracy: 0.8581 - val_loss: 0.7022 - val_accuracy: 0.7604\n",
      "Epoch 831/1000\n",
      "48/48 [==============================] - 0s 9ms/step - loss: 0.5025 - accuracy: 0.8464 - val_loss: 0.7035 - val_accuracy: 0.7656\n",
      "Epoch 832/1000\n",
      "48/48 [==============================] - 0s 8ms/step - loss: 0.4880 - accuracy: 0.8542 - val_loss: 0.7080 - val_accuracy: 0.7552\n",
      "Epoch 833/1000\n",
      "48/48 [==============================] - 0s 9ms/step - loss: 0.5231 - accuracy: 0.8581 - val_loss: 0.7115 - val_accuracy: 0.7656\n",
      "Epoch 834/1000\n",
      "48/48 [==============================] - 0s 9ms/step - loss: 0.4991 - accuracy: 0.8503 - val_loss: 0.7127 - val_accuracy: 0.7552\n",
      "Epoch 835/1000\n",
      "48/48 [==============================] - 0s 9ms/step - loss: 0.4704 - accuracy: 0.8620 - val_loss: 0.7110 - val_accuracy: 0.7708\n",
      "Epoch 836/1000\n",
      "48/48 [==============================] - 0s 9ms/step - loss: 0.4786 - accuracy: 0.8659 - val_loss: 0.7137 - val_accuracy: 0.7708\n",
      "Epoch 837/1000\n",
      "48/48 [==============================] - 0s 8ms/step - loss: 0.4884 - accuracy: 0.8372 - val_loss: 0.7083 - val_accuracy: 0.7656\n",
      "Epoch 838/1000\n",
      "48/48 [==============================] - 0s 8ms/step - loss: 0.4721 - accuracy: 0.8594 - val_loss: 0.7019 - val_accuracy: 0.7708\n",
      "Epoch 839/1000\n",
      "48/48 [==============================] - 0s 9ms/step - loss: 0.4688 - accuracy: 0.8711 - val_loss: 0.7022 - val_accuracy: 0.7656\n",
      "Epoch 840/1000\n",
      "48/48 [==============================] - 0s 8ms/step - loss: 0.4818 - accuracy: 0.8490 - val_loss: 0.7060 - val_accuracy: 0.7760\n",
      "Epoch 841/1000\n",
      "48/48 [==============================] - 0s 8ms/step - loss: 0.4468 - accuracy: 0.8789 - val_loss: 0.7059 - val_accuracy: 0.7708\n",
      "Epoch 842/1000\n",
      "48/48 [==============================] - 0s 7ms/step - loss: 0.5000 - accuracy: 0.8607 - val_loss: 0.7109 - val_accuracy: 0.7656\n",
      "Epoch 843/1000\n",
      "48/48 [==============================] - 0s 8ms/step - loss: 0.5097 - accuracy: 0.8516 - val_loss: 0.7115 - val_accuracy: 0.7500\n",
      "Epoch 844/1000\n",
      "48/48 [==============================] - 0s 8ms/step - loss: 0.5053 - accuracy: 0.8438 - val_loss: 0.7162 - val_accuracy: 0.7552\n",
      "Epoch 845/1000\n",
      "48/48 [==============================] - 0s 8ms/step - loss: 0.5201 - accuracy: 0.8464 - val_loss: 0.7130 - val_accuracy: 0.7552\n",
      "Epoch 846/1000\n",
      "48/48 [==============================] - 0s 8ms/step - loss: 0.4844 - accuracy: 0.8620 - val_loss: 0.7170 - val_accuracy: 0.7604\n",
      "Epoch 847/1000\n",
      "48/48 [==============================] - 0s 8ms/step - loss: 0.4988 - accuracy: 0.8581 - val_loss: 0.7159 - val_accuracy: 0.7656\n",
      "Epoch 848/1000\n",
      "48/48 [==============================] - 0s 8ms/step - loss: 0.4419 - accuracy: 0.8633 - val_loss: 0.7172 - val_accuracy: 0.7552\n",
      "Epoch 849/1000\n",
      "48/48 [==============================] - 0s 8ms/step - loss: 0.4346 - accuracy: 0.8763 - val_loss: 0.7161 - val_accuracy: 0.7604\n",
      "Epoch 850/1000\n",
      "48/48 [==============================] - 0s 8ms/step - loss: 0.5012 - accuracy: 0.8333 - val_loss: 0.7164 - val_accuracy: 0.7656\n",
      "Epoch 851/1000\n",
      "48/48 [==============================] - 0s 8ms/step - loss: 0.4517 - accuracy: 0.8581 - val_loss: 0.7137 - val_accuracy: 0.7656\n",
      "Epoch 852/1000\n",
      "48/48 [==============================] - 0s 9ms/step - loss: 0.4890 - accuracy: 0.8516 - val_loss: 0.7124 - val_accuracy: 0.7708\n",
      "Epoch 853/1000\n",
      "48/48 [==============================] - 0s 8ms/step - loss: 0.4936 - accuracy: 0.8620 - val_loss: 0.7090 - val_accuracy: 0.7760\n",
      "Epoch 854/1000\n",
      "48/48 [==============================] - 0s 8ms/step - loss: 0.4715 - accuracy: 0.8633 - val_loss: 0.7075 - val_accuracy: 0.7760\n",
      "Epoch 855/1000\n",
      "48/48 [==============================] - 0s 8ms/step - loss: 0.4374 - accuracy: 0.8737 - val_loss: 0.7070 - val_accuracy: 0.7708\n",
      "Epoch 856/1000\n",
      "48/48 [==============================] - 0s 8ms/step - loss: 0.5023 - accuracy: 0.8477 - val_loss: 0.7058 - val_accuracy: 0.7708\n",
      "Epoch 857/1000\n",
      "48/48 [==============================] - 0s 8ms/step - loss: 0.4634 - accuracy: 0.8555 - val_loss: 0.7077 - val_accuracy: 0.7708\n",
      "Epoch 858/1000\n",
      "48/48 [==============================] - 0s 8ms/step - loss: 0.4833 - accuracy: 0.8529 - val_loss: 0.7124 - val_accuracy: 0.7708\n",
      "Epoch 859/1000\n",
      "48/48 [==============================] - 0s 8ms/step - loss: 0.4542 - accuracy: 0.8646 - val_loss: 0.7130 - val_accuracy: 0.7708\n",
      "Epoch 860/1000\n",
      "48/48 [==============================] - 0s 8ms/step - loss: 0.4773 - accuracy: 0.8477 - val_loss: 0.7113 - val_accuracy: 0.7604\n",
      "Epoch 861/1000\n",
      "48/48 [==============================] - 0s 9ms/step - loss: 0.4558 - accuracy: 0.8737 - val_loss: 0.7097 - val_accuracy: 0.7708\n",
      "Epoch 862/1000\n",
      "48/48 [==============================] - 0s 8ms/step - loss: 0.4797 - accuracy: 0.8594 - val_loss: 0.7107 - val_accuracy: 0.7708\n",
      "Epoch 863/1000\n",
      "48/48 [==============================] - 0s 9ms/step - loss: 0.4411 - accuracy: 0.8841 - val_loss: 0.7108 - val_accuracy: 0.7708\n",
      "Epoch 864/1000\n",
      "48/48 [==============================] - 0s 8ms/step - loss: 0.4979 - accuracy: 0.8581 - val_loss: 0.7103 - val_accuracy: 0.7812\n",
      "Epoch 865/1000\n",
      "48/48 [==============================] - 0s 8ms/step - loss: 0.4341 - accuracy: 0.8633 - val_loss: 0.7054 - val_accuracy: 0.7760\n",
      "Epoch 866/1000\n",
      "48/48 [==============================] - 0s 9ms/step - loss: 0.4474 - accuracy: 0.8750 - val_loss: 0.7061 - val_accuracy: 0.7708\n",
      "Epoch 867/1000\n",
      "48/48 [==============================] - 0s 8ms/step - loss: 0.4838 - accuracy: 0.8594 - val_loss: 0.7042 - val_accuracy: 0.7760\n",
      "Epoch 868/1000\n",
      "48/48 [==============================] - 0s 8ms/step - loss: 0.4527 - accuracy: 0.8776 - val_loss: 0.7045 - val_accuracy: 0.7656\n",
      "Epoch 869/1000\n",
      "48/48 [==============================] - 0s 8ms/step - loss: 0.4472 - accuracy: 0.8828 - val_loss: 0.7010 - val_accuracy: 0.7656\n",
      "Epoch 870/1000\n",
      "48/48 [==============================] - 0s 8ms/step - loss: 0.4934 - accuracy: 0.8542 - val_loss: 0.7012 - val_accuracy: 0.7708\n",
      "Epoch 871/1000\n",
      "48/48 [==============================] - 0s 8ms/step - loss: 0.4264 - accuracy: 0.8802 - val_loss: 0.7007 - val_accuracy: 0.7708\n",
      "Epoch 872/1000\n",
      "48/48 [==============================] - 0s 8ms/step - loss: 0.4896 - accuracy: 0.8438 - val_loss: 0.7035 - val_accuracy: 0.7656\n",
      "Epoch 873/1000\n",
      "48/48 [==============================] - 0s 8ms/step - loss: 0.4637 - accuracy: 0.8776 - val_loss: 0.7026 - val_accuracy: 0.7760\n",
      "Epoch 874/1000\n",
      "48/48 [==============================] - 0s 8ms/step - loss: 0.4658 - accuracy: 0.8737 - val_loss: 0.6962 - val_accuracy: 0.7708\n",
      "Epoch 875/1000\n",
      "48/48 [==============================] - 0s 8ms/step - loss: 0.4715 - accuracy: 0.8594 - val_loss: 0.6956 - val_accuracy: 0.7708\n",
      "Epoch 876/1000\n",
      "48/48 [==============================] - 0s 8ms/step - loss: 0.4660 - accuracy: 0.8646 - val_loss: 0.7038 - val_accuracy: 0.7812\n",
      "Epoch 877/1000\n",
      "48/48 [==============================] - 0s 8ms/step - loss: 0.4596 - accuracy: 0.8828 - val_loss: 0.7056 - val_accuracy: 0.7812\n",
      "Epoch 878/1000\n",
      "48/48 [==============================] - 0s 8ms/step - loss: 0.4216 - accuracy: 0.8880 - val_loss: 0.7058 - val_accuracy: 0.7865\n",
      "Epoch 879/1000\n",
      "48/48 [==============================] - 0s 8ms/step - loss: 0.4751 - accuracy: 0.8646 - val_loss: 0.7110 - val_accuracy: 0.7812\n",
      "Epoch 880/1000\n",
      "48/48 [==============================] - 0s 7ms/step - loss: 0.4449 - accuracy: 0.8672 - val_loss: 0.7100 - val_accuracy: 0.7760\n",
      "Epoch 881/1000\n",
      "48/48 [==============================] - 0s 8ms/step - loss: 0.4657 - accuracy: 0.8503 - val_loss: 0.7100 - val_accuracy: 0.7708\n",
      "Epoch 882/1000\n",
      "48/48 [==============================] - 0s 8ms/step - loss: 0.4316 - accuracy: 0.8802 - val_loss: 0.7092 - val_accuracy: 0.7760\n",
      "Epoch 883/1000\n",
      "48/48 [==============================] - 0s 8ms/step - loss: 0.4553 - accuracy: 0.8633 - val_loss: 0.7076 - val_accuracy: 0.7708\n",
      "Epoch 884/1000\n",
      "48/48 [==============================] - 0s 9ms/step - loss: 0.4827 - accuracy: 0.8659 - val_loss: 0.7070 - val_accuracy: 0.7760\n",
      "Epoch 885/1000\n",
      "48/48 [==============================] - 0s 8ms/step - loss: 0.4183 - accuracy: 0.8854 - val_loss: 0.7014 - val_accuracy: 0.7760\n",
      "Epoch 886/1000\n",
      "48/48 [==============================] - 0s 8ms/step - loss: 0.4523 - accuracy: 0.8763 - val_loss: 0.7007 - val_accuracy: 0.7760\n",
      "Epoch 887/1000\n",
      "48/48 [==============================] - 0s 8ms/step - loss: 0.4836 - accuracy: 0.8711 - val_loss: 0.7010 - val_accuracy: 0.7760\n",
      "Epoch 888/1000\n",
      "48/48 [==============================] - 0s 8ms/step - loss: 0.4979 - accuracy: 0.8333 - val_loss: 0.7013 - val_accuracy: 0.7708\n",
      "Epoch 889/1000\n",
      "48/48 [==============================] - 0s 9ms/step - loss: 0.4433 - accuracy: 0.8698 - val_loss: 0.6974 - val_accuracy: 0.7708\n",
      "Epoch 890/1000\n",
      "48/48 [==============================] - 0s 8ms/step - loss: 0.4395 - accuracy: 0.8789 - val_loss: 0.6998 - val_accuracy: 0.7760\n",
      "Epoch 891/1000\n",
      "48/48 [==============================] - 0s 8ms/step - loss: 0.4528 - accuracy: 0.8776 - val_loss: 0.7016 - val_accuracy: 0.7760\n",
      "Epoch 892/1000\n",
      "48/48 [==============================] - 0s 8ms/step - loss: 0.4244 - accuracy: 0.8633 - val_loss: 0.6980 - val_accuracy: 0.7760\n",
      "Epoch 893/1000\n",
      "48/48 [==============================] - 0s 8ms/step - loss: 0.4826 - accuracy: 0.8529 - val_loss: 0.7013 - val_accuracy: 0.7865\n",
      "Epoch 894/1000\n",
      "48/48 [==============================] - 0s 9ms/step - loss: 0.4769 - accuracy: 0.8685 - val_loss: 0.7023 - val_accuracy: 0.7760\n",
      "Epoch 895/1000\n",
      "48/48 [==============================] - 0s 8ms/step - loss: 0.4497 - accuracy: 0.8763 - val_loss: 0.7081 - val_accuracy: 0.7656\n",
      "Epoch 896/1000\n",
      "48/48 [==============================] - 0s 8ms/step - loss: 0.4481 - accuracy: 0.8711 - val_loss: 0.7103 - val_accuracy: 0.7708\n",
      "Epoch 897/1000\n",
      "48/48 [==============================] - 0s 9ms/step - loss: 0.4412 - accuracy: 0.8646 - val_loss: 0.7108 - val_accuracy: 0.7656\n",
      "Epoch 898/1000\n",
      "48/48 [==============================] - 0s 8ms/step - loss: 0.4526 - accuracy: 0.8737 - val_loss: 0.7093 - val_accuracy: 0.7760\n",
      "Epoch 899/1000\n",
      "48/48 [==============================] - 0s 9ms/step - loss: 0.4758 - accuracy: 0.8516 - val_loss: 0.7037 - val_accuracy: 0.7865\n",
      "Epoch 900/1000\n",
      "48/48 [==============================] - 0s 9ms/step - loss: 0.4475 - accuracy: 0.8789 - val_loss: 0.7007 - val_accuracy: 0.7760\n",
      "Epoch 901/1000\n",
      "48/48 [==============================] - 0s 8ms/step - loss: 0.4614 - accuracy: 0.8698 - val_loss: 0.7067 - val_accuracy: 0.7760\n",
      "Epoch 902/1000\n",
      "48/48 [==============================] - 0s 8ms/step - loss: 0.4409 - accuracy: 0.8815 - val_loss: 0.7046 - val_accuracy: 0.7812\n",
      "Epoch 903/1000\n",
      "48/48 [==============================] - 0s 8ms/step - loss: 0.4180 - accuracy: 0.8880 - val_loss: 0.7040 - val_accuracy: 0.7760\n",
      "Epoch 904/1000\n",
      "48/48 [==============================] - 0s 9ms/step - loss: 0.4483 - accuracy: 0.8659 - val_loss: 0.7021 - val_accuracy: 0.7812\n",
      "Epoch 905/1000\n",
      "48/48 [==============================] - 0s 8ms/step - loss: 0.4518 - accuracy: 0.8763 - val_loss: 0.7035 - val_accuracy: 0.7708\n",
      "Epoch 906/1000\n",
      "48/48 [==============================] - 0s 8ms/step - loss: 0.4683 - accuracy: 0.8516 - val_loss: 0.7049 - val_accuracy: 0.7760\n",
      "Epoch 907/1000\n",
      "48/48 [==============================] - 0s 8ms/step - loss: 0.4289 - accuracy: 0.8672 - val_loss: 0.7021 - val_accuracy: 0.7812\n",
      "Epoch 908/1000\n",
      "48/48 [==============================] - 0s 9ms/step - loss: 0.4032 - accuracy: 0.8880 - val_loss: 0.7010 - val_accuracy: 0.7865\n",
      "Epoch 909/1000\n",
      "48/48 [==============================] - 0s 8ms/step - loss: 0.4445 - accuracy: 0.8555 - val_loss: 0.6985 - val_accuracy: 0.7969\n",
      "Epoch 910/1000\n",
      "48/48 [==============================] - 0s 8ms/step - loss: 0.4156 - accuracy: 0.8932 - val_loss: 0.6997 - val_accuracy: 0.8021\n",
      "Epoch 911/1000\n",
      "48/48 [==============================] - 0s 9ms/step - loss: 0.4202 - accuracy: 0.8932 - val_loss: 0.7000 - val_accuracy: 0.7917\n",
      "Epoch 912/1000\n",
      "48/48 [==============================] - 0s 8ms/step - loss: 0.4019 - accuracy: 0.8867 - val_loss: 0.7004 - val_accuracy: 0.7708\n",
      "Epoch 913/1000\n",
      "48/48 [==============================] - 0s 8ms/step - loss: 0.4055 - accuracy: 0.8932 - val_loss: 0.6954 - val_accuracy: 0.7760\n",
      "Epoch 914/1000\n",
      "48/48 [==============================] - 0s 8ms/step - loss: 0.4520 - accuracy: 0.8659 - val_loss: 0.6893 - val_accuracy: 0.7812\n",
      "Epoch 915/1000\n",
      "48/48 [==============================] - 0s 9ms/step - loss: 0.4252 - accuracy: 0.8841 - val_loss: 0.6901 - val_accuracy: 0.7865\n",
      "Epoch 916/1000\n",
      "48/48 [==============================] - 0s 8ms/step - loss: 0.4574 - accuracy: 0.8542 - val_loss: 0.6902 - val_accuracy: 0.7865\n",
      "Epoch 917/1000\n",
      "48/48 [==============================] - 0s 8ms/step - loss: 0.4582 - accuracy: 0.8659 - val_loss: 0.6869 - val_accuracy: 0.7865\n",
      "Epoch 918/1000\n",
      "48/48 [==============================] - 0s 9ms/step - loss: 0.4286 - accuracy: 0.8633 - val_loss: 0.6940 - val_accuracy: 0.7812\n",
      "Epoch 919/1000\n",
      "48/48 [==============================] - 0s 8ms/step - loss: 0.4516 - accuracy: 0.8750 - val_loss: 0.6958 - val_accuracy: 0.7865\n",
      "Epoch 920/1000\n",
      "48/48 [==============================] - 0s 8ms/step - loss: 0.4424 - accuracy: 0.8646 - val_loss: 0.6988 - val_accuracy: 0.7812\n",
      "Epoch 921/1000\n",
      "48/48 [==============================] - 0s 9ms/step - loss: 0.4653 - accuracy: 0.8685 - val_loss: 0.6975 - val_accuracy: 0.7812\n",
      "Epoch 922/1000\n",
      "48/48 [==============================] - 0s 8ms/step - loss: 0.4506 - accuracy: 0.8529 - val_loss: 0.7050 - val_accuracy: 0.7812\n",
      "Epoch 923/1000\n",
      "48/48 [==============================] - 0s 8ms/step - loss: 0.4601 - accuracy: 0.8698 - val_loss: 0.6987 - val_accuracy: 0.7865\n",
      "Epoch 924/1000\n",
      "48/48 [==============================] - 0s 8ms/step - loss: 0.4149 - accuracy: 0.8854 - val_loss: 0.6986 - val_accuracy: 0.7812\n",
      "Epoch 925/1000\n",
      "48/48 [==============================] - 0s 9ms/step - loss: 0.4081 - accuracy: 0.8750 - val_loss: 0.6919 - val_accuracy: 0.7865\n",
      "Epoch 926/1000\n",
      "48/48 [==============================] - 0s 8ms/step - loss: 0.4489 - accuracy: 0.8711 - val_loss: 0.6905 - val_accuracy: 0.7760\n",
      "Epoch 927/1000\n",
      "48/48 [==============================] - 0s 9ms/step - loss: 0.4132 - accuracy: 0.8906 - val_loss: 0.6886 - val_accuracy: 0.7760\n",
      "Epoch 928/1000\n",
      "48/48 [==============================] - 0s 10ms/step - loss: 0.4304 - accuracy: 0.8802 - val_loss: 0.6936 - val_accuracy: 0.7708\n",
      "Epoch 929/1000\n",
      "48/48 [==============================] - 0s 8ms/step - loss: 0.4545 - accuracy: 0.8659 - val_loss: 0.6969 - val_accuracy: 0.7760\n",
      "Epoch 930/1000\n",
      "48/48 [==============================] - 0s 9ms/step - loss: 0.4353 - accuracy: 0.8763 - val_loss: 0.6921 - val_accuracy: 0.7812\n",
      "Epoch 931/1000\n",
      "48/48 [==============================] - 0s 9ms/step - loss: 0.4077 - accuracy: 0.8776 - val_loss: 0.6937 - val_accuracy: 0.7708\n",
      "Epoch 932/1000\n",
      "48/48 [==============================] - 0s 8ms/step - loss: 0.4380 - accuracy: 0.8802 - val_loss: 0.6995 - val_accuracy: 0.7760\n",
      "Epoch 933/1000\n",
      "48/48 [==============================] - 0s 8ms/step - loss: 0.4408 - accuracy: 0.8698 - val_loss: 0.6991 - val_accuracy: 0.7708\n",
      "Epoch 934/1000\n",
      "48/48 [==============================] - 0s 8ms/step - loss: 0.4467 - accuracy: 0.8789 - val_loss: 0.6959 - val_accuracy: 0.7708\n",
      "Epoch 935/1000\n",
      "48/48 [==============================] - 0s 9ms/step - loss: 0.3927 - accuracy: 0.8893 - val_loss: 0.6944 - val_accuracy: 0.7656\n",
      "Epoch 936/1000\n",
      "48/48 [==============================] - 0s 8ms/step - loss: 0.4223 - accuracy: 0.8880 - val_loss: 0.6955 - val_accuracy: 0.7708\n",
      "Epoch 937/1000\n",
      "48/48 [==============================] - 0s 8ms/step - loss: 0.4802 - accuracy: 0.8438 - val_loss: 0.7005 - val_accuracy: 0.7656\n",
      "Epoch 938/1000\n",
      "48/48 [==============================] - 0s 9ms/step - loss: 0.4207 - accuracy: 0.8776 - val_loss: 0.6954 - val_accuracy: 0.7656\n",
      "Epoch 939/1000\n",
      "48/48 [==============================] - 0s 8ms/step - loss: 0.4178 - accuracy: 0.8737 - val_loss: 0.6920 - val_accuracy: 0.7708\n",
      "Epoch 940/1000\n",
      "48/48 [==============================] - 0s 9ms/step - loss: 0.4503 - accuracy: 0.8646 - val_loss: 0.6975 - val_accuracy: 0.7760\n",
      "Epoch 941/1000\n",
      "48/48 [==============================] - 0s 8ms/step - loss: 0.4129 - accuracy: 0.8815 - val_loss: 0.6979 - val_accuracy: 0.7760\n",
      "Epoch 942/1000\n",
      "48/48 [==============================] - 0s 8ms/step - loss: 0.4332 - accuracy: 0.8789 - val_loss: 0.6990 - val_accuracy: 0.7812\n",
      "Epoch 943/1000\n",
      "48/48 [==============================] - 0s 9ms/step - loss: 0.4257 - accuracy: 0.8698 - val_loss: 0.6950 - val_accuracy: 0.7812\n",
      "Epoch 944/1000\n",
      "48/48 [==============================] - 0s 8ms/step - loss: 0.4265 - accuracy: 0.8711 - val_loss: 0.6971 - val_accuracy: 0.7812\n",
      "Epoch 945/1000\n",
      "48/48 [==============================] - 0s 9ms/step - loss: 0.4322 - accuracy: 0.8880 - val_loss: 0.6973 - val_accuracy: 0.7708\n",
      "Epoch 946/1000\n",
      "48/48 [==============================] - 0s 8ms/step - loss: 0.4145 - accuracy: 0.8737 - val_loss: 0.6965 - val_accuracy: 0.7812\n",
      "Epoch 947/1000\n",
      "48/48 [==============================] - 0s 9ms/step - loss: 0.4646 - accuracy: 0.8529 - val_loss: 0.6970 - val_accuracy: 0.7760\n",
      "Epoch 948/1000\n",
      "48/48 [==============================] - 0s 8ms/step - loss: 0.4181 - accuracy: 0.8776 - val_loss: 0.6990 - val_accuracy: 0.7812\n",
      "Epoch 949/1000\n",
      "48/48 [==============================] - 0s 9ms/step - loss: 0.4535 - accuracy: 0.8711 - val_loss: 0.6984 - val_accuracy: 0.7708\n",
      "Epoch 950/1000\n",
      "48/48 [==============================] - 0s 8ms/step - loss: 0.4154 - accuracy: 0.8971 - val_loss: 0.6972 - val_accuracy: 0.7760\n",
      "Epoch 951/1000\n",
      "48/48 [==============================] - 0s 9ms/step - loss: 0.4322 - accuracy: 0.8802 - val_loss: 0.7001 - val_accuracy: 0.7812\n",
      "Epoch 952/1000\n",
      "48/48 [==============================] - 0s 8ms/step - loss: 0.4488 - accuracy: 0.8672 - val_loss: 0.6977 - val_accuracy: 0.7865\n",
      "Epoch 953/1000\n",
      "48/48 [==============================] - 0s 8ms/step - loss: 0.3931 - accuracy: 0.8984 - val_loss: 0.6994 - val_accuracy: 0.7812\n",
      "Epoch 954/1000\n",
      "48/48 [==============================] - 0s 9ms/step - loss: 0.4217 - accuracy: 0.8828 - val_loss: 0.6942 - val_accuracy: 0.7760\n",
      "Epoch 955/1000\n",
      "48/48 [==============================] - 0s 8ms/step - loss: 0.4198 - accuracy: 0.8724 - val_loss: 0.6969 - val_accuracy: 0.7760\n",
      "Epoch 956/1000\n",
      "48/48 [==============================] - 0s 8ms/step - loss: 0.4036 - accuracy: 0.8880 - val_loss: 0.6968 - val_accuracy: 0.7812\n",
      "Epoch 957/1000\n",
      "48/48 [==============================] - 0s 9ms/step - loss: 0.4418 - accuracy: 0.8633 - val_loss: 0.6946 - val_accuracy: 0.7708\n",
      "Epoch 958/1000\n",
      "48/48 [==============================] - 0s 8ms/step - loss: 0.4380 - accuracy: 0.8724 - val_loss: 0.6973 - val_accuracy: 0.7708\n",
      "Epoch 959/1000\n",
      "48/48 [==============================] - 0s 8ms/step - loss: 0.4187 - accuracy: 0.8854 - val_loss: 0.6956 - val_accuracy: 0.7708\n",
      "Epoch 960/1000\n",
      "48/48 [==============================] - 0s 8ms/step - loss: 0.4121 - accuracy: 0.8711 - val_loss: 0.6960 - val_accuracy: 0.7760\n",
      "Epoch 961/1000\n",
      "48/48 [==============================] - 0s 8ms/step - loss: 0.4042 - accuracy: 0.8828 - val_loss: 0.6974 - val_accuracy: 0.7656\n",
      "Epoch 962/1000\n",
      "48/48 [==============================] - 0s 8ms/step - loss: 0.4108 - accuracy: 0.8776 - val_loss: 0.6988 - val_accuracy: 0.7760\n",
      "Epoch 963/1000\n",
      "48/48 [==============================] - 0s 8ms/step - loss: 0.4164 - accuracy: 0.8737 - val_loss: 0.6954 - val_accuracy: 0.7656\n",
      "Epoch 964/1000\n",
      "48/48 [==============================] - 0s 9ms/step - loss: 0.3955 - accuracy: 0.8997 - val_loss: 0.7001 - val_accuracy: 0.7708\n",
      "Epoch 965/1000\n",
      "48/48 [==============================] - 0s 8ms/step - loss: 0.4065 - accuracy: 0.8880 - val_loss: 0.7014 - val_accuracy: 0.7604\n",
      "Epoch 966/1000\n",
      "48/48 [==============================] - 0s 8ms/step - loss: 0.4334 - accuracy: 0.8776 - val_loss: 0.7024 - val_accuracy: 0.7604\n",
      "Epoch 967/1000\n",
      "48/48 [==============================] - 0s 8ms/step - loss: 0.4046 - accuracy: 0.8776 - val_loss: 0.6990 - val_accuracy: 0.7812\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 0.6869 - accuracy: 0.7865\n",
      "Test Loss: 0.6868939399719238, Test Accuracy: 0.7864583134651184\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv1D, MaxPooling1D, Flatten, Dense, Dropout, Activation, BatchNormalization\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from tensorflow.keras.regularizers import l2\n",
    "\n",
    "# Define your model\n",
    "model = Sequential()\n",
    "\n",
    "model.add(Conv1D(128, 5, padding='same', input_shape=(32, 1)))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dropout(0.3))\n",
    "\n",
    "model.add(Conv1D(64, 5, padding='same'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling1D(pool_size=2))\n",
    "model.add(Dropout(0.3))\n",
    "\n",
    "model.add(Conv1D(64, 5, padding='same'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dropout(0.3))\n",
    "\n",
    "model.add(Flatten())\n",
    "model.add(Dense(64, kernel_regularizer=l2(0.001)))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dropout(0.5))\n",
    "\n",
    "model.add(Dense(10))\n",
    "model.add(Activation('softmax'))\n",
    "\n",
    "# Compile the model with Adam optimizer and categorical crossentropy loss\n",
    "model.compile(optimizer=Adam(learning_rate=0.00005), loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Display model summary\n",
    "model.summary()\n",
    "\n",
    "# Implement early stopping\n",
    "early_stop = EarlyStopping(monitor='val_loss', patience=50, restore_best_weights=True)\n",
    "\n",
    "# Train the model with early stopping\n",
    "history = model.fit(x_traincnn, y_train, batch_size=16, epochs=1000, \n",
    "                    validation_data=(x_testcnn, y_test), callbacks=[early_stop])\n",
    "\n",
    "# Evaluate the model\n",
    "loss, accuracy = model.evaluate(x_testcnn, y_test)\n",
    "print(f\"Test Loss: {loss}, Test Accuracy: {accuracy}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "303837d4-a2b3-4a91-9bc8-f571ddcb1dc1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.title('model loss')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'test'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df9805ea",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
